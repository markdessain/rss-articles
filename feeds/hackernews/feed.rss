<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Hacker News</title>
    <link>https://news.ycombinator.com/</link>
    <description>Links for the intellectually curious, ranked by readers.</description>
    <image>
      <url></url>
      <title></title>
      <link></link>
    </image>
    <item>
      <title>Launch YC S21: Meet the Batch, Thread #5</title>
      <link>https://news.ycombinator.com/item?id=28128957</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div>Here&#39;s the fifth &#34;Meet the Batch&#34; thread for YC&#39;s S21 batch. The previous thread was <a href="https://news.ycombinator.com/item?id=28073548" rel="nofollow">https://news.ycombinator.com/item?id=28073548</a>, and if you&#39;re wondering what it&#39;s all about, the description is at <a href="https://news.ycombinator.com/item?id=27877280" rel="nofollow">https://news.ycombinator.com/item?id=27877280</a>.<p>There are 7 startups in this thread. The initial order is random:</p><p>Launch HN: Clarity (YC S21) - Run your distributed team with a single weekly doc - <a href="https://news.ycombinator.com/item?id=28128962" rel="nofollow">https://news.ycombinator.com/item?id=28128962</a></p><p>Launch HN: Mentorcam (YC S21) - Get advice from public figures - <a href="https://news.ycombinator.com/item?id=28128958" rel="nofollow">https://news.ycombinator.com/item?id=28128958</a></p><p>Launch HN: Sirka (YC S21) - Tackling obesity in Southeast Asia - <a href="https://news.ycombinator.com/item?id=28128964" rel="nofollow">https://news.ycombinator.com/item?id=28128964</a></p><p>Launch HN: Echoes HQ (YC S21) - Measure the effectiveness of engineering organizations - <a href="https://news.ycombinator.com/item?id=28128961" rel="nofollow">https://news.ycombinator.com/item?id=28128961</a></p><p>Launch HN: PayHippo (YC S21) - Loans to small businesses in Nigeria - <a href="https://news.ycombinator.com/item?id=28130022" rel="nofollow">https://news.ycombinator.com/item?id=28130022</a></p><p>Launch HN: ContraForce (YC S21) - All-in-one cybersecurity platform - <a href="https://news.ycombinator.com/item?id=28128959" rel="nofollow">https://news.ycombinator.com/item?id=28128959</a></p><p>Launch HN: Palenca (YC S21) - Payroll API for Latin America - <a href="https://news.ycombinator.com/item?id=28128960" rel="nofollow">https://news.ycombinator.com/item?id=28128960</a></p></div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 14:01:18 +0000</pubDate>
      <source>https://news.ycombinator.com/item?id=28128957</source>
    </item>
    <item>
      <title>Apple call center workers fear AI-powered surveillance cameras in their homes</title>
      <link>https://9to5mac.com/2021/08/09/apple-call-center-workers-surveillance/</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/NewsArticle">
				<!-- .elastic-container -->
				<div>
						
						<p>
						</p><!-- .feat-image -->
					<!-- .post-social-mobile -->
				</div><!-- .feat-image-wrapper -->
				<div>

					<div itemprop="articleBody">
						<p>Home-based <a href="https://9to5mac.com/guides/aapl/" target="_blank" rel="noreferrer noopener">Apple</a> call center workers in Colombia have expressed <a href="https://9to5mac.com/guides/privacy/" target="_blank" rel="noreferrer noopener">privacy</a> concerns over plans to install AI-powered cameras in their homes, to monitor their performance. The same issue has arisen over Apple UK workers based in Albania.</p>
<p>Apple outsources some of its call center work around the world to Teleperformance, and employees say they are being pressured to sign a contract agreeing to the cameras, despite an Apple policy prohibiting it ‚Ä¶ </p>

<p><em><a href="https://www.nbcnews.com/tech/tech-news/big-tech-call-center-workers-face-pressure-accept-home-surveillance-n1276227" target="_blank" rel="noreferrer noopener">NBC News</a></em> reports.</p>
<blockquote>
<p>Six workers based in Colombia for Teleperformance, one of the world‚Äôs largest call center companies, which counts Apple, Amazon and Uber among its clients, said that they are concerned about the new contract, first issued in March. The contract allows monitoring by AI-powered cameras in workers‚Äô homes, voice analytics and storage of data collected from the worker‚Äôs family members, including minors [‚Ä¶]</p>
<p>‚ÄúThe contract allows constant monitoring of what we are doing, but also our family,‚Äù said a Bogota-based worker on the Apple account who was not authorized to speak to the news media. ‚ÄúI think it‚Äôs really bad. We don‚Äôt work in an office. I work in my bedroom. I don‚Äôt want to have a camera in my bedroom.‚Äù</p>
<p>The worker said that she signed the contract, a copy of which NBC News has reviewed, because she feared losing her job. She said that she was told by her supervisor that she would be moved off the Apple account if she refused to sign the document. </p>
</blockquote>

<p>Teleperformance<span> operates in 18 other countries, and was previously banned from using the cameras in Albania.</span></p>
<blockquote>
<p>At the end of 2020, workers at Teleperformance in Albania, including those working on the Apple U.K. account, complained to the country‚Äôs Information and Data Protection Commissioner about the company‚Äôs proposal to introduce video monitoring in their homes. The commissioner later ruled that Teleperformance could not use webcams to monitor Albanian workers in their homes.</p>
</blockquote>
<p>It‚Äôs unclear how this was allowed to get as far as even the planning stage, as Apple says it does not allow its contractors to do this. </p>
<blockquote>
<p>Apple spokesperson Nick Leahy said that the company ‚Äúprohibits the use of video or photographic monitoring by our suppliers and have confirmed Teleperformance does not use video monitoring for any of their teams working with Apple.‚Äù Leahy said that Apple had audited Teleperformance in Colombia this year and did not find any ‚Äúcore violations of our strict standards.‚Äù</p>
<p>‚ÄúWe investigate all claims and will continue to ensure everyone across our supply chain is treated with dignity and respect,‚Äù he added.</p>
</blockquote>
<p>Teleperformance says that its use of the technology is for security reasons, to ensure that employees are not taking photos or videos of confidential materials, but the report says that the AI can detect when employees and not using the keyboard or mouse and flag them as idle.</p>
<p>The <a href="https://www.nbcnews.com/tech/tech-news/big-tech-call-center-workers-face-pressure-accept-home-surveillance-n1276227" target="_blank" rel="noreferrer noopener">full piece</a> is worth reading.</p>
<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><figure><a href="https://bit.ly/3C0YHbr"></a></figure></div><hr/>
<p><a href="https://www.youtube.com/c/9to5mac?sub_confirmation=1" target="_blank" rel="noopener">Check out 9to5Mac on YouTube for more Apple news:</a></p><!-- youtube embed --><p><iframe title="Recent Videos" src="https://www.youtube.com/embed/Q0C3hzx54KM?playlist=AKy8o-nvjQw,eYzKvIDPX88,gy5aEplDrS0,tBB6m5Mbw1g,UBaiOB4WBdU,i7IebkHZom0,qtUKzWab71Q,tyEmqllTrO0,v7PqmXZsKww" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" width="1000" height="563"></iframe></p>
					</div><!-- .post-body -->


						
				</div><!-- .elastic-container -->

				

				

			<div>
				<div>
					<h2>About the Author</h2>
					<div itemprop="author" itemscope="" itemtype="https://schema.org/Person">
							<div>
								<p><a href="https://9to5mac.com/author/benlovejoy/">
									
								</a></p><h3>
									<a href="https://9to5mac.com/author/benlovejoy/">
										<span itemprop="name">Ben Lovejoy</span>
									</a>
								</h3>

									<p>
										<a href="https://twitter.com/benlovejoy" target="_blank"><span></span>@benlovejoy</a>
									</p>

								<p>Ben Lovejoy is a British technology writer and EU Editor for 9to5Mac. He‚Äôs known for his op-eds and diary pieces, exploring his experience of Apple products over time, for a more rounded review. He also writes fiction, with two technothriller novels, a couple of SF shorts and a rom-com!</p>
						</div>
					</div>
						<div>
							<h3><span>Ben Lovejoy&#39;s favorite gear</span></h3>
							
						</div>
				</div>
			</div>




				

		</article></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 00:41:50 +0000</pubDate>
      <source>https://9to5mac.com/2021/08/09/apple-call-center-workers-surveillance/</source>
    </item>
    <item>
      <title>Unity to acquire Parsec for $320M</title>
      <link>https://investors.unity.com/news/news-details/2021/Unity-Enters-Into-Agreement-to-Acquire-Parsec/default.aspx</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div>
                    <div><p>
  <i>Parsec‚Äôs technology allows creators to work together remotely and leverage high performance processing from anywhere</i>
</p><p>    SAN FRANCISCO--(BUSINESS WIRE)--
<a rel="nofollow" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=http%3A%2F%2Fwww.unity3d.com&amp;esheet=52474008&amp;newsitemid=20210810005116&amp;lan=en-US&amp;anchor=Unity&amp;index=1&amp;md5=0c45ea5f41deef1623b3511a6475f3ac" shape="rect">Unity</a> (NYSE: U), the world‚Äôs leading platform for creating and operating real-time 3D (RT3D) content, announced it has entered into a definitive agreement to acquire the high performance remote desktop and streaming technology company, <a rel="nofollow" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=https%3A%2F%2Fparsec.app%2F&amp;esheet=52474008&amp;newsitemid=20210810005116&amp;lan=en-US&amp;anchor=Parsec&amp;index=2&amp;md5=5231e89df85b176ed66fc16fa8e0813b" shape="rect">Parsec</a>, which allows gaming and creative professionals to work together from anywhere. This transaction is an important step toward Parsec‚Äôs and Unity‚Äôs expanded cloud vision: that creators should expect to be able to work from any location, on any device through rich and powerful tools and seamless cloud infrastructure to deliver the real-time 3D experiences of the future.
</p><p>
Under the terms of the agreement, Unity will acquire Parsec for approximately US$320 million in cash. The proposed acquisition is expected to close during Unity‚Äôs third quarter and is subject to customary closing conditions.
</p><p>
The work of game development and creative professionals is high fidelity, interactive and immersive, and only getting more complex as creators shift to RT3D. With companies and their employees transitioning to hybrid working and collaboration models, Parsec allows creators to be untethered from the office by meeting the unique requirements to support this level of performance processing no matter the location, device or platform. This means delivering low latency, ultra-high definition desktop streaming (at 4k pixels/60 frames per second) while providing rich detail with the same sampling rate for all images, such as 4:4:4 color space. Additionally, Parsec offers the privacy, security, quality of life and management tools needed for companies to support fleets of computing resources for all of their creators<i>.</i></p><p>
‚ÄúIn the past year, companies and their employees have been collaborating and working together in fundamentally different ways,‚Äù said Marc Whitten, Senior Vice President and General Manager, Create Solutions at Unity. ‚ÄúWith the workplace becoming more flexible, teams expanding and collaborating across multiple locations and creators leveraging a myriad of new devices, it‚Äôs clear that the creative process will evolve from on premise devices to flexible and cost effective cloud architectures. Parsec has addressed the unique requirements to support this type of high-performance processing no matter where creators are, showcasing technology that is both highly innovative and prescient. We believe Parsec is a rocket ship and we‚Äôre very excited to support their future growth.‚Äù
</p><p>
&#34;When Chris Dickson and I started Parsec, we believed Parsec&#39;s ultra-low latency streaming technology could allow anyone in the world to remotely interact with real-time 3D content,&#34; said Benjy Boxer, Parsec&#39;s CEO and co-founder. &#34;In the past year, Parsec has empowered the world&#39;s most inspiring and creative companies to freely work and play from anywhere, on any device, on their own terms. We&#39;re thrilled to partner with Unity, where we can offer even more creators this same kind of liberating access to content and technology.&#34;
</p><p>
As a result of their unique capabilities and the shift to new ways of working, Parsec‚Äôs Parsec for Teams subscription business is growing by 170% year-over-year with aggressive plans to accelerate even further next year. Subscription growth is driven by a strong net dollar expansion rate of nearly 200%, a loyal customer base, and strong profitability.
</p><p>
Parsec has become a go-to solution for hybrid work models among gaming companies such as Electronic Arts, Ubisoft and Square Enix and is integrated in many of the industry verticals where Unity sells solutions, including media and entertainment, architecture and design, and more. Together, Unity sees an opportunity to drive shared momentum with these customers through targeted cross-selling and bundled solutions.
</p><p>
  <b>About Parsec</b>
</p><p>
Founded in 2016 by CTO Chris Dickson and CEO Benjy Boxer, Parsec delivers a best-in-class high frame rate, low-latency remote desktop experience. The Parsec app is available for Windows, Mac, Linux, Android, Raspberry Pi and the web, and Parsec&#39;s SDK allows its streaming technology to be leveraged across any platform.
</p><p>
  <b>About Unity </b>
</p><p>
Unity (NYSE: U) is the world‚Äôs leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity‚Äôs platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices. The company‚Äôs 1,800+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than five billion times per month in 2020. For more information, please visit <a rel="nofollow" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=http%3A%2F%2Fwww.unity.com&amp;esheet=52474008&amp;newsitemid=20210810005116&amp;lan=en-US&amp;anchor=www.unity.com&amp;index=3&amp;md5=892250673999adcfa4d4d8b4f63ba390" shape="rect">www.unity.com</a>.
</p><p>
  <b>Forward-Looking Statements</b>
</p><p>
This press release contains forward-looking statements that involve risks and uncertainties, including statements regarding Parsec‚Äôs ability to allow gaming and creative professionals to work together from anywhere and Unity‚Äôs ability to integrate Parsec‚Äôs technology into Unity‚Äôs business; Parsec and Unity‚Äôs expanded cloud vision; the closing of the transaction; Parsec‚Äôs continued ability to deliver high frame rates and resolution and low latency; the increasing demand for flexible workplaces and the evolution from on premise devices to flexible and cost effective cloud architectures; Parsec‚Äôs continued growth and Unity‚Äôs ability to support that growth; Parsec‚Äôs strong presence among gaming companies and other industry verticals; and Unity‚Äôs ability to drive shared momentum through targeted cross-selling and bundled solutions. The words ‚Äúwill,‚Äù ‚Äúallows,‚Äù ‚Äúcan,‚Äù ‚Äúenable,‚Äù ‚Äúobjective‚Äù and similar expressions are intended to identify forward-looking statements. These forward-looking statements are subject to risks, uncertainties, and assumptions, such as Unity‚Äôs ability to successfully integrate Parsec‚Äôs technology and business; costs related to the acquisition; whether potential benefits of the transaction extend to Unity and Parsec‚Äôs customers; Unity‚Äôs and Parsec‚Äôs success developing new products or modifying existing products and the degree to which these gain market acceptance; any unanticipated impact of accounting for the acquisition; and the conditional closing of the transaction. If the risks materialize or assumptions prove incorrect, actual results could differ materially from the results implied by these forward-looking statements. Further information on these and additional risks that could affect Unity‚Äôs results is included in our filings with the Securities and Exchange Commission (‚ÄúSEC‚Äù), including our Form 10-Q filed with the SEC on August 11, 2021, and our future reports that we may file with the SEC from time to time, which could cause actual results to vary from expectations. Unity assumes no obligation to, and does not currently intend to, update any such forward-looking statements after the date of this release.
</p><p>
  
  <span></span>
</p><p id="mmgallerylink">
  <span id="mmgallerylink-phrase">View source version on <a href="http://businesswire.com">businesswire.com</a>: </span>
  <span id="mmgallerylink-link">
    <a href="https://www.businesswire.com/news/home/20210810005116/en/" rel="nofollow">https://www.businesswire.com/news/home/20210810005116/en/</a>
  </span>
</p><p>
  <b>Marisa Graves
</b>
  </p><p>Source: Unity</p></div>
                </div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 21:14:01 +0000</pubDate>
      <source>https://investors.unity.com/news/news-details/2021/Unity-Enters-Into-Agreement-to-Acquire-Parsec/default.aspx</source>
    </item>
    <item>
      <title>Apple drops Lawsuit against Corellium</title>
      <link>https://9to5mac.com/2021/08/10/apple-drops-copyright-lawsuit-against-corellium-for-selling-virtual-ios-devices/</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/NewsArticle">
				<!-- .elastic-container -->
				<div>
						
						<p>
						</p><!-- .feat-image -->
					<!-- .post-social-mobile -->
				</div><!-- .feat-image-wrapper -->
				<div>

					<div itemprop="articleBody">
						<p>Apple has been fighting with Corellium in the courts since August 2019 after the virtualization company started selling virtual iOS devices to security researchers. Following its first defeat last year, Apple is now dropping the copyright lawsuit against Corellium and its virtualization software.</p>

<p>The news was first shared by the <em><a href="https://www.washingtonpost.com/technology/2021/08/10/apple-drops-corellium-lawsuit/" target="_blank" rel="noreferrer noopener">Washington Post</a></em>, which claims that both companies have reached an agreement. Although Corellium sent an email to its sales team saying that its virtual iOS devices will remain for sale, the terms of the agreement with Apple are confidential. Both companies declined to comment publicly on the matter.</p>
<blockquote>
<p><em>Corellium was previously facing the prospect of years of expensive and drawn out legal action, and many in the security research community saw the lawsuit as having a chilling effect on independent research.</em></p>
</blockquote>
<p>Corellium‚Äôs software lets security experts run virtualized iOS devices for research purposes. In a lawsuit filed in the Southern District of Florida, <a href="https://9to5mac.com/2019/08/15/apple-corellium-lawsuit/" target="_blank" rel="noreferrer noopener">Apple claimed that the company was infringing its copyright</a> by selling a copy of iOS without authorization. Apple also claimed that hackers could use Corellium‚Äôs platform to find ways to hack iPhones and iPads.</p>
<p>Despite its attempts, <a href="https://9to5mac.com/2020/12/29/apple-loses-copyright-lawsuit-against-ios-virtualization-company-corellium/" target="_blank" rel="noreferrer noopener">Apple faced a major defeat</a> in December 2020 when a federal judge said Corellium ‚Äúhad established fair use for using Apple‚Äôs code.‚Äù The Cupertino-based company continued to seek an injunction to stop Corellium from selling virtual iOS devices, but now Apple has decided to drop the case.</p>
<p>Earlier this year, <a href="https://9to5mac.com/2021/01/25/corellium-now-offers-ios-virtualization-tool-for-individual-subscribers/" target="_blank" rel="noreferrer noopener">Corellium‚Äôs platform became available to individual subscribers</a>. Previously, only users with enterprise accounts were able to request a virtualized iOS device. According to the company, each request is reviewed individually to avoid the use of the software for malicious purposes.</p>
<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><figure><a href="https://bit.ly/3C0YHbr"></a></figure></div><hr/>
<p><a href="https://www.youtube.com/c/9to5mac?sub_confirmation=1" target="_blank" rel="noopener">Check out 9to5Mac on YouTube for more Apple news:</a></p><!-- youtube embed --><p><iframe title="Recent Videos" src="https://www.youtube.com/embed/gy5aEplDrS0?playlist=UBaiOB4WBdU,tyEmqllTrO0,i7IebkHZom0,Q0C3hzx54KM,qtUKzWab71Q,eYzKvIDPX88,tBB6m5Mbw1g,AKy8o-nvjQw,v7PqmXZsKww" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" width="1000" height="563"></iframe></p>
					</div><!-- .post-body -->


						
				</div><!-- .elastic-container -->

				

				

			<div>
				<div>
					<h2>About the Author</h2>
					<div itemprop="author" itemscope="" itemtype="https://schema.org/Person">
							<div>
								<p><a href="https://9to5mac.com/author/filipeesposito/">
									
								</a></p><h3>
									<a href="https://9to5mac.com/author/filipeesposito/">
										<span itemprop="name">Filipe Esp√≥sito</span>
									</a>
								</h3>

									<p>
										<a href="https://twitter.com/filipeesposito" target="_blank"><span></span>@filipeesposito</a>
									</p>

								<p>Filipe Esp√≥sito is a Brazilian tech Journalist who started covering Apple news on iHelp BR with some exclusive scoops ‚Äî including the reveal of the new Apple Watch Series 5 models in titanium and ceramic. He joined 9to5Mac to share even more tech news around the world.</p>
						</div>
					</div>
				</div>
			</div>




				

		</article></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 05:58:31 +0000</pubDate>
      <source>https://9to5mac.com/2021/08/10/apple-drops-copyright-lawsuit-against-corellium-for-selling-virtual-ios-devices/</source>
    </item>
    <item>
      <title>Please log in with router&#39;s password</title>
      <link>https://www.google.com/search?q=%22Please+log+in+with+router%27s+password%22</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div id="main"><div><div><div><div><div><div><div><p>Please Log in with Router&#39;s Password (google.com). 432 points by fny 10 hours ago | hide | past | favorite | 202 comments†...</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p>Please log in with router&#39;s password. This router is not bound to the current TP-Link ID. Enter the router&#39;s login password to bind for management.</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p><span>Jun 18, 2020</span><span> ∑ </span>Please log in with router&#39;s password, or contact the router&#39;s owner to add your TP-Link ID as a manager.‚Äù. If I then log in using the router†...</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p>Please log in with router&#39;s password. This router is not bound to the current TP-Link ID. Enter the router&#39;s login password to bind for management.</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p><span>11 hours ago</span><span> ∑ </span>Search This Blog ∑ Please Log in with Router&#39;s Password ∑ Comments ∑ Popular Posts ∑ HBO Max accidentally sent a Integration Test email to all†...</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p>Please log in with router&#39;s password. This router is not bound to the current TP-Link ID. Enter the router&#39;s login password to bind for management.</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p>Please log in with router&#39;s password. This router is not bound to the current TP-Link ID. Enter the router&#39;s login password to bind for management.</p></div></div></div></div></div></div></div><div><div><p><span><p><span>People also ask</span></p></span></p><div><div><div><div aria-expanded="false" id="tsuid1" role="button" tabindex="0" data-ved="2ahUKEwj0q_7Jw6jyAhWbk2oFHUR1C-4Quk56BAgKEAI"><p>What is the router&#39;s password?</p></div></div></div></div><div><div><div><div aria-expanded="false" id="tsuid4" role="button" tabindex="0" data-ved="2ahUKEwj0q_7Jw6jyAhWbk2oFHUR1C-4Quk56BAgKEAk"><p>How do I log into my routers login?</p></div></div></div></div><div><div><div><div aria-expanded="false" id="tsuid7" role="button" tabindex="0" data-ved="2ahUKEwj0q_7Jw6jyAhWbk2oFHUR1C-4Quk56BAgKEBA"><p>How do you log into your wireless router password?</p></div></div></div></div><div><div><div><div aria-expanded="false" id="tsuid10" role="button" tabindex="0" data-ved="2ahUKEwj0q_7Jw6jyAhWbk2oFHUR1C-4Quk56BAgKEBc"><p>What is my router&#39;s admin username and password?</p></div></div></div></div></div></div><div><div><div><div><div><div><div><p>Please log in with router&#39;s password. This router is not bound to the current TP-Link ID. Enter the router&#39;s login password to bind for management.</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p>Please log in with router&#39;s password. This router is not bound to the current TP-Link ID. Enter the router&#39;s login password to bind for management.</p></div></div></div></div></div></div></div><div><div><div><div><div><div><div><p>Please log in with router&#39;s password. This router is not bound to the current TP-Link ID. Enter the router&#39;s login password to bind for management.</p></div></div></div></div></div></div></div></div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 20:41:04 +0000</pubDate>
      <source>https://www.google.com/search?q=%22Please+log+in+with+router%27s+password%22</source>
    </item>
    <item>
      <title>Build you own SGI Indy workstation with mame</title>
      <link>https://sgi.neocities.org/</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div>

			<div>
				<p><a target="_blank" href="https://sgi.neocities.org/main.png">
				
				</a>
				</p>
				</div>
				
				<div>
				<p><a target="_blank" href="https://sgi.neocities.org/1.png">
				
				</a>
				</p>
				</div>
					
				<div>
				<p><a target="_blank" href="https://sgi.neocities.org/2.png">
				
				</a>
				</p>
				</div>
					
				<div>
				<p><a target="_blank" href="https://sgi.neocities.org/3.png">
				
				</a>
				</p>
				</div>
					
				<div>
				<p><a target="_blank" href="https://sgi.neocities.org/4.png">
				
				</a>
				</p>
				</div>

					
				

			
				<nav>
					<ul>
						<li><a href="https://sgi.neocities.org/index.html">Home</a></li>
						<li><a href="https://sgi.neocities.org/installguide.html">Install Guide</a></li>
						<li><a href="https://sgi.neocities.org/hardware.html">Hardware</a></li>
						<li><a href="https://sgi.neocities.org/links.html">Links</a></li>
						<li><a href="https://sgi.neocities.org/feedback.html">Feedback</a></li>
						<li><a href="http://www.guestcity.com/cgi-bin/view.fcgi?book=sgi">Guest Book</a></li>
					</ul>
				</nav>


<h2><span>A guide to running IRIX 6.5.22 in MAME</span></h2>

<p><strong><span>About this project:</span></strong></p>
<p><span>This is a guide that will help you set up MAME to emulate a Silicon Graphics Indy with a 100MHz MIPS R4600, 128MB of RAM, and 24-bit XL graphics. Below are the instructions for running IRIX 6.5.22 off a pre-made disk image. Check out the installation guide for instructions on how to make your own disk image and install IRIX from scratch. As of right now the emulator is fairly slow, meaning it&#39;s only really good for exploring the OS itself and a few basic programs. Have patience with it and don&#39;t expect too much. I would also like to offer my thanks to everyone who worked on MAME and/or hosts these files. Thank you all for making the preservation of this awesome software possible. Please send any donations to the MAME project or IRIX Network Forums.</span></p>


<p><strong><span>Files you will need:</span></strong></p>


<ul>
<li><span>72x8455.zm82 (ps2_keybc.zip)</span></li>
<li><span>https://archive.org/download/MAME208RomsOnlyMerged</span></li>

<li><span>natural.bin (kb_ms_natural.zip)</span></li>
<li><span>https://archive.org/download/aristmk6_201810</span></li>

<li><span>ip24prom.070-9101-011.bin</span></li>
<li><span>http://www.vdheijden-messerli.net/sgistuff/nekochan/prom/IP24_Indy/</span></li>

<li><span>MAME 0.218 or later</span></li>
<li><span>https://www.mamedev.org/release.html</span></li>

<li><span>A disk image with IRIX 6.5.22 installed</span></li>
<li><span>http://usftp.irixnet.org/sgi-mame/irix-6.5.22m-MAME.tar.xz</span></li>

<li><span>Alternatively a disk image with IRIX 5.3 installed</span></li>
<li><span>http://usftp.irixnet.org/sgi-mame/irix-5.3-MAME.tar.xz</span></li>
</ul>

<p><strong><span>Making the ROM and placing the files:</span></strong></p>

<p><span>The ROM file that MAME wants to boot from is a .zip file containing the first three files listed above. Compress them into one .zip archive named &#34;indy_4610.zip&#34; and place it into the &#34;roms&#34; directory in the main MAME directory. Place the irix65.chd into the main MAME directory.</span></p>

<p><strong><span>Booting the emulator and setting the PROM variables:</span></strong></p>

<p><span>Open a system shell in your host OS in the MAME directory (PowerShell on Windows, Terminal on macOS/Linux) and enter the following:</span></p>
<p><span>./mame64 indy_4610 -gio64_gfx xl24 -hard1 irix65.chd</span></p>

<p><span>Alternatively, the Indigo2 can be emulated. It&#39;s almost exactly the same as the Indy apart from the 150MHz R4400 CPU and its ability to run in a dual head configuration. The Indigo2 will run slower than the Indy, so this machine is only recommended if you want to try the dual graphics boards. Run it with this command:</span></p>
<p><span>./mame64 indigo2_4415 -gio64_gfx xl24 -gio64_exp0 xl24 -hard1 irix65.chd -window -numscreens 2</span></p>

<p><span>Wait a moment for hardware diagnostics to complete and then click the &#34;Stop for Maintenance&#34; button to go to the PROM setup. Next you will need to go to the Command Monitor and enter a few commands. They only need to be entered once. After that the system will boot normally.</span></p>

<p><span>Set the default Ethernet address:</span></p>
<p><span>setenv -f eaddr 08:00:69:12:34:56</span></p>
<p><span>Set the display to 1280x1024:</span></p>
<p><span>setenv monitor h</span></p>
<p><span>Boot into IRIX:</span></p>
<p><span>auto</span></p>

<p><strong><span>A few words about performance:</span></strong></p>
<p><span>Average performance for me is around 15% of a real SGI Indy. That&#39;s on my Core2 Quad workstation with a Q9550 running Debian 10. On that same machine running macOS Mojave I get around 8-10%. On my main desktop, a Hackintosh with an i5-2500s and macOS Mojave, I get around 10%. I compiled MAME myself for both systems. I&#39;m not sure why but Linux seems to be the best choice for a host OS when running IRIX in MAME. This still holds true as of MAME 0.218.</span></p>
<p><span>UPDATE: I have since purchased a new workstation and moved entirely to Debian Linux. This machine uses a Ryzen 5 3600. Performance has improved quite a bit. Average speeds are 25-35% in MAME 0.225 compiled from source.</span></p>

<p><strong><span>Site changelog (Dec 2020):</span></strong></p>
<p><span>Corrected some info on the hardware page.</span></p>
<p><span>Added Indigo2 instructions on the main page and slow boot fixes on the install guide. </span></p>
<p><span>Added a link for the IRIX 5.3 disk image.</span></p>
<p><span>Massive design overhaul. The site should be easier to navigate and more pleasant to look at now.</span></p>

<p><strong><span>Site changelog (June 2021):</span></strong></p>
<p><span>Added nicer fonts for better readability.</span></p>

<p><span>Last updated: June 29, 2021</span></p>
</div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 11:43:34 +0000</pubDate>
      <source>https://sgi.neocities.org/</source>
    </item>
    <item>
      <title>Am I stuck in a local maximum?</title>
      <link>https://blog.ploeh.dk/2021/08/09/am-i-stuck-in-a-local-maximum/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___blog_ploeh_dk_2021_08_09_am-i-stuck-in-a-local-maximum_/image.jpg" /> 
<div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>On long-standing controversies, biases, and failures of communication.</em>
	</p>
	<p>
		If you can stay out of politics, Twitter can be a great place to engage in robust discussions. I mostly follow and engage with people in the programming community, and every so often find myself involved in a discussion about one of several long-standing controversies. No, not the tabs-versus-spaces debate, but other debates such as functional versus object-oriented programming, dynamic versus static typing, or <a href="https://blog.ploeh.dk/2020/03/16/conways-law-latency-versus-throughput">oral versus written collaboration</a>.
	</p>
	<p>
		It happened again the past week, but while this article is a reaction, it&#39;s not about the specific debacle. Thus, I&#39;m not going to link to the tweets in question.
	</p>
	<p>
		These discussion usually leave me wondering why people with decades of industry experience seem to have such profound disagreements.
	</p>
	<h3 id="13c8dc8fbc9b4e26ba08bfeef9b61fd9">
		I might be wrong <a href="#13c8dc8fbc9b4e26ba08bfeef9b61fd9" title="permalink">#</a>
	</h3>
	<p>
		Increasingly, I find myself disagreeing with my heroes. This isn&#39;t a comfortable position. Could I be wrong?
	</p>
	<p>
		I&#39;ve definitely been wrong before. For example, in my article <a href="https://blog.ploeh.dk/2016/02/10/types-properties-software">Types + Properties = Software</a>, I wrote about type systems:
	</p>
	<blockquote>
		<p>&#34;To the far right, we have a hypothetical language with such a strong type system that, indeed, <em>if it compiles, it works.</em>&#34;</p>
	</blockquote>
	<p>
		<em>To the right</em>, in this context, means <em>more statically typed</em>. While the notion is natural, the sentence is uninformed. When I wrote the article, I <a href="https://www.goodreads.com/review/show/1731926050">hadn&#39;t yet read</a> Charles Petzold&#39;s excellent <a href="http://amzn.to/2n9MFGh">Annotated Turing</a>. Although I had heard about the <a href="https://en.wikipedia.org/wiki/Halting_problem">halting problem</a> before reading the book, I hadn&#39;t internalised it. I wasn&#39;t able to draw inferences based on that labelled concept.
	</p>
	<p>
		After I read the book, I&#39;ve come to understand that general-purpose static type system can never prove unequivocally that a generic program works. That&#39;s what <a href="https://en.wikipedia.org/wiki/Alonzo_Church">Church</a>, <a href="https://en.wikipedia.org/wiki/Alan_Turing">Turing</a>, and <a href="https://en.wikipedia.org/wiki/Kurt_G√∂del">G√∂del</a> proved.
	</p>
	<p>
		I&#39;ve been writing articles on this blog <a href="https://blog.ploeh.dk/2009/01/28/LivingInInterestingTimes">since January 2009</a>. To date, I&#39;ve published 582 posts. Some are bound to be misinformed, outdated, or just plain wrong. Due to the sheer volume, I make no consistent effort to retroactively monitor and correct my past self. (I&#39;m happy to engage with specific posts. If you feel that an old post is misleading, erroneous, or the like, please <a href="https://github.com/ploeh/ploeh.github.com#comments">leave a comment</a>.)
	</p>
	<p>
		For good measure, despite my failure to understand the implications of the halting problem, I&#39;m otherwise happy with the article series <a href="https://blog.ploeh.dk/2016/02/10/types-properties-software">Types + Properties = Software</a>. You shouldn&#39;t consider this particular example a general condemnation of it. It&#39;s just an example of a mistake I made. This time, I&#39;m aware of it, but there are bound to be plenty of other examples where I don&#39;t even realise it.
	</p>
	<h3 id="d7843f0140164eaf97a7724413d70d76">
		Heroes <a href="#d7843f0140164eaf97a7724413d70d76" title="permalink">#</a>
	</h3>
	<p>
		I don&#39;t have a formal degree in computer science. As so many others of my age, I began my software career by tinkering with computers and (later) programming. The first five years of my professional career, there wasn&#39;t much methodology to the way I approached software development. Self-taught often means that you have to learn everything the hard way.
	</p>
	<p>
		This changed when I first heard about test-driven development (TDD). I credit <a href="https://martinfowler.com">Martin Fowler</a> with that. Around the same time I also read <a href="http://amzn.to/XBYukB">Design Patterns</a>. Armed with those two techniques, I was able to rescue a failed software project and bring it to successful completion. I even received an (internal) award for it.
	</p>
	<p>
		While there&#39;s more to skilled programming than test-driven development and patterns, it wasn&#39;t a bad place to start. Where, before, I had nothing that even resembled a methodology, now I had a set of practices I could use. This gave me an opportunity to experiment and observe. A few years later, <a href="https://blog.ploeh.dk/2010/12/03/Towardsbetterabstractions">I&#39;d already started to notice some recurring beneficial patterns</a> in the code that I wrote, as well as <a href="https://blog.ploeh.dk/2010/12/22/TheTDDApostate">some limits of TDD</a>.
	</p>
	<p>
		Still, that was a decade where I voraciously read, attended conferences, and tried to learn from my heroes. I hope that they won&#39;t mind that I list them here:
		</p><ul>
			<li><a href="https://martinfowler.com">Martin Fowler</a></li>
			<li><a href="https://en.wikipedia.org/wiki/Kent_Beck">Kent Beck</a></li>
			<li><a href="https://en.wikipedia.org/wiki/Robert_C._Martin">Robert C. Martin</a></li>
			<li><a href="https://michaelfeathers.silvrback.com">Michael Feathers</a></li>
			<li><a href="https://dannorth.net">Dan North</a></li>
		</ul><p>
		Surely, there were others. I remember being a big fan of <a href="https://en.wikipedia.org/wiki/Don_Box">Don Box</a>, but he seems to have withdrawn from the public long time ago. There were also .NET trailblazers that I admired and tried to emulate. Later, I learned much from the early luminaries of <a href="https://fsharp.org">F#</a>. I&#39;m not going to list all the people I admire here, because the list could never be complete, and I don&#39;t wish to leave anyone feeling left out. Related to the point I&#39;m trying to make, all these other wonderful people give me less pause.
	</p>
	<p>
		There&#39;s a reason I list those particular heroes. I should include a few more of whom I wasn&#39;t aware in my formative years, but whom I&#39;ve since come to highly respect: <a href="https://twitter.com/marick">Brian Marick</a> and <a href="https://jessitron.com">Jessica Kerr</a>.
	</p>
	<p>
		Why do I mention these heroes of mine?
	</p>
	<h3 id="ae81dde11de94f9fb223cf06377a22c4">
		Bias <a href="#ae81dde11de94f9fb223cf06377a22c4" title="permalink">#</a>
	</h3>
	<p>
		Humans aren&#39;t as rational as we&#39;d like to think. We all have plenty of <a href="https://en.wikipedia.org/wiki/Cognitive_bias">cognitive biases</a>. I&#39;m aware of a few of mine, but I expect most of them to be hidden from me. Sometimes, it&#39;s easier to spot the bias in others. Perhaps, by spotting the bias in others, it reveals something about oneself?
	</p>
	<p>
		I increasingly find myself disagreeing with my heroes. One example is the long-standing controversy about static versus dynamic typing.
	</p>
	<p>
		I hope I&#39;m not misrepresenting anyone, but the heroes I enumerate above seem to favour dynamic typing over static typing - some more strongly than others. This worries me.
	</p>
	<p>
		These are people who&#39;ve taught me a lot; whose opinion I deeply respect, and yet I fail to grasp the benefit of dynamic typing. What are the benefits they gain from their preferred languages that I&#39;m blind to? What am I missing?
	</p>
	<p>
		Whenever I find myself disagreeing with my heroes, I can&#39;t help question my own judgment. Am I biased? Yes, obviously, but in which way? What bias prohibits me from seeing the benefits that are so obvious to them?
	</p>
	<p>
		It&#39;s too easy to jump to conclusions - to erect a dichotomy:
		</p><ul>
			<li>My heroes are right, and I&#39;m wrong</li>
			<li>My heroes are <em>all</em> wrong, and I&#39;m right</li>
		</ul><p>
		The evidence doesn&#39;t seem to support the latter conclusion, but if the first is true, I still fail to understand <em>why</em> I&#39;m wrong.
	</p>
	<p>
		I&#39;m hoping that there&#39;s a more nuanced position to take - that the above is a <a href="https://en.wikipedia.org/wiki/False_dilemma">false dichotomy</a>.
	</p>
	<h3 id="1dc21ee0532e4555ab621dfd32f31f12">
		What&#39;s the problem? <a href="#1dc21ee0532e4555ab621dfd32f31f12" title="permalink">#</a>
	</h3>
	<p>
		Perhaps we&#39;re really talking past each other. Perhaps we&#39;re trying to solve different problems, and thereby arrive at different solutions.
	</p>
	<p>
		I can only guess at the kinds of problems that my heroes think of when they prefer dynamic languages, and I don&#39;t want to misrepresent them. What I <em>can</em> do, however, is outline the kind of problem that I typically have in mind.
	</p>
	<p>
		I&#39;ve spent much of my career trying to balance <a href="https://blog.ploeh.dk/2019/03/04/code-quality-is-not-software-quality">sustainability</a> with correctness. I consider correctness as a prerequisite for all code. As <a href="http://amzn.to/1jos26M">Gerald Weinberg implies</a>, if a program doesn&#39;t have to work, anything goes. Thus, sustainability is a major focus for me: how do we develop software that can sustain our organisation now <em>and</em> in the future? How do we structure and organise code so that future change is possible?
	</p>
	<p>
		Whenever I get into debates, that&#39;s implicitly the problem on my mind. It&#39;d probably improve communication if I stated this explicitly going into every debate, but sometimes, I get dragged sideways into a debacle... I do, however, speculate that much disagreement may stem from such implicit assumptions. I bring my biases and implicit problem statements into any discussion. I consider it only human if my interlocutors do the same, but their biases and implicit problem understanding may easily be different than mine. What are they, I wonder?
	</p>
	<p>
		This seems to happen not only in the debate about dynamic versus static types. I get a similar sense when I discuss collaboration. Most of my heroes seem to advocate for high-band face-to-face collaboration, while <a href="https://blog.ploeh.dk/2020/03/16/conways-law-latency-versus-throughput">I favour asynchronous, written communication</a>. Indeed, I admit that my bias is speaking. I self-identify as a contrarian introvert (although, again, we should be careful not turning introversion versus extroversion into binary classification).
	</p>
	<p>
		Still, even when I try to account for my bias, I get the sense that my opponents and I may actually try to accomplish a common goal, but by addressing two contrasting problems.
	</p>
	<p>
		
	</p>
	<p>
		I think and hope that, ultimately, we&#39;re trying to accomplish the same goal: to deliver and sustain business capability.
	</p>
	<p>
		I do get the sense that the proponents of more team co-location, more face-to-face collaboration are coming at the problem from a different direction than I am. Perhaps the problem they&#39;re trying to solve is micro-management, red tape, overly bureaucratic processes, and a lack of developer autonomy. I can certainly see that if that&#39;s the problem, talking to each other is likely to improve the situation. I&#39;d recommend that too, in such a situation.
	</p>
	<p>
		Perhaps it&#39;s a local Danish (or perhaps Northern European) phenomenon, but that&#39;s not the kind of problem I normally encounter. Most organisations who ask for my help essentially have <em>no</em> process. Everything is ad hoc, nothing is written down, deployment is a manual process, and there are meetings and interruptions all the time. Since nothing is written down, decisions aren&#39;t recorded, so team members and stakeholders keep having the same meetings over and over. Again, little gets done, but for an entirely different reason than too much bureaucracy. I see this more frequently than too much red tape, so I tend to recommend that people start leaving behind some sort of written trail of what they&#39;ve been doing. Pull request reviews, for example, are great for that, and I see <a href="https://blog.ploeh.dk/2021/06/21/agile-pull-requests">no incongruity between agile and pull requests</a>.
	</p>
	<h3 id="37232ffbc5cf48e58ec773ca83046807">
		Shaped by scars <a href="#37232ffbc5cf48e58ec773ca83046807" title="permalink">#</a>
	</h3>
	<p>
		The inimitable <a href="https://twitter.com/richcampbell">Richard Campbell</a> has phrased our biases as the scars we collect during our careers. If you&#39;ve deleted the production database one too many times, you develop routines and practices to avoid doing that in the future. If you&#39;ve mostly worked in an organisation that stifled progress by subjecting you to <a href="https://en.wikipedia.org/wiki/Brazil_(1985_film)">Brazil</a>-levels of bureaucracy, it&#39;s understandable if you develop a preference for less formal methods. And if, like me, you&#39;ve mostly seen dysfunction manifest as a <em>lack</em> of beneficial practices, you develop a taste for written over oral communication.
	</p>
	<p>
		Does it go further than that? Are we also shaped by our successes, just like we are shaped by our scars?
	</p>
	<p>
		The first time I had professional success <em>with a methodology</em> was when I discovered TDD. This made me a true believer in TDD. I&#39;m still a big proponent of TDD, but since I learned what <a href="https://en.wikipedia.org/wiki/Algebraic_data_type">algebraic data types</a> <a href="https://blog.ploeh.dk/2016/11/28/easy-domain-modelling-with-types">can do</a> in terms of modelling, I see <a href="https://blog.ploeh.dk/2011/04/29/Feedbackmechanismsandtradeoffs">no reason to write a run-time test if I instead can get the compiler to enforce a rule</a>.
	</p>
	<p>
		In a recent discussion, some of my heroes expressed the opinion that they don&#39;t need <a href="https://blog.ploeh.dk/2021/06/07/abstruse-nomenclature">fancy</a> functional-programming concepts and features to write good code. I&#39;m sure that they don&#39;t.
	</p>
	<p>
		My heroes have written code for decades. While I <em>have</em> met bad programmers with decades of experience, most programmers who last that long ultimately become good programmers. I&#39;m not so worried about them.
	</p>
	<p>
		The people who need my help are typically younger teams. Statistically, there just aren&#39;t that many <a href="https://blog.ploeh.dk/2020/09/14/we-need-young-programmers-we-need-old-programmers">older programmers</a> around.
	</p>
	<p>
		When I recommend certain practices or programming techniques, those recommendations are aimed at anyone who care to listen. Usually, I find that the audience who engage with me is predominantly programmers with five to ten years of professional experience.
	</p>
	<h3 id="0d6d6bee68644d158deb5fa8cf478be7">
		Anecdotal evidence <a href="#0d6d6bee68644d158deb5fa8cf478be7" title="permalink">#</a>
	</h3>
	<p>
		This is a difficult discussion to have. I think that another reason that we keep returning to the same controversies is that we mostly rely on <a href="https://martinfowler.com/bliki/AnecdotalEvidence.html">anecdotal evidence</a>. As we progress through our careers, we observe what works and what doesn&#39;t, but it&#39;s likely that <a href="https://en.wikipedia.org/wiki/Confirmation_bias">confirmation bias</a> makes us remember the results that we already favour, whereas we conveniently forget about the outcomes that don&#39;t fit our preferred narrative.
	</p>
	<p>
		Could we settle these discussions with more science? Alas, <a href="https://blog.ploeh.dk/2020/05/25/wheres-the-science">that&#39;s difficult</a>.
	</p>
	<p>
		I can&#39;t think of anything better, then, than keep having the same discussions over and over. I try hard to overcome my biases to understand the other side, and now and then, I learn something that I find illuminating. It doesn&#39;t seem to be a particularly efficient way to address these difficult questions, but I don&#39;t know what else to do. What&#39;s the alternative to discussion? To <em>not</em> discuss? To <em>not</em> exchange ideas?
	</p>
	<p>
		That seems worse.
	</p>
	<h3 id="ea7ed446c9094c1985f585223fbddb26">
		Conclusion <a href="#ea7ed446c9094c1985f585223fbddb26" title="permalink">#</a>
	</h3>
	<p>
		In this essay, I&#39;ve tried to come to grips with an increasing cognitive incongruity that I&#39;m experiencing. I find myself disagreeing with my heroes on a regular basis, and that makes me uncomfortable. Could it be that I&#39;m erecting an echo chamber for myself?
	</p>
	<p>
		The practices that I follow and endorse work well for me, but could I be stuck in a local maximum?
	</p>
	<p>
		This essay has been difficult to write. I&#39;m not sure that I&#39;ve managed to convey my doubts and motivations. Should I have named my heroes, only to describe how I disagree with them? Will it be seen as aggressive?
	</p>
	<p>
		I hope not. I&#39;m writing about my heroes with reverence and gratitude for all that they&#39;ve taught me. I mean no harm.
	</p>
	<p>
		At the same time, I&#39;m struggling with reconciling that they rarely seem to agree with me these days. Perhaps they never did.
	</p>
</div></div>]]></content:encoded>
      <pubDate>Mon, 09 Aug 2021 09:57:25 +0000</pubDate>
      <source>https://blog.ploeh.dk/2021/08/09/am-i-stuck-in-a-local-maximum/</source>
    </item>
    <item>
      <title>FairyTailor: A Multimodal Generative Framework for Storytelling</title>
      <link>https://github.com/EdenBD/MultiModalStory-demo</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text">
<h3><a id="user-content-human-in-the-loop-visual-story-co-creation" aria-hidden="true" href="#human-in-the-loop-visual-story-co-creation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Human-in-the-loop visual story co-creation.</h3>
<p>Users can create a cohesive children&#39;s story by weaving generated texts and retrieved images with their input.
With co-creation, writers contribute their creative thinking, while generative models contribute to their constant workflow.
FairyTailor adds another modality and modifies the text generation process to help producing a coherent and creative story.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/EdenBD/MultiModalStory-demo/blob/master/framework.png"></a></p>
<h2><a id="user-content-set-up-development" aria-hidden="true" href="#set-up-development"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Set-up (development)</h2>
<p>After cloning the repository:</p>
<h3><a id="user-content-client-vue-26" aria-hidden="true" href="#client-vue-26"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Client (<a href="https://vuejs.org/" rel="nofollow">Vue 2.6</a>)</h3>
<p>Install and check that the client compiles:</p>
<div data-snippet-clipboard-copy-content="cd client
npm i
npm run build
"><pre><code>cd client
npm i
npm run build
</code></pre></div>
<h3><a id="user-content-backend-fastapi" aria-hidden="true" href="#backend-fastapi"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Backend (<a href="https://fastapi.tiangolo.com/" rel="nofollow">FASTAPI</a>)</h3>
<p>Install and activate the environment (conda provided):</p>
<div data-snippet-clipboard-copy-content="conda env create -f environment.yml
conda activate MultiModalStory
"><pre><code>conda env create -f environment.yml
conda activate MultiModalStory
</code></pre></div>
<p>Install environment globally in the directory:</p>
<div data-snippet-clipboard-copy-content="pip install -e .
pip install git+https://github.com/openai/CLIP.git
"><pre><code>pip install -e .
pip install git+https://github.com/openai/CLIP.git
</code></pre></div>
<p>After installation run:</p>
<div data-snippet-clipboard-copy-content="python -m spacy download en_core_web_sm
"><pre><code>python -m spacy download en_core_web_sm
</code></pre></div>
<p>In python terminal:</p>
<div data-snippet-clipboard-copy-content="nltk.download(&#39;wordnet&#39;)
nltk.download(&#39;sentiwordnet&#39;)
nltk.download(&#39;averaged_perceptron_tagger&#39;)
"><pre><code>nltk.download(&#39;wordnet&#39;)
nltk.download(&#39;sentiwordnet&#39;)
nltk.download(&#39;averaged_perceptron_tagger&#39;)
</code></pre></div>
<h3><a id="user-content-large-data-management-dvc" aria-hidden="true" href="#large-data-management-dvc"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Large Data Management (<a href="https://dvc.org/" rel="nofollow">dvc</a>)</h3>
<p>Our large data files are stored on IBM&#39;s Cloud Object Storage, and to pull data files from that platform you will use a special, read-only <code>.dvc/config</code> file.</p>

<p>Which will pull:</p>
<ul>
<li>backend/outputs (five preset stories)</li>
<li>backend/story_generator/downloaded (transformers)</li>
<li>client/public/unsplash25k (styled images)</li>
</ul>
<h3><a id="user-content-running-the-framework-during-developemnt" aria-hidden="true" href="#running-the-framework-during-developemnt"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Running the framework during developemnt</h3>
<p>Client:</p>

<p>Backend (with server auto reload):</p>
<div data-snippet-clipboard-copy-content="uvicorn backend.server:app --reload --reload-dir backend
"><pre><code>uvicorn backend.server:app --reload --reload-dir backend
</code></pre></div>
<p>Open the uvicorn server <code>localhost:8000</code> in your web browser</p>
<h2><a id="user-content-modifications-ideas" aria-hidden="true" href="#modifications-ideas"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Modifications Ideas:</h2>
<h3><a id="user-content-new-huggingface-transformer" aria-hidden="true" href="#new-huggingface-transformer"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>New huggingface transformer</h3>
<ul>
<li>Place the transformer in <code>backend/story_generator/downloaded directory</code>.</li>
<li>Update the current model path by changing the constant <code>FINETUNED_GPT2_PATH</code> in <code>backend/story_generator/constants.py</code>.</li>
</ul>
<h3><a id="user-content-new-images-folder" aria-hidden="true" href="#new-images-folder"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>New images folder</h3>
<ul>
<li>Replace the folder <code>client/public/unsplash25k/sketch_images1024</code> with yours.</li>
<li>Update the current path by changing the constant <code>IMAGE_PATH</code> in <code>client/src/components/Constants.js</code>.</li>
</ul>
<h3><a id="user-content-api-functionalities" aria-hidden="true" href="#api-functionalities"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>API functionalities</h3>
<ul>
<li>Add functions to the backend endpoint at <code>backend/server/main.py</code>.</li>
<li>Update <code>client/src/js/api/mainApi.js</code> to call the backend endpoint from the client.</li>
<li>Update the corresponding user components in <code>client/src/components</code>.</li>
</ul>
</article>
        </div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 02:23:11 +0000</pubDate>
      <source>https://github.com/EdenBD/MultiModalStory-demo</source>
    </item>
    <item>
      <title>Bloom Filters: More than a space-efficient hashmap</title>
      <link>https://boyter.org/posts/bloom-filter/</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div>
<p>A bloom filter is one of those data structures you are probably already aware of, or have at least heard about. For those looking for a simple recap, they are a probabilistic data structure which can be used to determine if something is in a set or not, giving a slight chance of returning a false positive result for some checks but while using less space than a full hashmap.</p>
<p>What you may not know is that while you can use them as a space efficient hash/dictionary there are other use cases you might not be aware of.</p>
<h2 id="implementation-of-a-bloom-filter">Implementation of a bloom filter</h2>
<p>However before going though usage though, lets take a quick moment to build one. A lot of people seem to lack this understanding and assume that bloom filters are more complex or mysterious than they actually are.</p>
<p>Turns out a bloom filter is actually really easy to build if you don‚Äôt mind doing it inefficiently (at least at first). I am going to implement one using JavaScript because anyone reading this can follow along using the browser console. Why? Well I find a simple bit of code tends to be mostly unambiguous and communicates meaning quite well.</p>
<p>The first thing you need is a hash function. Ideally for a bloom filter you want to use something like Murmur3 and FNV-1a because you want the hash to be as fast as possible and yet have a good distribution. See <a href="https://softwareengineering.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed">this excellent stackexchange</a> question and the first comment for more detail.</p>
<p>However because JavaScript in the browser does not come with hash, here is a port of the Java string hash which gets us moving without needing to implement anything too difficult. You can copy and paste the below into your console, which will add a hash function to strings.</p>
<div><pre><code data-lang="javascript"><span>// Primitive hash function that for a string returns a positive 32 bit int
</span><span>// Do not use in production, use murmur3 or fnv1
</span><span></span>Object.<span>defineProperty</span>(String.<span>prototype</span>, <span>&#39;hashCode&#39;</span>, {
  <span>value</span><span>:</span> <span>function</span>() {
    <span>var</span> <span>hash</span> <span>=</span> <span>0</span>, <span>i</span>, <span>chr</span>;
    <span>for</span> (<span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>this</span>.<span>length</span>; <span>i</span><span>++</span>) {
      <span>chr</span>   <span>=</span> <span>this</span>.<span>charCodeAt</span>(<span>i</span>);
      <span>hash</span>  <span>=</span> ((<span>hash</span> <span>&lt;&lt;</span> <span>5</span>) <span>-</span> <span>hash</span>) <span>+</span> <span>chr</span>;
      <span>hash</span> <span>|=</span> <span>0</span>; <span>// Convert to 32bit integer
</span><span></span>    }
    <span>return</span> Math.<span>abs</span>(<span>hash</span>);
  }
});
</code></pre></div>
<p>So with that done lest create our filter. At it‚Äôs heart the filter itself is just an array of bits. You only need to store two states for every entry in the array. Note that in many languages using a boolean is not backed by a bit so using boolean‚Äôs as your backing array might not be as efficient as you expect. You tend to need to use a bitset implementation or bit packing into an integer for efficiency but that‚Äôs out of the scope of what we need here.</p>
<p>Lets create a bloom filter which contains 16 boolean‚Äôs to represent out bits and then hash two words and put them into the filter.</p>
<div><pre><code data-lang="javascript"><span>// start out our bloom filter out with 16 0&#39;s indicating its empty
</span><span></span><span>var</span> <span>bloom</span> <span>=</span> [<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>];

<span>// add some words to the filter using a single hash
</span><span>// we use % to convert our 32 bit number into one of 16 values
</span><span>// for the length of our bloom filter
</span><span></span><span>bloom</span>[<span>&#34;something&#34;</span>.<span>hashCode</span>() <span>%</span> <span>bloom</span>.<span>length</span>] <span>=</span> <span>1</span>;
<span>bloom</span>[<span>&#34;another&#34;</span>.<span>hashCode</span>() <span>%</span> <span>bloom</span>.<span>length</span>] <span>=</span> <span>1</span>;
</code></pre></div>
<p>After running the above your bloom filter should have 2 bits set and look like the following,</p>
<div><pre><code data-lang="javascript">[<span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>1</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>1</span>, <span>0</span>]
</code></pre></div>
<p>As you can see positions 7 and 15 in this filter are now set. In order to check if something is in the filter, you do the same hash operations and check the value rather than setting. So if we want to see if something is in the filter,</p>
<div><pre><code data-lang="javascript"><span>if</span> (<span>bloom</span>[<span>&#34;something&#34;</span>.<span>hashCode</span>() <span>%</span> <span>bloom</span>.<span>length</span>] <span>==</span> <span>1</span>) {
  <span>// something might be in the filter
</span><span></span>}
</code></pre></div>
<p>Note the comment that says it ‚Äúmight‚Äù be in the filter due to the false positive properties of a bloom filter.</p>
<p>The above is pretty much all you need to get started with bloom filters. For a real implementation swap out for a better hash function, in fact use two of them with salts in order to get more than 2 hashes which you will need to drive down the false positive rates. You also need to increase the size of the filter itself for anything non trivial. Use <a href="https://hur.st/bloomfilter/">this calculator</a> in order to determine how large a filter you need to achieve your desired false positive rate.</p>
<p>Note that the false positive rate is actually a feature, and there are situations where you might want to drive it up or down to achieve your goal.</p>
<p>If you are looking for bit more detail about how to implement one here is a gist <a href="https://gist.github.com/boyter/0cffa9ff8e2e7259d455594d744f1164">https://gist.github.com/boyter/0cffa9ff8e2e7259d455594d744f1164</a> which has a bit more details and examples.</p>
<p>Note that bloom filters don‚Äôt have any inbuilt limit to how many terms you can add. You can add as many terms to them as you want, but at some point it drives the false positive rate close to 100% making the filter effectively useless, so knowledge of how many terms you are going to store in it up front is a requirement of using them effectively.</p>
<h2 id="interesting-use-cases-of-bloom-filters">Interesting use cases of bloom filter‚Äôs</h2>
<p>Bloom filters can be so much more than a space efficient hashmap! Lets go though some of the more and less common use cases for them.</p>
<p>The first and most obvious is to use it as a lookup cache. This is the same idea as a hashmap but more space efficient. Consider running a video/music e-store where you pull detailed information about the movie or song from a back-end database or cache. With a bloom filter fronting it you could use a smallish amount of memory to filter requests to the back-end by only looking where you are confident that a result exists. Because each key you need to store can fit into ~10 bits of data you can trade a small amount of memory to avoid overloading your backend systems.</p>
<p>You can also use bloom filters to mitigate cache busting attacks on your website. For any website its fairly common to use various cache levels in order to prevent multiple requests hitting your back-end and overloading it. However most websites also allow parameters either in the URL itself or via GET parameters. Consider a e-commerce site where you have many product id‚Äôs, and by fiddling with the URL someone can iterate though them all. While you can cache results for each product, what happens if someone malicious decides to request items for which there is no product? You have to check your back-end in order to actually check if its there, which at scale can case contention on your system. You can use bloom filters to hold all of the product id‚Äôs, and only hit the back-end for a full lookup if the filter says the item actually appears.</p>
<p>Akami also uses bloom filters to avoid one hit wonder items filling the cache. There is little benefit in populating your cache for items that are only requested once, and the long tail of the internet is very large. Akami realised this and used a bloom filter to determine if the item in question had been requested before and only after being requested the second time would the item be cached. A similar technique can be used by any cache system to avoid populating your cache with rarely requested items.</p>
<p>Spelling checkers were also a use case for bloom filters back in the day when you really had to worry about your memory usage. At ~10 bits per term you could pack a lot of words into limited memory, with fast lookups to determine if a word was a real word or not.</p>
<p>One thing to consider is the properties of a bloom filter. Because you hash keys multiple times through a non reversible function, it‚Äôs possible to then share your bloom filter at the end as a way to share information that you hold without sharing the information itself. You can even make it impossible to brute force to get the information back because you can configure your filter to have a higher error rate and swamp the attacker with false positives as they brute force things.</p>
<p>Consider a distributed social network where I want to have two people determine if there is any overlap in their contact lists. I want to do so without having to share the lists because of privacy reasons. You could build a filter for each users contacts, and swap them. Then check against the filter in order to determine if we have an overlap, without the possibility of you being able to reconstruct either list even were you to hold even both filters. Assuming I am worried about someone getting a copy of these filters I can also drive up the false positive rate to thwart the potential attack.</p>
<p>You can extend this idea further as well. Say I want to determine the overlap between two user‚Äôs social circles. Build two filters of the same size containing each users friends. Then compare the bits of the two filters. The more overlap the more shared bits. This also applies to finding distance between words or sentences, and it works regardless of how long the text is as its driven more closely by the words/terms and not how often they appear. You split the document into ngrams (say trigrams), add each into your filter and compare them the same way. The more overlapping bits the closer they are.</p>
<p>The idea of sharing reasonable proof of ownership is an interesting use case for bloom filters. Say for example you have obtained a list of hashed passwords and want to prove you have them without transmitting the hashes themselves. You could encode them all into a bloom filter configured with a high error rate.</p>
<p>You can also use bloom filters to make a search engine. I first read about this idea on Hacker News <a href="https://www.stavros.io/posts/bloom-filter-search-engine/">https://www.stavros.io/posts/bloom-filter-search-engine/</a> with the idea being you build a bloom filter per document you want to index and then loop over each filter to check if terms are in each. This works at a small scale of a few thousand documents.</p>
<p>However this is a fairly primitive version of a bloom filter search engine. You can do much better as it turns out.</p>
<p>The nice thing about bloom filters is that you can query them using bitwise operations. In effect if you store each document in a filter of the same size, you end up with a collection of filters in a block that looks like the below for 3 documents with 8 bit bloom filters for each one.</p>
<pre><code>document1 10111010
document2 01100100
document3 00100111
</code></pre><p>This is great because say you have search for a term with the hash <code>10010000</code> (note that the search filter must be as long as the documents you are searching) you can then step through each document applying bitwise OR operations to see if the result is zero and if not it means we might have a matching document. Bitwise operations are very fast on any CPU so the actual check is effectively free from a CPU point of view. The catch being you need to step through every part of memory for your whole corpus.</p>
<p>There is a way to reduce this however. If you rotate the bit vectors you can then just check those which match your search term hash bit positions, so documents move from being rows to columns like so.</p>
<p>In the below document 1 is now represented by column 1.</p>
<pre><code>term1 100
term2 010
term3 111
term4 100
term5 100
term6 011
term7 101
term8 001
</code></pre><p>Then given our search <code>10010000</code> you would look at the bits for term1 and term4 (as bit position 1 and 4 are set). Then OR them together and you get <code>1</code> indicating that document 1 is a possible match for the search. It also reduced the number of bits we looked at for this query from 24 to 9. This is more impressive when you have larger filters (which you would expect).</p>
<p>It looks like this,</p>
<pre><code>search 10010000

positions 1 and 4 are set so we want to use those

take from our filter positions term1 and term4

term1 100
term4 100

then OR them together

100

which means document1 which was in the first column might be a match

</code></pre><p>What‚Äôs really cool about this search technique is that because bitwise operations are so fast you can consider them free you end up being limited only by memory bandwidth, which means you can actually work out how long each search will take based on the number of documents in your index per machine.</p>
<p>However part of the bing.com managed to improve this algorithm even more. It‚Äôs well out of the scope of this document, but it involves using what they call higher ranked rows where they logically OR half of the filter against itself to reduce memory access. Along with the ability to shard filter lengths to different machines (possible because of scale) they are able to reduce memory access to a level where they can run thousands of searches on each machine per second. Its a very cool collection of techniques.</p>
<p>The links you need to get started on how Bing does this are below,</p>
<ul>
<li><a href="http://bitfunnel.org/">http://bitfunnel.org/</a></li>
<li><a href="https://www.youtube.com/watch?v=1-Xoy5w5ydM">https://www.youtube.com/watch?v=1-Xoy5w5ydM</a></li>
<li><a href="https://www.youtube.com/watch?v=80LKF2qph6I">https://www.youtube.com/watch?v=80LKF2qph6I</a></li>
<li><a href="https://www.clsp.jhu.edu/events/mike-hopcroft-microsoft/">https://www.clsp.jhu.edu/events/mike-hopcroft-microsoft/</a></li>
<li><a href="https://danluu.com/bitfunnel-sigir.pdf">https://danluu.com/bitfunnel-sigir.pdf</a></li>
</ul>
<p>They are worth looking at!</p>
<h2 id="similar-data-structures">Similar data structures</h2>
<p>There are modified versions of bloom filters, as well as other similar structures.</p>
<p>Variants of bloom filters include compressed bloom filters, expiring and counting bloom filters. They use less memory, expire old keys and record how many times keys were added (allowing removal if you implement it correctly at the expense of memory).</p>
<p>Another similar one is the cuckoo filter which works in a similar way to a bloom filter, except it has a inbuilt limit after which it will no longer add items, can delete items and has some different memory characteristics.</p>
<h2 id="conclusion">Conclusion</h2>
<p>So started as me wanting to implement bitfunnel myself turned into a longer than I expected look at bloom filters in general. I have to admit they are now my new favourite data structure (wow‚Ä¶ how much of a nerd do you have to be to have one of those) supplanting my previous which was the vector space. While I don‚Äôt really have any use for bloom filters in much of what I do from day to day I‚Äôm hoping like <a href="https://boyter.org/posts/media-clipping-using-ffmpeg-with-cache-eviction-2-random-for-disk-caching-at-scale/">https://boyter.org/posts/media-clipping-using-ffmpeg-with-cache-eviction-2-random-for-disk-caching-at-scale/</a> 2 random cache eviction I might get to use it one of these days.</p>

</div></div>]]></content:encoded>
      <pubDate>Mon, 09 Aug 2021 05:46:26 +0000</pubDate>
      <source>https://boyter.org/posts/bloom-filter/</source>
    </item>
    <item>
      <title>Memory Bandwidth</title>
      <link>https://fgiesen.wordpress.com/2017/04/11/memory-bandwidth/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___fgiesen_wordpress_com_2017_04_11_memory-bandwidth_/image.jpg" /> 
<div id="readability-page-1" class="page"><div>
								<p>Absolute memory bandwidth figures tend to look fairly large, especially for GPUs. This is deceptive. It‚Äôs much more useful to relate memory bandwidth to say the number of clock cycles or instructions being executed, to get a feel for what you can (and can‚Äôt) get away with.</p>
<p>Let‚Äôs start with a historical example: the MOS 6502, first released in 1975 ‚Äì 42 years ago, and one of the key chips in the microcomputer revolution. A 6502 was typically clocked at 1MHz and did a 1-byte memory access essentially every clock cycle, which are nice round figures to use as a baseline. A typical 6502 instruction took 3-5 cycles; some instructions with more complex addressing modes took longer, a few were quicker, and there was some overlapping of the fetch of the next instruction with execution of the current instruction, but no full pipelining like you‚Äôd see in later (and more complex) workstation and then microcomputer CPUs, starting around the mid-80s. That gives us a baseline of 1 byte/cycle and let‚Äôs say about 4 bytes/instruction memory bandwidth on a 40-year old CPU. A large fraction of that bandwidth went simply into fetching instruction bytes.</p>
<p>Next, let‚Äôs look at a recent (as of this writing) and relatively high-end desktop CPU. An Intel Core i7-7700K, has <a href="http://techreport.com/review/31179/intel-core-i7-7700k-kaby-lake-cpu-reviewed/4">about 50GB/s</a> and 4 cores, so if all 4 cores are under equal load, they get about 12.5GB/s each. They also clock at about 4.2GHz (it‚Äôs safe to assume that with all 4 cores active and hitting memory, none of them is going to be in ‚Äúturbo boost‚Äù mode), so they come in just under 3 bytes per cycle of memory bandwidth. Code that runs OK-ish on that CPU averages around 1 instruction per cycle, well-optimized code around 3 instructions per cycle. So well-optimized code running with all cores busy has about 1 byte/instruction of available memory bandwidth. Note that we‚Äôre 40 years of Moore‚Äôs law scaling later and the available memory bandwidth per instruction has gone <em>down</em> substantially. And while the 6502 is a 8-bit microprocessor doing 8-bit operations, these modern cores can execute multiple (again, usually up to three) 256-bit SIMD operations in one cycle; if we treat the CPU like a GPU and count each 32-bit vector lane as a separate ‚Äúthread‚Äù (appropriate when running SIMT/SPMD-style code), then we get 24 ‚Äúinstructions‚Äù executed per cycle and a memory bandwidth of about 0.125 bytes per cycle per ‚ÄúSIMT thread‚Äù, or less unwieldy, one byte every 8 ‚Äúinstructions‚Äù.</p>
<p>It gets even worse if we look at GPUs. Now, GPUs generally look like they have insanely high memory bandwidths. But they also have a lot of compute units and (by CPU standards) extremely small amounts of cache per ‚Äúthread‚Äù (invocation, lane, CUDA core, pick your terminology of choice). Let‚Äôs take the (again quite recent as of this writing) NVidia GeForce GTX 1080Ti as an example. It has (as per <a href="https://en.wikipedia.org/wiki/GeForce_10_series">Wikipedia</a>) a memory bandwidth of 484GB/s, with a stock core clock of about 1.48GHz, for an overall memory bandwidth of about 327 bytes/cycle for the whole GPU. However, this GPU has 28 ‚ÄúShading Multiprocessors‚Äù (roughly comparable to CPU cores) and 3584 ‚ÄúCUDA cores‚Äù (SIMT lanes). We get about 11.7 bytes/cycle per SM, so about 4x what the i7-7700K core gets; that sounds good, but each SM drives 128 ‚ÄúCUDA cores‚Äù, each corresponding to a thread in the SIMT programming model. Per <em>thread</em>, we get about 0.09 bytes of memory bandwidth per cycle ‚Äì or perhaps less awkward at this scale, one byte every 11 instructions.</p>
<p>That, in short, is why everything keeps getting more and larger caches, and why even desktop GPUs have <a href="http://www.realworldtech.com/tile-based-rasterization-nvidia-gpus/">quietly started using tile-based rendering</a> approaches (or just announced so <a href="https://www.pcper.com/reviews/Graphics-Cards/AMD-Vega-GPU-Architecture-Preview-Redesigned-Memory-Architecture/Primitive-Sh">openly</a>). Absolute memory bandwidths in consumer devices have gone up by several orders of magnitude from the ~1MB/s of early 80s home computers, but available compute resources have grown much faster still, and the only way to stop bumping into bandwidth limits all the time is to make sure your workloads have reasonable locality of reference so that the caches can do their job.</p>
<p>Final disclaimer: bandwidth is only one part of the equation. Not considered here is memory latency (and that‚Äôs a topic for a different post). The good news is absolute DRAM latencies have gone down since the 80s ‚Äì by a factor of about 4-5 or so. The bad news is that clock rates have increased by about a factor of 3000 since then ‚Äì oops. CPUs generally hit much lower memory latencies than GPUs (and are designed for low-latency operation in general) whereas GPUs are all about throughput. When CPU code is limited by memory, it is more commonly due to latency than bandwidth issues (running out of independent work to run while waiting for a memory access). GPU kernels have tons of runnable warps at the same time, and are built to schedule something else during the wait; running on GPUs, it‚Äôs much easier to run into bandwidth issues.</p>
											</div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 01:05:42 +0000</pubDate>
      <source>https://fgiesen.wordpress.com/2017/04/11/memory-bandwidth/</source>
    </item>
    <item>
      <title>Summary of the semantics of inline in C and C++</title>
      <link>https://lists.llvm.org/pipermail/llvm-dev/2021-August/152031.html</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page">
   
    <b>David Chisnall via llvm-dev</b> 
    <a href="mailto:llvm-dev%40lists.llvm.org?Subject=Re%3A%20%5Bllvm-dev%5D%20Inline%20function%20not%20eventually%20inlined%20is%20removed&amp;In-Reply-To=%3Ceaa6a67a-b818-d451-3f13-84006c0ab934%40cl.cam.ac.uk%3E" title="[llvm-dev] Inline function not eventually inlined is removed">llvm-dev at lists.llvm.org
       </a><!--beginarticle-->





<!--endarticle-->
    
    




</div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 09:41:37 +0000</pubDate>
      <source>https://lists.llvm.org/pipermail/llvm-dev/2021-August/152031.html</source>
    </item>
    <item>
      <title>JPL&#39;s Plan for the Next Mars Helicopter</title>
      <link>https://spectrum.ieee.org/the-next-mars-helicopter</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><template>
                    <p>
	Looking to such specialized nervous systems as a model for artificial intelligence may prove just as valuable, if not more so, than studying the human brain. Consider the brains of those ants in your pantry. Each has some 250,000 neurons. Larger insects have closer to 1 million. In my research at Sandia National Laboratories in Albuquerque, I study the brains of one of these larger insects, the dragonfly. I and my colleagues at Sandia, a national-security laboratory, hope to take advantage of these insects&#39; specializations to design computing systems optimized for tasks like intercepting an incoming missile or following an odor plume. By harnessing the speed, simplicity, and efficiency of the dragonfly nervous system, we aim to design computers that perform these functions faster and at a fraction of the power that conventional systems consume.
</p><p>
<strong>Looking to a dragonfly</strong> as a harbinger of future computer systems may seem counterintuitive. The developments in artificial intelligence and machine learning that make news are typically algorithms that mimic human intelligence or even surpass people&#39;s abilities. Neural networks can already perform as well‚Äîif not better‚Äîthan people at some specific tasks, such as detecting cancer in medical scans. And the potential of these neural networks stretches far beyond visual processing. The computer program<a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/deepmind-achieves-holy-grail" rel="noopener noreferrer" target="_blank"> <u>AlphaZero</u></a>, trained by self-play, is the best Go player in the world. Its sibling AI,<a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/deepminds-ai-shows-itself-to-be-a-worldbeating-world-builder" rel="noopener noreferrer" target="_blank"> <u>AlphaStar</u></a>, ranks among the best<em> Starcraft II </em>players.
</p><p>
	Such feats, however, come at a cost. Developing these sophisticated systems requires massive amounts of processing power, generally available only to select institutions with the fastest supercomputers and the resources to support them. And the energy cost is off-putting.
	<a href="https://arxiv.org/abs/1906.02243" rel="noopener noreferrer" target="_blank"> <u>Recent estimates</u></a> suggest that the carbon emissions resulting from developing and training a natural-language processing algorithm are greater than those produced by four cars over their lifetimes.
</p><p>

<small placeholder="Add Photo Caption...">It takes the dragonfly only about 50 milliseconds to begin to respond to a prey&#39;s maneuver. If we assume 10 ms for cells in the eye to detect and transmit information about the prey, and another 5 ms for muscles to start producing force, this leaves only 35 ms for the neural circuitry to make its calculations. Given that it typically takes a single neuron at least 10 ms to integrate inputs, the underlying neural network can be at least three layers deep.</small>
</p><p>
	But does an artificial neural network really need to be large and complex to be useful? I believe it doesn&#39;t. To reap the benefits of neural-inspired computers in the near term, we must strike a balance between simplicity and sophistication.
</p><p>
	Which brings me back to the dragonfly, an animal with a brain that may provide precisely the right balance for certain applications.
</p><p>
	If you have ever encountered a dragonfly, you already know how fast these beautiful creatures can zoom, and you&#39;ve seen their incredible agility in the air. Maybe less obvious from casual observation is their excellent hunting ability: Dragonflies successfully capture up to 95 percent of the prey they pursue, eating hundreds of mosquitoes in a day.
</p><p>
	The physical prowess of the dragonfly has certainly not gone unnoticed. For decades, U.S. agencies have experimented with using dragonfly-inspired designs for surveillance drones. Now it is time to turn our attention to the brain that controls this tiny hunting machine.
</p><p>
<strong>While dragonflies</strong> may not be able to play strategic games like Go, a dragonfly does demonstrate a form of strategy in the way it aims ahead of its prey&#39;s current location to intercept its dinner. This takes calculations performed extremely fast‚Äîit typically takes a dragonfly just 50 milliseconds to start turning in response to a prey&#39;s maneuver. It does this while tracking the angle between its head and its body, so that it knows which wings to flap faster to turn ahead of the prey. And it also tracks its own movements, because as the dragonfly turns, the prey will also appear to move.
</p><p>

<small placeholder="Add Photo Caption...">The model dragonfly reorients in response to the prey&#39;s turning. The smaller black circle is the dragonfly&#39;s head, held at its initial position. The solid black line indicates the direction of the dragonfly&#39;s flight; the dotted blue lines are the plane of the model dragonfly&#39;s eye. The red star is the prey&#39;s position relative to the dragonfly, with the dotted red line indicating the dragonfly&#39;s line of sight.</small>
</p><p>
	So the dragonfly&#39;s brain is performing a remarkable feat, given that the time needed for a single neuron to add up all its inputs‚Äîcalled its membrane time constant‚Äîexceeds 10 milliseconds. If you factor in time for the eye to process visual information and for the muscles to produce the force needed to move, there&#39;s really only time for three, maybe four, layers of neurons, in sequence, to add up their inputs and pass on information
</p><p>
	Could I build a neural network that works like the dragonfly interception system? I also wondered about uses for such a neural-inspired interception system. Being at Sandia, I immediately considered defense applications, such as missile defense, imagining missiles of the future with onboard systems designed to rapidly calculate interception trajectories without affecting a missile&#39;s weight or power consumption. But there are civilian applications as well.
</p><p>
	For example, the algorithms that control self-driving cars might be made more efficient, no longer requiring a trunkful of computing equipment. If a dragonfly-inspired system can perform the calculations to plot an interception trajectory, perhaps autonomous drones could use it to 
	<em>avoid</em> collisions. And if a computer could be made the same size as a dragonfly brain (about 6 cubic millimeters), perhaps insect repellent and mosquito netting will one day become a thing of the past, replaced by tiny insect-zapping drones!
</p><p>
<strong>To begin to answer</strong> these questions, I created a simple neural network to stand in for the dragonfly&#39;s nervous system and used it to calculate the turns that a dragonfly makes to capture prey. My three-layer neural network exists as a software simulation. Initially, I worked in Matlab simply because that was the coding environment I was already using. I have since ported the model to Python.
</p><p>
	Because dragonflies have to see their prey to capture it, I started by simulating a simplified version of the dragonfly&#39;s eyes, capturing the minimum detail required for tracking prey. Although dragonflies have two eyes, it&#39;s generally accepted that they do not use stereoscopic depth perception to estimate distance to their prey. In my model, I did not model both eyes. Nor did I try to match the resolution of
	<a href="https://www.brisbaneinsects.com/brisbane_insects/DragonflyHead.htm" rel="noopener noreferrer" target="_blank"> <u>a</u></a><u> dragonfly eye</u>. Instead, the first layer of the neural network includes 441 neurons that represent input from the eyes, each describing a specific region of the visual field‚Äîthese regions are tiled to form a 21-by-21-neuron array that covers the dragonfly&#39;s field of view. As the dragonfly turns, the location of the prey&#39;s image in the dragonfly&#39;s field of view changes. The dragonfly calculates turns required to align the prey&#39;s image with one (or a few, if the prey is large enough) of these &#34;eye&#34; neurons. A second set of 441 neurons, also in the first layer of the network, tells the dragonfly which eye neurons should be aligned with the prey&#39;s image, that is, where the prey should be within its field of view.
</p><p>

<small placeholder="Add Photo Caption...">The model dragonfly engages its prey.</small>
</p><p>
	Processing‚Äîthe calculations that take input describing the movement of an object across the field of vision and turn it into instructions about which direction the dragonfly needs to turn‚Äîhappens between the first and third layers of my artificial neural network. In this second layer, I used an array of 194,481 (21<sup>4</sup>) neurons, likely much larger than the number of neurons used by a dragonfly for this task. I precalculated the weights of the connections between all the neurons into the network. While these weights could be learned with enough time, there is an advantage to &#34;learning&#34; through evolution and preprogrammed neural network architectures. Once it comes out of its nymph stage as a winged adult (technically referred to as a teneral), the dragonfly does not have a parent to feed it or show it how to hunt. The dragonfly is in a vulnerable state and getting used to a new body‚Äîit would be disadvantageous to have to figure out a hunting strategy at the same time. I set the weights of the network to allow the model dragonfly to calculate the correct turns to intercept its prey from incoming visual information. What turns are those? Well, if a dragonfly wants to catch a mosquito that&#39;s crossing its path, it can&#39;t just aim at the mosquito. To borrow from what hockey player Wayne Gretsky once said about pucks, the dragonfly has to aim for where the mosquito is going to be. You might think that following Gretsky&#39;s advice would require a complex algorithm, but in fact the strategy is quite simple: All the dragonfly needs to do is to maintain a constant angle between its line of sight with its lunch and a fixed reference direction.
</p><p>
	Readers who have any experience piloting boats will understand why that is. They know to get worried when the angle between the line of sight to another boat and a reference direction (for example due north) remains constant, because they are on a collision course. Mariners have long avoided steering such a course, known as parallel navigation, to avoid collisions
</p><p>
	Translated to dragonflies, which 
	<em>want</em> to collide with their prey, the prescription is simple: keep the line of sight to your prey constant relative to some external reference. However, this task is not necessarily trivial for a dragonfly as it swoops and turns, collecting its meals. The dragonfly does not have an internal gyroscope (that we know of) that will maintain a constant orientation and provide a reference regardless of how the dragonfly turns. Nor does it have a magnetic compass that will always point north. In my simplified simulation of dragonfly hunting, the dragonfly turns to align the prey&#39;s image with a specific location on its eye, but it needs to calculate what that location should be.
</p><p>
	The third and final layer of my simulated neural network is the motor-command layer. The outputs of the neurons in this layer are high-level instructions for the dragonfly&#39;s muscles, telling the dragonfly in which direction to turn. The dragonfly also uses the output of this layer to predict the effect of its own maneuvers on the location of the prey&#39;s image in its field of view and updates that projected location accordingly. This updating allows the dragonfly to hold the line of sight to its prey steady, relative to the external world, as it approaches.
</p><p>
	It is possible that biological dragonflies have evolved additional tools to help with the calculations needed for this prediction. For example, dragonflies have specialized sensors that measure body rotations during flight as well as head rotations relative to the body‚Äîif these sensors are fast enough, the dragonfly could calculate the effect of its movements on the prey&#39;s image directly from the sensor outputs or use one method to cross-check the other. I did not consider this possibility in my simulation.
</p><p>
	To test this three-layer neural network, I simulated a dragonfly and its prey, moving at the same speed through three-dimensional space. As they do so my modeled neural-network brain &#34;sees&#34; the prey, calculates where to point to keep the image of the prey at a constant angle, and sends the appropriate instructions to the muscles. I was able to show that this simple model of a dragonfly&#39;s brain can indeed successfully intercept other bugs, even prey traveling along curved or semi-random trajectories. The simulated dragonfly does not quite achieve the success rate of the biological dragonfly, but it also does not have all the advantages (for example, impressive flying speed) for which dragonflies are known.
</p><p>
<strong>More work is needed </strong>to determine whether this neural network is really incorporating all the secrets of the dragonfly&#39;s brain. Researchers at the Howard Hughes Medical Institute&#39;s Janelia Research Campus, in Virginia, have developed tiny backpacks for dragonflies that can measure electrical signals from a dragonfly&#39;s nervous system while it is in flight and transmit these data for analysis. The backpacks are small enough not to distract the dragonfly from the hunt. Similarly, neuroscientists can also record signals from individual neurons in the dragonfly&#39;s brain while the insect is held motionless but made to think it&#39;s moving by presenting it with the appropriate visual cues, creating a dragonfly-scale virtual reality.
</p><p>
	Data from these systems allows neuroscientists to validate dragonfly-brain models by comparing their activity with activity patterns of biological neurons in an active dragonfly. While we cannot yet directly measure individual connections between neurons in the dragonfly brain, I and my collaborators will be able to infer whether the dragonfly&#39;s nervous system is making calculations similar to those predicted by my artificial neural network. That will help determine whether connections in the dragonfly brain resemble my precalculated weights in the neural network. We will inevitably find ways in which our model differs from the actual dragonfly brain. Perhaps these differences will provide clues to the shortcuts that the dragonfly brain takes to speed up its calculations.
</p><p>

<small placeholder="Add Photo Caption...">This backpack that captures signals from electrodes inserted in a dragonfly&#39;s brain was created by Anthony Leonardo, a group leader at Janelia Research Campus.</small><small placeholder="Add Photo Credit...">Anthony Leonardo/Janelia Research Campus/HHMI</small>
</p><p>
<strong>Dragonflies could also teach us</strong> how to implement &#34;attention&#34; on a computer. You likely know what it feels like when your brain is at full attention, completely in the zone, focused on one task to the point that other distractions seem to fade away. A dragonfly can likewise focus its attention. Its nervous system turns up the volume on responses to particular, presumably selected, targets, even when other potential prey are visible in the same field of view. It makes sense that once a dragonfly has decided to pursue a particular prey, it should change targets only if it has failed to capture its first choice. (In other words, using parallel navigation to catch a meal is not useful if you are easily distracted.)
</p><p>
	Even if we end up discovering that the dragonfly mechanisms for directing attention are less sophisticated than those people use to focus in the middle of a crowded coffee shop, it&#39;s possible that a simpler but lower-power mechanism will prove advantageous for next-generation algorithms and computer systems by offering efficient ways to discard irrelevant inputs
</p><p>
	The advantages of studying the dragonfly brain do not end with new algorithms; they also can affect systems design. Dragonfly eyes are fast, operating at the equivalent of 200 frames per second: That&#39;s several times the speed of human vision. But their spatial resolution is relatively poor, perhaps just a hundredth of that of the human eye. Understanding how the dragonfly hunts so effectively, despite its limited sensing abilities, can suggest ways of designing more efficient systems. Using the missile-defense problem, the dragonfly example suggests that our antimissile systems with fast optical sensing could require less spatial resolution to hit a target.
</p><p>
<strong>The dragonfly isn&#39;t the only insect</strong> that could inform neural-inspired computer design today. Monarch butterflies migrate incredibly long distances, using some innate instinct to begin their journeys at the appropriate time of year and to head in the right direction. We know that monarchs rely on the position of the sun, but navigating by the sun requires keeping track of the time of day. If you are a butterfly heading south, you would want the sun on your left in the morning but on your right in the afternoon. So, to set its course, the butterfly brain must therefore read its own circadian rhythm and combine that information with what it is observing.
</p><p>
	Other insects, like the Sahara desert ant, must forage for relatively long distances. Once a source of sustenance is found, this ant does not simply retrace its steps back to the nest, likely a circuitous path. Instead it calculates a direct route back. Because the location of an ant&#39;s food source changes from day to day, it must be able to remember the path it took on its foraging journey, combining visual information with some internal measure of distance traveled, and then
	<a href="https://www.amazon.com/Desert-Navigator-Journey-R%C3%BCdiger-Wehner/dp/0674045882" rel="noopener noreferrer" target="_blank"> <u>calculate its return route</u></a> from those memories.
</p><p>
	While nobody knows what neural circuits in the desert ant perform this task, researchers at the Janelia Research Campus have identified neural circuits that allow the fruit fly to
	<a href="https://www.nature.com/articles/nature14446" rel="noopener noreferrer" target="_blank"> <u>self-orient using visual landmarks</u></a>. The desert ant and monarch butterfly likely use similar mechanisms. Such neural circuits might one day prove useful in, say, low-power drones.
</p><p>
	And what if the efficiency of insect-inspired computation is such that millions of instances of these specialized components can be run in parallel to support more powerful data processing or machine learning? Could the next AlphaZero incorporate millions of antlike foraging architectures to refine its game playing? Perhaps insects will inspire a new generation of computers that look very different from what we have today. A small army of dragonfly-interception-like algorithms could be used to control moving pieces of an amusement park ride, ensuring that individual cars do not collide (much like pilots steering their boats) even in the midst of a complicated but thrilling dance.
</p><p>
	No one knows what the next generation of computers will look like, whether they will be part-cyborg companions or centralized resources much like Isaac Asimov&#39;s Multivac. Likewise, no one can tell what the best path to developing these platforms will entail. While researchers developed early neural networks drawing inspiration from the human brain, today&#39;s artificial neural networks often rely on decidedly unbrainlike calculations. Studying the calculations of individual neurons in biological neural circuits‚Äîcurrently only directly possible in nonhuman systems‚Äîmay have more to teach us. Insects, apparently simple but often astonishing in what they can do, have much to contribute to the development of next-generation computers, especially as neuroscience research continues to drive toward a deeper understanding of how biological neural circuits work.
</p><p>
	So next time you see an insect doing something clever, imagine the impact on your everyday life if you could have the brilliant efficiency of a small army of tiny dragonfly, butterfly, or ant brains at your disposal. Maybe computers of the future will give new meaning to the term &#34;hive mind,&#34; with swarms of highly specialized but extremely efficient minuscule processors, able to be reconfigured and deployed depending on the task at hand. With the advances being made in neuroscience today, this seeming fantasy may be closer to reality than you think.
</p><p>
<em>This article appears in the August 2021 print issue as &#34;Lessons From a Dragonfly&#39;s Brain.&#34;</em>
</p>
                    
                    </template></div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 18:21:46 +0000</pubDate>
      <source>https://spectrum.ieee.org/the-next-mars-helicopter</source>
    </item>
    <item>
      <title>DevOps, SRE, and Platform Engineering</title>
      <link>https://iximiuz.com/en/posts/devops-sre-and-platform-engineering/</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a name="cut"></a>
I compiled this thread on Twitter, and all of a sudden, it got quite some attention. So here, I&#39;ll try to elaborate on the topic a bit more. Maybe it would be helpful for someone trying to make a career decision or just improve general understanding of the most hyped titles in the industry.</p>
<blockquote><p lang="en" dir="ltr">DevOps, SRE, and Platform Engineering (thread)</p>‚Äî Ivan Velichko (@iximiuz) <a href="https://twitter.com/iximiuz/status/1421435412157972480?ref_src=twsrc%5Etfw">July 31, 2021</a></blockquote> 
<p>During my career, I used to work in teams and companies where as a developer, I would push code to a repository and just hope that it would work well when some mythical system administrator would eventually take it to production. I also was in setups where I would need to provision bare-metal servers on Monday, figure out the deployment strategy on Tuesday, write some business logic on Wednesday, roll it out myself on Thursday, and firefight a production incident on Friday. And all this without even being aware of the existence of fancy titles like DevOps or SRE engineer.</p>
<p>But then people around me started talking DevOps and SRE, comparing them with each other, and compiling <a href="https://github.com/dastergon/awesome-sre">awesome lists</a> of <a href="https://github.com/AcalephStorage/awesome-devops">resources</a>. New job opportunities began emerging, and I quickly jumped into the SRE train. So, below is my experience of being involved in all things SRE and Platform Engineering from the former Software Developer standpoint. And yeah, I think it&#39;s applicable primarily for companies where the product is some sort of a web-facing service. This is the kind of company I spent ten years working for. People doing embedded software or implementing databases probably live in totally different realities.</p>
<h2 id="what-is-development">What is Development</h2>
<p>This one is the simplest to explain. Development - is about application programming, i.e., writing the business logic of your main product. This is the only activity among the three ones being discussed here that directly makes money for the company.</p>
<blockquote data-conversation="none"><p lang="en" dir="ltr">The only one that makes for a company is of course sales, everything else is expenditure :)</p>‚Äî ‚ä•n…πq√∂S◊ü…ê åƒ± û (@slavadotcom) <a href="https://twitter.com/slavadotcom/status/1421541971051663371?ref_src=twsrc%5Etfw">July 31, 2021</a></blockquote> 

<p>IMO, development is super hot! As a developer, you quickly start thinking that you are the most important person around. Without your code, there is nothing. But apparently, just writing code often isn&#39;t enough. The code needs to be delivered to production and executed there.</p>
<p>I&#39;d been carrying the Software Developer (or Software Engineer) title since the very beginning of my career in 2011. And I still remember the pain quite vividly - I always wished to have control over deploying my code. And I rarely had it. Instead, there would be some obscure procedure when someone, usually not even your senior colleague, would have access to production servers and deploy the code there for you. So, if after pushing the changes to the repository, you got unlucky enough to notice a bug only on the live version of your service, you&#39;d need to beg for an extra rollout. It most definitely sucked.</p>
<h2 id="what-is-devops">What is DevOps</h2>
<p>I&#39;ll not even try to quote the official definition here. Instead, I&#39;ll share the first-hand experience. For me, DevOps was a cultural shift giving development teams more control over shipping code to production. The implementation could vary. I&#39;ve been in setups where developers would just have <code>sudo</code> on production servers. But probably the most common approach is to provide development teams with some sort of CI/CD pipelines.</p>
<p>In an ideal GitOps world, developers would still be just pushing code to repositories. However, there would be a magical button somewhere at the team&#39;s disposal that would put the new version on live or maybe even provision a new piece of infrastructure to cover the new requirements.</p>
<p>The original idea of DevOps is probably much broader than just that. But from what I see in the job descriptions, what I hear from recruiters trying to hunt me for a DevOps position, and what I managed to gather from my fellow colleagues carrying the DevOps engineer title, most of the time, it&#39;s about creating an efficient way to deploy stuff produced by Development. In more advanced setups, DevOps may also be concerned with other things improving the Development velocity. But DevOps itself is never concerned with the actual application business logic.</p>
<h2 id="what-is-sre">What is SRE</h2>
<p>There is a <a href="https://sre.google/books/">excellent series of books by Google</a> explaining the idea of the Site Reliability Engineering and, what&#39;s even more important for me, sharing some real tech practices conducted by Google SREs. In particular, it says that SRE is just one of the ways to implement the DevOps culture - <code>class SRE implements DevOps {}</code>.</p>
<p>This explanation didn&#39;t really help me much. But what was even more puzzling, subconsciously, I always felt excited while reading SRE job descriptions and got bored quickly by the DevOps ones... So, there was clearly a difference but, for a long time, I couldn&#39;t distill it.</p>
<p>Of course, that&#39;s just about my personal preferences, but whenever someone mentions configuring a CI/CD pipeline, I always got depressed. And the DevOps job descriptions nowadays are full of such responsibilities. Don&#39;t get me wrong, CI/CD pipelines are amazing! I&#39;m always glad when I have a chance to use one. But setting them up isn&#39;t a thing I enjoy the most. On the contrary, when someone asks me to jump in and take a look at a bleeding production, be it chasing a bug, a memory leak, or performance degradation, I&#39;m always more than just happy to help.</p>
<p>Developing code and shipping it to production still doesn&#39;t give you the full picture. Someone needs to keep the production alive and healthy! And that&#39;s how I see the place of SRE in my model of the world.</p>
<p>Google&#39;s SRE book focuses on monitoring and alerting, defining SLOs of your services and tracking error budgets, incident response and postmortems. These are the things one would need to apply to make the production reliable. Facebook has a famous Production Engineer role, but it&#39;s pretty hard to distinguish it from a typical SRE role, judging only by the job description.</p>
<p>Here is also a great tweet that kind of confirms my feeling that the primary focus of SRE is production.</p>
<blockquote><p lang="en" dir="ltr">My very simplified answer when someone says what is the difference between SRE and DevOps. </p>‚Äî Tammy Bryant Butow ‚öì (@tambryantbutow) <a href="https://twitter.com/tambryantbutow/status/1405158127369129989?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote> 

<p>And one more:</p>
<blockquote data-conversation="none"><p lang="en" dir="ltr">I like it! My typical answer is:</p>‚Äî Gary Pochron (@garypochron) <a href="https://twitter.com/garypochron/status/1405160330909552646?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote> 

<p>So, DevOps keeps production fresh. SRE keeps production healthy.</p>
<h2 id="what-is-platform-engineering">What is Platform Engineering</h2>
<p>When I used to be the only engineer in a startup, a decent part of my job was to turn some generic resources I&#39;d rent from the infrastructure provider into something more tailored for the company&#39;s needs. So, I had a bunch of scripts to provision a new server, some understanding of how to provide network connectivity between our servers in different data centers, some skills to replicate the production setup on staging, and maybe even write one or two daemons to help me with log collection. I didn&#39;t really understand it, but these things constituted our Platform.</p>
<p>Joining a much bigger company and starting consuming infra-related resources brought me to a realization that there is a third area of focus that might be quite close to DevOps and SRE. It&#39;s called Platform Engineering.</p>
<p>From my understanding, Platform Engineering focuses on developing an ecosystem that can be efficiently used from the Dev, Ops, and SRE standpoints.</p>
<p>There might be quite some code writing in Platform Engineering. Or, it could be mostly about configuring things. But again, it&#39;s not about the primary business logic of your product - it&#39;s about making some basic infrastructure more suitable for the day-to-day needs.</p>
<blockquote><p lang="en" dir="ltr">Platform Engineering is not about infrastructure development.</p>‚Äî Ivan Pedrazas (@ipedrazas) <a href="https://twitter.com/ipedrazas/status/1421566465627594758?ref_src=twsrc%5Etfw">July 31, 2021</a></blockquote> 

<p>To be honest, I don&#39;t see a contradiction between my way of seeing Platform Engineering and the explanation from this tweet. Development needs infrastructure to run the code. So, if Platform Engineering is about enabling others to do whatever they want to do, at least in part, it should be concerned with infrastructure development.</p>
<p>I have a feeling that in a bigger setup, when a company would have thousands of bare-metal servers in its own data centers, a Platform Engineering would start from managing this fleet of machines. So, some sort of inventory software might need to be installed or even developed internally. Installing operating systems and basic packages on the servers being provisioned would probably also fall into the Platform Engineering responsibility.</p>
<p>Luckily, clouds made Platform Engineering operating on much higher layers. All the basic fleet management tasks are already solved for you. And even orchestration of your workloads is solved by projects like Kubernetes or AWS ECS. However, the solution is quite generic, while your teams are likely to deploy pretty similar microservices. So, providing them with a default project template that would be integrated with the company&#39;s metrics and logs collection subsystems would make things moving much faster.</p>
<h2 id="whats-about-titles">What&#39;s about titles?</h2>
<p>So far, I was deliberately avoiding talking about roles and titles. Development, Operations, SRE, and Platform Engineering for me are about areas of focus. And to a much lesser extent about titles. One person can be a Dev this week, then an Ops on the next week, and an SRE on the week after.</p>
<p>From my experience, the separation between Dev, Ops, SRE, and PE becomes more apparent when the company size gets bigger. A bigger company size usually means more specialists and fewer generalists. That&#39;s how you end up with dedicated SRE teams and a Platform Engineering department. But of course, it&#39;s not a strict rule. For instance, with my SRE title, I spent like a year doing all things true SRE (SLO, monitoring, alerting, incident response) and then transitioned into Platform Engineering, where I do more infra development than traditional SRE. YMMV.</p>
<h2 id="where-security-goes">Where Security goes?</h2>
<blockquote data-conversation="none"><p lang="en" dir="ltr">Awesome , but where the security team gets involved from DevOps and SRE prospective.</p>‚Äî Saliou Fall (@S4L1OU) <a href="https://twitter.com/S4L1OU/status/1421585485277941761?ref_src=twsrc%5Etfw">July 31, 2021</a></blockquote> 

<p>That&#39;s a very good question! But I don&#39;t have a simple answer. For me, a reasonable approach is to make security a cross-cutting theme in all Dev, Ops, SRE, and PE. Different security concerns can be addressed on different layers using different tools. For instance, Development could be concerned with preventing SQL injections while Platform folks could harden the networking by configuring some fancy cilium policies.</p>
<h2 id="instead-of-conclusion">Instead of conclusion</h2>
<p>Don&#39;t forget, all the things above are IMO üòâ</p>
</div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 03:58:55 +0000</pubDate>
      <source>https://iximiuz.com/en/posts/devops-sre-and-platform-engineering/</source>
    </item>
    <item>
      <title>Germany to Stop Free Covid-19 Tests in October</title>
      <link>https://www.reuters.com/business/healthcare-pharmaceuticals/germany-stop-free-covid-19-tests-report-2021-08-09/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___www_reuters_com_business_healthcare-pharmaceuticals_germany-stop-free-covid-19-tests-report-2021-08-09_/image.jpg" /> 
<div id="readability-page-1" class="page"><p id="primary-image-caption" data-testid="primary-image-caption">People queue to receive a vaccine against the coronavirus disease (COVID-19), during a night of vaccinations with music, at the Arena Treptow vaccination centre in Berlin, Germany, August 9, 2021. John Macdougall/Pool via REUTERS</p><div><p data-testid="paragraph-0">BERLIN, Aug 9 (Reuters) - Germany wants to end free coronavirus tests in October, the RND group of newspapers reported on Monday, citing a draft proposal to be discussed by Chancellor Angela Merkel and leaders of the country&#39;s 16 states.</p><p data-testid="paragraph-1">The government made the tests free for all in March to make a gradual return to normal life possible after a lockdown to break a third wave of COVID-19.</p><p data-testid="paragraph-2">But with 55% of the population fully vaccinated there have been calls to stop spending taxpayers&#39; money on a subsidised scheme that now mainly benefits those who are not yet vaccinated even though vaccines are available for all.</p><p data-testid="paragraph-3">&#34;Given that all vaccination is immediately available to all citizens, it is no longer justifiable that the federal government and therefore taxpayers cover the cost of all tests,&#34; RND cited from a draft proposal.</p><p data-testid="paragraph-4">Less than seven weeks before a federal election, Merkel and state leaders will discuss measures to keep rising new infections spurred by the Delta variant in check without instituting lockdowns.</p><p data-testid="paragraph-5">The draft stipulates that people who cannot be vaccinated for health reasons like expectant women and children under 18 will continue to be entitled to subsidised tests.</p><p data-testid="paragraph-6">An exact date in October for curtailing the program has not yet been made, RND added.</p><p data-testid="paragraph-7">Germany has recorded more than 3,000 cases on each of the past five days but with almost 63% of the population having received at least one shot the government is hoping lockdowns could be avoided.</p><p><span>Reporting by Joseph Nasr; editing by Jonathan Oatis</span></p><p>Our Standards: <a href="https://www.thomsonreuters.com/en/about-us/trust-principles.html" target="_blank">The Thomson Reuters Trust Principles.</a></p></div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 07:39:36 +0000</pubDate>
      <source>https://www.reuters.com/business/healthcare-pharmaceuticals/germany-stop-free-covid-19-tests-report-2021-08-09/</source>
    </item>
    <item>
      <title>TikTok overtakes Facebook as most downloaded app</title>
      <link>https://asia.nikkei.com/Business/Technology/TikTok-overtakes-Facebook-as-world-s-most-downloaded-app</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>TOKYO -- A global survey of¬†downloads in 2020 shows TikTok, a video-sharing app developed in China, on top of¬†the list of social media providers for the first time since the study was first conducted in 2018.</p><p>As concern for personal privacy grows, Telegram, a messaging app that can delete posts, also ranked high during a year when¬†social media use has been driven up by the COVID-19 pandemic.¬†</p><p>ByteDance launched the¬†international version of TikTok in 2017, and has since overtaken Facebook, WhatsApp, Instagram and Facebook Messenger -- all of which are Facebook owned --¬†in downloads, even in the U.S.</p><p>&#34;I¬†enjoy¬†videos by artists who aren&#39;t performing live anymore because of the pandemic,&#34; said Nina, 37, of Portland in the U.S.</p><div><p><span></span><span><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon--cross" href="#icon--cross"></use><image src="https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fasia.nikkei.com%2Fassets%2Fimages%2Ficon--cross.2d18c509.svg?format=png&amp;source=nar-cms&amp;tint=%23ffffff"></image></svg></span></p></div><p>Some believe that¬†personal information shared with¬†TikTok is not secure. In 2020, former President Donald Trump called on the company to sell off its U.S. operations or be banned. The app&#39;s popularity nevertheless grew during the pandemic, when it became the leading download in Europe, South America and the U.S.</p><p>Joe Biden, Trump&#39;s successor,¬†withdrew the presidential executive order, but uncertainties remain elsewhere. While The Financial Times reported on Sunday that ByteDance has revived plans to go public in the coming months, a spokesperson told Nikkei Asia on Monday that the article was &#34;inaccurate,&#34; insisting the company¬†has no current plans for a stock market listing.</p><p>China&#39;s¬†Likee, a TikTok¬†competitor, creates¬†short videos that many companies use for marketing, and it ranked eighth in the latest global download league.</p><p>At the start of 2021, WhatsApp announced that it would share messaging data¬†with Facebook relating to interactions between users and companies. Although¬†WhatsApp promised to protect information about communications between¬†friends and family, some users moved over to¬†other apps.</p><p>Bucking that trend, Telegram, a messaging app originally developed in Russia but now based in Germany, moved up to seventh place. Users can adjust the settings to delete messages automatically after a specified period.¬†The app was a particular hit with protesters in¬†Hong Kong and Thailand who wanted to operate under the state radar.¬†</p><p>Users have previously been mostly guided by the convenience and ease of use of¬†free social media,¬†but¬†privacy has become more of a concern lately. &#34;Companies&#39; approach to¬†handling data will become a deciding factor in consumer¬†choices,&#34; Shinichi Yamaguchi, an associate professor at the Center for Global Communications, told Nikkei.</p><p>Discord, a voice calling app that moved up to seventh place, has benefited from people&#39;s need to isolate¬†during the pandemic.¬†The app is popular among gamers for chatting when online, and¬†has been funded by Sony Group. Social media services have primed the pump for greater outside investment and corporate involvement.¬†</p><p>Domestic apps dominate the¬†China market where¬†many from¬†overseas are closed out. Three in China&#39;s top ten are for short video posting, including Douyin, the predecessor of TikTok, which¬†ByteDance still provides in China.</p><p>Douyin is popular for music, dancing and general¬†entertainment content. Douyin Volcano¬†Edition -- also from ByteDance -- provides¬†videos from¬†everyday life, including people falling down in the street and other mishaps.¬†</p><p>Tencent&#39;s WeShow focuses on video games, and includes celebrities playing games live.</p><div><p><span></span><span><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon--cross" href="#icon--cross"></use><image src="https://www.ft.com/__origami/service/image/v2/images/raw/https%3A%2F%2Fasia.nikkei.com%2Fassets%2Fimages%2Ficon--cross.2d18c509.svg?format=png&amp;source=nar-cms&amp;tint=%23ffffff"></image></svg></span></p></div><p>Among newcomers, Little Red Book (RED, Xiaohongshu)¬†was fifth most downloaded. It combines social networking with¬†e-commerce, mainly¬†cosmetics, fashion, dietary supplements and¬†consumer goods. In China, word-of-mouth is important, especially among women. &#34;I read reviews of cosmetics and other products every day,&#34; said a female user¬†in Beijing.</p><p>Online networking¬†is particularly¬†popular among Generation Z, or Zoomers, born in the second half of the 1990s.¬†Soul, the number ten app, uses artificial intelligence to analyze users&#39; personalities through psychological tests. It then¬†matches them to others¬†with similar profiles. A major difference from traditional matchmaking services is that people are not selected based on a picture¬†of their face. Consumers use the app for matchmaking or simply¬†to find new friends.</p><p>Short videos have gained¬†popularity in other parts of Asia. Snack Video,¬†an app from China&#39;s Kuaishou, was the sixth most downloaded in Asia-Pacific.¬†Its main feature¬†is live commerce¬†-- a combination of video broadcasting and online shopping. Companies have used it to grow sales during the COVID-19¬†pandemic.</p><p>Line, which is especially popular in Thailand, was pushed out of the global rankings by strong¬†competition from new players. In¬†Japan, however,¬†it moved from number two to the top spot. Line is working to make itself a super app by enhancing its payment settlement function.</p><p>During the pandemic,¬†Osaka prefectural authorities used Line for vaccine¬†reservations, and it is widely used by other¬†local governments in Japan to disseminate information, making it¬†increasingly a part of the infrastructure of daily.¬†However, a subcontractor in China was discovered to be able to view Japanese user data, making security more of a concern.¬†</p><p>The U.S. matchmaking app Pairs was originally developed in Japan, where it rose to eighth place. With the pandemic ongoing, it offers a remote dating function that was added in April 2020 to enable people to maintain romantic links from home.¬†&#34;I started using the service because I couldn&#39;t have any real encounters with people during the pandemic,&#34; said one male office worker in his twenties.</p><p>&#34;The total viewing time for TikTok in the U.S. and U.K. is longer than that for YouTube, and short videos will continue to attract attention,&#34; Chuzen Kin, marketing manager at App Annie, an app market intelligence company,¬†told Nikkei as he reviewed trends. &#34;In terms of content, music and comedies are becoming more popular.&#34; Vocal social media is also on the up,¬†with Clubhouse taking off in Japan and the U.S. in early 2021.</p></div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 19:21:14 +0000</pubDate>
      <source>https://asia.nikkei.com/Business/Technology/TikTok-overtakes-Facebook-as-world-s-most-downloaded-app</source>
    </item>
    <item>
      <title>Essence ‚Äì An Operating System</title>
      <link>https://gitlab.com/nakst/essence</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___gitlab_com_nakst_essence/image.jpg" /> 
<div id="readability-page-1" class="page"><div>
<div role="menu">
<section>
<h5>Download source code</h5>
<div>
<div>
<p><a rel="nofollow" download="" href="https://gitlab.com/nakst/essence/-/archive/master/essence-master.zip">zip</a>
<a rel="nofollow" download="" href="https://gitlab.com/nakst/essence/-/archive/master/essence-master.tar.gz">tar.gz</a>
<a rel="nofollow" download="" href="https://gitlab.com/nakst/essence/-/archive/master/essence-master.tar.bz2">tar.bz2</a>
<a rel="nofollow" download="" href="https://gitlab.com/nakst/essence/-/archive/master/essence-master.tar">tar</a>
</p></div>

</div>
</section>

</div>
</div></div>]]></content:encoded>
      <pubDate>Mon, 09 Aug 2021 23:21:29 +0000</pubDate>
      <source>https://gitlab.com/nakst/essence</source>
    </item>
    <item>
      <title>The Problem with Ethereum</title>
      <link>https://tomerstrolight.medium.com/the-problem-with-ethereum-af9692f4af95</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___tomerstrolight_medium_com_the-problem-with-ethereum-af9692f4af95/image.jpg" /> 
<div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a rel="noopener" href="https://tomerstrolight.medium.com/?source=post_page-----af9692f4af95--------------------------------"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><p></p></div></figure><p id="316d">People ask me, ‚ÄúCan you explain why you dislike Ethereum and recommend against buying or holding it?‚Äù</p><p id="5ce0">Here is my explanation.</p><p id="c296">Imagine starting a new community. The community will be called ‚ÄúEthereum‚Äù. A number of promises will be made to encourage people to join this community:</p><p id="f864">There will be a number of different roles in this community.</p><p id="ec99">There will be a <strong>working class</strong> ‚Äî a group that does the work the community needs to operate it. They will get paid for their work, but they will also have to pay their own expenses. Let‚Äôs call this group the <strong>miners</strong>.</p><p id="0389">T<span id="rmm"><span id="rmm">h</span></span>ere will be a <strong>wealthy class</strong> ‚Äî the group that participates in the founding. Let‚Äôs call this group the <strong>initial coin offering participants</strong>.</p><p id="d2e1">There will be a <strong>ruling class ‚Äî a group that makes the rules</strong>. This will be a small group. Let‚Äôs call this group the <strong>core developers</strong>, and/or the Foundation, and/or Vitalik. <strong>This is a subset of the wealthy class</strong>.</p><p id="f10c">And there will also be a <strong>class that are subjects of the rules and the results of the work</strong>. This last will be the most numerous. We‚Äôll call this group the <strong>Etherians</strong>.</p><p id="14d2">Now, when this new community is constituted, certain <strong>promises are made</strong>. One of the promises made is that <strong>the need for the working class, the miners, will go away at some point</strong> in the near future. This promise is even enforced by a rule that makes work impossible after a time. <strong>This is Ethereum‚Äôs promise of a switch from Proof-of-Work to Proof-of-Stake, enforced by a rule called the ‚Äúdifficulty bomb‚Äù which would bring about an ‚Äúice age‚Äù.</strong> This code, to eventually make mining impossible, is put into the constitution, or code, of the community.</p><p id="d525"><strong>Another promise</strong> made is that the computer code in this community is its law.<strong> ‚ÄúCode is law.‚Äù</strong></p><p id="7bc3">Now it so happens that early on, a mistake is made and <strong>a lot of the wealthy class‚Äô money risks being lost</strong> in that mistake. This is the <a href="https://www.gemini.com/cryptopedia/the-dao-hack-makerdao" rel="noopener nofollow">infamous case of ‚Äúthe DAO</a>‚Äù, a smart contract that raised $150 million worth of Eth from its early investors and which was hacked to have most of its money drained by the hacker. Excuses are made and <strong>explanations are given as to why in this particular case an exception needs to be made to the ‚ÄúCode is Law‚Äù promise</strong>, but that this exception will be a one-off. The change is made to reverse the mistake: The ruling class proposes changes to the rules so that the wealthy class will benefit at the expense of the person who took advantage of the mistake. It seems mostly reasonable at the time.</p><p id="573e"><strong>A few people</strong>, mostly from the class of subjects, the Ethereans<strong>, complain that the ‚Äúcode is law‚Äù promise should not be broken.</strong> However, they are told to leave the community and create a new one called ‚ÄúEthereum Classic‚Äù, which they do.</p><p id="c75f">Meanwhile, in the Ethereum community, the ruling class enacts new rules (a hard fork) to undo the mistake. <strong>The wealthy class get all their money back and are granted an exemption from the enforcement of the law of ‚ÄúCode is Law‚Äù for this one instance,</strong> with the promise of never doing it again.</p><p id="271c">A little while later it is determined that some rules need to be changed for maintenance and optimization purposes. Another hard fork. This was not unexpected.</p><p id="4eca">But at the same time something previously unexpected does happen:</p><p id="08db"><strong>One of the promises made when the community was constituted was that the working class would be paid five units of currency for each unit of work they completed. That is 5 Eth per block. But the ruling class now feels that‚Äôs too much because it amounts to a lot of value for the work. So the ruling class changes the rule of 5 Eth per block to 4 Eth per block. </strong>This reduces the working class‚Äô compensation by 20%.</p><p id="a9ed"><strong>Some people</strong>, particularly those in the working class,<strong> complain. They are told they can take this pay cut or leave and go work someplace else.</strong> The work is still profitable, however and many remain.</p><p id="8eba">Now, <strong>it is not just the ruling class alone that issues this ultimatum of ‚Äòtake the pay cut or leave‚Äô</strong>. Most everyone else in both the wealthy class and class of subjects likes the change too. Why? This change reduces the creation of new currency units that they weren‚Äôt themselves earning (because they weren‚Äôt doing any work). Thus, it gives them a larger share of the total monetary pie after the change than they would have had if the change didn‚Äôt take place.</p><p id="9d3c"><strong>No moral questions are seriously considered about whether changing this rule is a breach of the promise made at the time of the constitution of the community.</strong></p><p id="f4b7">The change is made.</p><p id="1e04">Time passes. In fact, <strong>the time of detonation for the ‚Äúdifficulty bomb‚Äù which would lead to an ‚Äúice age‚Äù is drawing near. If the bomb activated the work would become impossible and the entire community would halt. </strong>Everyone agrees this would be bad.</p><p id="7d58"><strong>The ruling class, however, has failed to engineer the rules that would deliver on their promise</strong> to activate the switch to Proof-of-Stake. They cannot keep their original promise.</p><p id="e960"><strong>The ruling class proposes a solution. The solution does not include them sacrificing their wealth as punishment for failing to have delivered on their promise. The solution also does not remove the difficulty bomb from the code base. The solution only delays the difficulty bomb.</strong></p><p id="e60a">The ruling class claims something to the effect of ‚Äú<strong>by delaying the difficulty bomb we reaffirm our promise to deliver Proof-of-Stake by creating another deadline for ourselves through the postponement of the ice age</strong>.‚Äù</p><p id="97d5">Some people accept this statement at face value. Others have doubts. ‚Äú<strong>What if the deadline is missed again?</strong>‚Äù they ask. ‚Äú<strong>Won‚Äôt you just delay the difficulty bomb again?</strong>‚Äù</p><p id="d9c1"><strong>They are given the now-becoming-usual ultimatum, ‚ÄúIf you don‚Äôt like it, leave.‚Äù</strong></p><p id="cfe1">A hard fork to delay the difficulty bomb is enacted.</p><p id="3724">Time passes. More hard forks are proposed and enacted for the very same reasons as before.</p><p id="b583">This time the <strong>working class has their pay reduced from 4 Eth to 3 Eth per block, a 25% pay cut. Miners now earn 40% less per block than at the time of the community‚Äôs constitution, which promised that code was law, and which the ruling class later said they would break only once,</strong> for what was an especially good reason. But <strong>the code is law promise has now been broken so many times people expect it to occur at regular intervals </strong>and even worry that ‚Äúprogress‚Äù is slowing down if there aren‚Äôt frequent enough hard forks (to break that promise yet again).</p><p id="dafb">Predictably, the <strong>deadline is missed again for proof of stake and no penalty is paid by the ruling class for missing it again</strong>. In fact,<strong> that reduction of the working class‚Äô earnings is what pays for pacifying the class of subjects who are starting to make demands of the ruling class to deliver</strong> on their promise. <strong>The ruling class is happy to make a sacrifice of the working class‚Äô money. </strong>After all, it‚Äôs not their money being sacrificed.</p><p id="03f5"><strong>The wealthy class and class of subjects accepts this sacrifice without asking the moral question of ‚ÄúIs it right for the workers in our community to pay the price for the failings of the rulers</strong> in our community?‚Äù</p><p id="c3f6">Now, I want to pause here before continuing this story, because at this point, any reader should be able to reflect and say, ‚Äú<strong>Something here seems awfully similar to the system that crypto-currency was meant to fix. It was meant to eliminate rulers. It was meant to make everyone accountable for their actions. It was meant to reward the intelligent, the hard working and the capable, and not reward the incompetent, or the makers-yet-breakers of promises. However, this repeat of the broken old system seems to be playing out again.</strong>‚Äù Of course, that kind of reflection doesn‚Äôt take place if you‚Äôre only in this for the gains and not for repairing anything about our financial system.</p><p id="203e">More time passes. <strong>Progress towards Proof-of-Stake, the promise that the system will work with no work, is much slower than originally expected. The ruling class assures the other classes that progress <em>is</em> happening. They launch a partial solution to pacify the other classes. This pacification solution pays people to <em>stake</em> their coins, but does not do away with the dependency on proof-of-work. Paying for <em>stake</em> is welcomed by the wealthy class. It is, after all, getting paid for being wealthy, so why would they object?</strong></p><p id="2a12">Under this new arrangement, work is still needed. However, it‚Äôs just that <strong>the rich now get issued new units for the cost-less act of being rich</strong> <strong>while the workers only get paid for the costly act of doing work</strong>.</p><p id="6ef7">With everyone getting paid now in newly issued units (everyone except the poorer people in the class of subjects) <strong>concerns about inflation arise</strong>.</p><p id="d6cf"><strong>There are no actual delivery dates for the end of Proof-of-Work</strong>, and if there were, <strong>nobody would believe</strong> them by now anyways.</p><p id="2397"><strong>There is no concern about a difficulty bomb, which nobody cares about any more because they already know that it would just get delayed again </strong>if it kicked in.</p><p id="aa05"><strong>Everybody knows that the ruling class will not be held to account</strong>.</p><p id="017d">However, there is this concern about inflation.</p><p id="7fe0">So <strong>the ruling class proposes a solution. </strong>It‚Äôs<strong> </strong>one that has worked before: <strong>Cut the pay of the working class again.</strong> It turns out the working class not only earned rewards of newly issued Eth, but they also earned fees that users would pay for getting their transactions into blocks. <strong>The ruling class proposes that a portion of the working class‚Äô fees be burned.</strong> The fees will still be paid by users, but the miners will not receive the fee. It will instead be sacrificed. <strong>By burning the working class‚Äô money, the ruling class and wealthy class end up with a larger piece of the overall pie. It‚Äôs ingenious. Evil, but ingenious.</strong></p><p id="781c">Now, by this point it is quite clear that <strong>the ruling class turns out to be better at delivering narratives </strong>with cool names like ‚Äúice age‚Äù and ‚Äúworld computer‚Äù <strong>than they are at delivering actual code </strong>that corresponds with their promises. They do not disappoint in that regard. <strong>They call the burning of the working class‚Äô earnings ‚ÄúUltra-sound Money‚Äù</strong> as a great sounding term combining ‚Äúsound money‚Äù ‚Äî being good money that made a distinctive sound you could hear when that money was bounced on a table‚Äî and the word ‚Äúultra-sound‚Äù ‚Äî being sounds you can‚Äôt hear. Well, it sounds better when you don‚Äôt analyze it this way. Like everything in Ethereum, it sounds better when you don‚Äôt analyze it at all.</p><p id="ebb8">And that brings us to the present.</p><p id="38ba"><strong>We have a community where the ruling class has failed to deliver on their promises time and time again. Sound familiar?</strong></p><p id="0871"><strong>We have a community where those who do the work have been made to pay, time and time again, for those who do no work. Sound familiar?</strong></p><p id="0ac0"><strong>We have a ruling class whose solutions to every problem, even if it is them that caused the problem, never involve them owning up or paying any price for the solution. Sound familiar?</strong></p><p id="174d"><strong>We have complicity in the classes that benefit from the decisions of the ruling class at the expense of the working class. Sound familiar?</strong></p><p id="c6ca">It sounds just like the corrupt fiat money system we‚Äôre trying to escape.</p><p id="dc5b">How did we get here ‚Äî right back to the very system we were trying to escape from? I think it was these factors.</p><p id="d7b7">First, the initial coin offering, or pre-sale or pre-mine, created a class with the vast majority of wealth.</p><p id="cf27">Then, the DAO hard fork was intended to fix a naive mistake made by that rich class. However, the controversy it created appears to have set a precedent that the rulemakers can issue ultimatums to the rule-takers: ‚ÄúTake it or leave‚Äù.</p><p id="e38d">Next, the rule-makers were never held to account financially for failing to deliver on their promises.</p><p id="22a3">Instead, the ruling class repeatedly offered up the working class‚Äô money as a sacrifice to appease people in the other classes who felt they were due some reparations for the ruling class‚Äô broken promises.</p><p id="2acd">Those people in the other classes accepted those offers of sacrifice.</p><p id="cd8a"><strong>This is why I dislike Ethereum. I condemn it for repeatedly breaking its promises, thus making it entirely unreliable. I condemn it for making victims out of the only group in their community who actually delivered on their responsibilities.</strong></p><p id="2672"><strong>As a Bitcoiner I find these actions intolerable and unacceptable. I know none of them would ever be accepted in Bitcoin. We wouldn‚Äôt dare permit the installation of a bomb that could destroy the system, let alone leave one small group in charge of it. We would never break the code-is-law promise for the purpose of enriching one class at the expense of another. We would never make promises based on what sounds clever. We would simply never break the promises that constituted our community, because the whole attraction of it is that is doesn‚Äôt have a ruling class to take advantage of other classes.</strong></p><p id="a62c"><strong>I‚Äôm also curious about what all those people who repeatedly backed the ruling class think will eventually happen to them</strong>. How would they answer the questions ‚ÄúWhat do you think is going to happen to you if the working class is actually eliminated? <strong>Do you think the ruling class will suddenly stop seeking victims‚Äô to enrich themselves?</strong>‚Äù After all, the ruling class has the power to do anything. They can accelerate the issuance of Eth to themselves. They can make the money even more ultra-sound ‚Äî ultra-supersonic ‚Äî by burning existing coins (Ethereans‚Äô coins, not theirs of course) for whatever reasons they claim are good for the community. The sky is the limit for how they can control the currency. <strong>Any abuses that a central bank digital currency is vulnerable to, so too is Ethereum, especially based on the history of its ruling class intervening to change the rules to always make things better for themselves and keep them in power</strong>.</p><p id="e428">The truth that everyone should now see is that <strong>Ethereum is not a decentralized peer-to-peer system. It is a system with an unaccountable ruling class exploiting the working class, making promises they can‚Äôt keep, while spinning a wonderful narrative</strong> about how they are solving all the problems ‚Äî a combination of problems they created, problems that don‚Äôt exist, and problems they don‚Äôt actually know how to solve.</p><p id="79e6"><strong>It would be fine to leave it at that,</strong> even setting aside the countless fraudulent scams that have been perpetrated on Ethereum, <strong>but for just one thing</strong>.</p><p id="9a8b">That one thing is that <strong>this truth about Ethereum is swept under the rug while an entirely different tale is told to newcomers.</strong> As such, <strong>newcomers to Ethereum have repeatedly been hit with a broad variety of scams.</strong>These include a range of ICOs that have been subsequently found to be illegal to ones that were outright frauds. ‚ÄúSmart‚Äù contracts that lack smarts and are exploited and drained or ‚Äúrug-pulled‚Äù are so common that many don‚Äôt even make the news anymore. Garbage is sold as art. Art that can‚Äôt be owned is positioned as that which can be. Lies are told about what is on the blockchain and ownable and what isn‚Äôt.</p><p id="eec7">Ethereum‚Äôs promises change frequently as new marketing campaigns come up, like the ‚ÄúUltrasound Money‚Äù one, for example. But the tale never involves this clear history of the ruling class helping the wealthy class at the expense of the working class with everyone else standing by and enjoying the spoils.</p><p id="07c3"><strong>If none of this concerns you, I suppose you can take it.</strong> I would encourage you to seek some kind of moral counselling, but you don‚Äôt have to, and you can accept trying to be a winner in this regime. So you can take it, or, <strong>if it does bother you, you can leave it. This at least is a promise Ethereum makes and keeps.</strong></p></div></div></section></div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 04:52:41 +0000</pubDate>
      <source>https://tomerstrolight.medium.com/the-problem-with-ethereum-af9692f4af95</source>
    </item>
    <item>
      <title>Console Desktop Guide (2018)</title>
      <link>https://pspodcasting.net/dan/blog/2018/console_desktop.html</link>
      <description></description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page">
<h2>CONSOLE DESKTOP GUIDE</h2>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/intro.png"></a>
</p>

<h3>INDEX</h3>
<ul>
  <li><a href="#intro">What is a Console?</a></li>
  <li><a href="#serious">A Console Desktop? Seriously?!?</a></li>
  <li><a href="#basics">Basics</a></li>
  <ul>
    <li><a href="#consoles">Switching Consoles</a></li>
    <li><a href="#nvidia">Nvidia</a></li>
    <li><a href="#desktop">Getting to the Desktop again</a></li>
    <li><a href="#configuration">Configuring the Console on various Systems</a></li>
    <ul>
      <li><a href="#multi-monitor">Multiple Monitors</a></li>
      <li><a href="#linux">Linux: Generic Instructions</a></li>
      <li><a href="#framebuffer">Linux Framebuffer</a></li>
      <li><a href="#systemv">Non-System-D Linux</a></li>
      <li><a href="#systemd">System-D Linux</a></li>
      <li><a href="#nonlinux">Non-Linux Systems: A Reminder</a></li>
      <li><a href="#freebsd">FreeBSD and DragonFly BSD</a></li>
      <li><a href="#openbsd">OpenBSD</a></li>
      <li><a href="#netbsd">NetBSD</a></li>
      <li><a href="#illumos">Solaris and Illumos</a></li>
    </ul>
    <li><a href="#organize">Getting Organized</a></li>
    <li><a href="#jobs">Multitasking: Jobs</a></li>
    <li><a href="#tmux">Multitasking: Tmux</a></li>
    <li><a href="#mouse">Copy Pasting: The Console Mouse</a></li>
    <li><a href="#copy_paste_tmux">Copy Pasting: Tmux</a></li>
    <li><a href="#sysadmin">Sysadmin</a></li>
    <ul>
       <li><a href="#shutdown">Shutting Down</a></li>
       <li><a href="#monitoring">Monitoring</a></li>
       <li><a href="#disk">Disk Management</a></li>
       <ul>
         <li><a href="#disk_linux">Linux</a></li>
         <li><a href="#disk_bsd">BSD</a></li>
         <li><a href="#disk_illumos">Solaris and Illumos</a></li>
         <li><a href="#disk_alternatives">Alternatives to FAT</a></li>
         <li><a href="#disk_network">Network File Systems</a></li>
       </ul>
       <li><a href="#power">Power Management</a></li>
       <ul>
         <li><a href="#power_freebsd">FreeBSD and DragonFly BSD</a></li>
         <li><a href="#power_openbsd">OpenBSD</a></li>
         <li><a href="#power_netbsd">NetBSD</a></li>
         <li><a href="#power_illumos">Solaris and Illumos</a></li>
       </ul>
    </ul>
    <li><a href="#security">Security</a></li>
    <ul>
    	<li><a href="#user_mng">Users and Groups</a></li>
    	<li><a href="#sudo">To Be or Not to Be Root?</a></li>
    	<li><a href="#ssh">Remote Connections</a></li>
    	<li><a href="#passwords">Remembering Passwords</a></li>
    </ul>
    <li><a href="#interactive">Making Things Interactive</a></li>
    <ul>
      <li><a href="#shortcuts">Creating Shortcuts</a></li>
      <li><a href="#menu">Creating Menus</a></li>
      <li><a href="#progress">Progressbars and Interactive Pipes</a></li>
      <li><a href="#auto">Autocompletion</a></li>
      <li><a href="#fun">Having Fun</a></li>
    </ul>
  </ul>
  <li><a href="#web">The Web</a></li>
  <ul>
    <li><a href="#connect">Connecting to the Internet</a></li>
    <ul>
      <li><a href="#wifi">Wifi without NetworkManager</a></li>
      <li><a href="#wifi_freebsd">FreeBSD and DragonFly BSD</a></li>
      <li><a href="#wifi_netbsd">NetBSD</a></li>
      <li><a href="#wifi_openbsd">OpenBSD</a></li>
      <li><a href="#wifi_illumos">Solaris and Illumos</a></li>
    </ul>
    <li><a href="#browsing">Browsing</a></li>
    <li><a href="#webapps">Web Apps</a></li>
    <ul>
      <li><a href="#weatherapp">Example 1: A Weather App</a></li>
      <li><a href="#dailyapp">Example 2: Daily Motivational&#39;s</a></li>
      <li><a href="#smsapp">Example 3: Sending SMS</a></li>
      <li><a href="#chatapp">Example 4: A Chat Client</a></li>
    </ul>
    <li><a href="#downloads">Downloads</a></li>
    <li><a href="#chatting">Chatting</a></li>
    <li><a href="#email">Email</a></li>
    <li><a href="#news">News</a></li>
    <li><a href="#socialmedia">Social Media</a></li>
    <li><a href="#hipster">Hipster Media</a></li>
  </ul>
  <li><a href="#media">Multimedia</a></li>
  <ul>
    <li><a href="#volume">Volume</a></li>
    <ul>
      <li><a href="#volume_freebsd">FreeBSD and DragonFly BSD</a></li>
      <li><a href="#volume_openbsd">OpenBSD</a></li>
      <li><a href="#volume_netbsd">NetBSD</a></li>
      <li><a href="#volume_illumos">Solaris and Illumos</a></li>
    </ul>
    <li><a href="#video">Video</a></li>
    <li><a href="#youtube">Youtube</a></li>
    <li><a href="#music">Music</a></li>
    <li><a href="#radio">Internet Radio</a></li>
    <li><a href="#spotify">Spotify, LastFM and Podcasts</a></li>
    <li><a href="#making_music">Making Music and Video</a></li>
  </ul>
  <li><a href="#graphics">Graphics</a></li>
  <ul>
    <li><a href="#pictures">Pictures</a></li>
    <li><a href="#pdf">PDF and Postscript</a></li>
    <li><a href="#ocr">OCR</a></li>
    <li><a href="#ascii">Asciiart</a></li>
  </ul>
  <li><a href="#peripherals">Peripherals</a></li>
  <ul>
    <li><a href="#usb">USB Memory Sticks</a></li>
    <li><a href="#dvd">CD&#39;s, DVD&#39;s and BlueRays</a></li>
    <li><a href="#printer">Printers and Scanners</a></li>
  </ul>
  <li><a href="#game">Gaming</a></li>
  <ul>
    <li><a href="#strategy_games">Strategy Games</a></li>
    <li><a href="#framebuffer_games">Framebuffer Games</a></li>
    <li><a href="#roguelikes">Roguelikes</a></li>
    <li><a href="#if">Interactive Fiction</a></li>
    <li><a href="#mud">MUD&#39;s</a></li>
    <li><a href="#edu">Edutainment</a></li>
    <li><a href="#misc">Misc Fun</a></li>
  </ul>
  <li><a href="#office">Office</a></li>
  <ul>
    <li><a href="#documents">Reading Documents</a></li>
    <ul>
      <li><a href="#libreoffice">LibreOffice</a></li>
      <li><a href="#epub">E-Books</a></li>
      <li><a href="#cbr">CBR Comic Books</a></li>
    </ul>
    <li><a href="#spelling">Writing Text and Spell Checking</a></li>
    <li><a href="#dictionary">Dictionaries and Translation</a></li>
    <li><a href="#writing">Writing Documents</a></li>
    <ul>
      <li><a href="#troff">Troff</a></li>
      <li><a href="#tex">Tex</a></li>
      <li><a href="#docbook">Docbook</a></li>
    </ul>
    <li><a href="#spreadsheets">Spreadsheets and Databases</a></li>
    <ul>
      <li><a href="#sqlite">Sqlite</a></li>
      <li><a href="#awk">AWK</a></li>
    </ul>
    <li><a href="#presentation">Presentations</a></li>
    <li><a href="#math">Math and Graphs</a></li>
    <li><a href="#mindmap">Mindmaps and Flowcharts</a></li>
    <li><a href="#pim">PIM</a></li>
    <ul>
      <li><a href="#2do">2do lists</a></li>
      <li><a href="#que">Queues</a></li>
      <li><a href="#calendar">Calendar</a></li>
      <li><a href="#marking_calendar">Marking The Calendar</a></li>
      <li><a href="#password_mng">Password Manager</a></li>
      <li><a href="#accounting">Accounting</a></li>
      <li><a href="#addresses">Address Book</a></li>
      <li><a href="#bookmarks">Bookmarks</a></li>
      <li><a href="#timetracker">Keeping Track of Time</a></li>
    </ul>
  </ul>
  <li><a href="#x11">Console and X11 Integration</a></li>
  <ul>
    <li><a href="#retrieving">Retrieving Console Data</a></li>
    <li><a href="#console_desktop">Putting a Console on the Desktop</a></li>
    <li><a href="#desktop_console">Putting a Desktop on the Console</a></li>
  </ul>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>


<h2 id="intro">What is a Console..?</h2>

<p>
A <i>console</i> in UNIX speak
(<i>UNIX</i>..? think Linux - best to confuse one concept at a time!) 
is the text-based interface,
as opposed to the graphical interface
(the &#34;desktop&#34; in people speak).
The console is sometimes referred to as a &#34;tty&#34;
(short for 
<a href="https://en.wikipedia.org/wiki/Teleprinter">&#34;teletype&#34;</a>, 
which is graybeard speak - the kind of people who refer to a monitor as a &#39;glass teletype&#39;...)
You can change between consoles and the graphical environment by holding the keys <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>Function-Key</kbd>
(eg. <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>F1</kbd> will change to tty1 - the first console).
Exactly how many consoles are available,
and where the graphical environment is located,
depends greatly on which version of UNIX you are running,
and how it is configured.
More on that later,
but feel free to experiment!
A console
(technically a <i>virtual</i> console) 
is not the same as a terminal emulator,
such as XTerm,
which is a program you can run within a graphical environment.
Neither is it a <i>shell</i> by the way,
a shell like <samp>bash</samp> for instance runs inside a terminal emulator/virtual console.
Confusion reigns supreme however since terminal emulators and virtual consoles are often just called &#34;terminals&#34;, &#34;consoles&#34; or &#34;shells&#34; interchangeably.
(btw, all of them are &#34;cli&#39;s&#34; - command line interfaces)
</p>

<p>
If you feel confused at this point,
the following analogy might help:
Think of a &#34;shell&#34; as a language, such as English.
A &#34;console&#34; as an oldschool office from the 50&#39;s,
with only basic essentials like a typewriter and a filing cabinet.
And a &#34;desktop&#34; as a modern office of plexiglas and shiny chrome,
complete with air conditioning,
a coffee machine,
fancy artwork on the walls,
soft ambient background music and what not.
It even has some pencils and papers laying around somewhere if people get in a productive mood...
Although the office environments are certainly different,
and reflect different time periods,
in practice the occupants often work on the same things,
and of course they all use the same language.
</p>

<h2 id="serious">A Console Desktop? Seriously?</h2>

<p>
Yes.
The text-based environment in UNIX is incredibly versatile and powerful,
programmers and system administrators who log into a UNIX server remotely will typically work exclusively in the console,
working on a remote desktop
(similar to team-viewer in Windows)
is just too inefficient.
But can a console really function as an everyday &#34;desktop&#34;?
That is what this article will try to explore,
and I think you will be pleasantly surprised at just how useful a text-based environment can be!
</p>

<p>
Useful you say? 
Isn&#39;t a text based environment like... <i>boring</i>?!?
That depends.
Learning to use the console certainly requires effort,
just as it does to learn any language.
But once mastered, you don&#39;t think much about it as either boring or fun,
instead you focus on the task at hand.
An article you read might peak your interest or not,
but you wouldn&#39;t consider the English language itself as boring would you?
Once a language is learned you don&#39;t think much about it.
</p>

<p>
Since our goal here is to illustrate day-to-day &#34;desktop&#34; usage,
we will try to avoid going into system administration and programming as much as possible
(although we will have to dip our toes into such matters a little bit).
The internet is brimming with articles on these matters,
so just google around if you need some help ;)
The article assumes you are already familiar with basic UNIX commands,
and many solutions are provided as shell scripts.
If you don&#39;t have the skill to read such programs,
the following books may be useful additions to your bookshelf:
</p>

<ul>
<li><i>The UNIX Programming Environment</i> by Kernighan and Pike</li>
<li><i>The AWK Programming Language</i> by Aho, Kernighan and Weinberger</li>
<li><i>UNIX Power Tools</i> from O&#39;Reilly</li>
<li><i>The Handbook</i> from the FreeBSD project</li>
<li><i>The Linux Bible</i> from Wiley</li>
<li><i>The Linux Command Line and Shell Scripting Bible</i> from Wiley</li>
</ul>


<p>
Despite not delving deeply into administration and programming however,
we will cover much ground and therefore I try to give brief instructions.
You are encouraged to read the manpages and relevant documentation yourself to get the finer details.
Finally we will not talk much about Emacs.
This editor deserves a desktop howto article all on it&#39;s own,
and thus we try to avoid it not to digress to far off topic.
</p>

<p>
I will start off by discussing how to configure and use the console,
and introduce some basic topics.
Although necessary,
this first section is mindnumbingly boring,
so you might want to skip ahead to the <a href="#fun">fun</a> parts.
</p>

<h2 id="basics">Basics</h2>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/basics.png"></a>
</p>

<h3 id="consoles">Switching Consoles</h3>

<p>
As mentioned you normally have multiple virtual consoles available.
So if your waiting for a job to finish at tty1,
you can hit <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>F2</kbd> to jump over to tty2.
When you want to go back to the first console again, 
just hit <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>F1</kbd>.
Most systems will also allow you to scroll back the text with <kbd>Shift</kbd> + <kbd>PgUp</kbd> and <kbd>Shift</kbd> + <kbd>PgDown</kbd>,
this enables you to go back and read previous output.
In the following sections I will talk about how to configure fonts,
colors, keyboard layouts and the consoles in general.
The method of doing this varies greatly from system to system,
so you don&#39;t need to read all of the subsections,
just the ones that are relevant for you.
</p>

<h3 id="nvidia">Nvidia</h3>

<p>
This hardware vendor deserves special mention.
Now I know that many a Windows gamer out there loves his Nvidia card like his favorite pet monkey.
And sure enough the Nvidia engineers can produce stunning specs,
but they cannot write quality software if their life depended on it!
Their driver is a bad joke,
and an affront to the finer feelings of system administrators everywhere.
It is clear that the Nvidia developers have the Windows mindset,
where it is perfectly fine,
nay <i>expected</i>,
to write binary blobs that bloat the system and boldly crash it in ways no one have crashed it before!
What&#39;s life without a little whimsy,
stability is for wimps!
</p>

<p>
If you are using their driver on any version of UNIX,
then you will most likely not be able to switch back and forth between the console and your graphical environment.
In fact you often cannot run multiple graphical environments simultaneously either,
something that is unheard of in the Windows world,
but is a given on UNIX systems.
Don&#39;t be surprised either if your system suddenly freezes or crashes for no apparent reason whatsoever,
these are classical symptoms of <s>Windows</s> Nvidia.
The only way to work around these issues is to use either the reverse engineered open source Nvidia driver,
or configure X to use the generic VESA driver.
In both cases you will have very shabby resolution,
both on your desktop and on your console.
Using the console with an Nvidia card will definitely cause lower quality of life,
if you have no choice however,
I recommend that you take a closer look at the
<a href="#console_desktop">Putting a Console on the Desktop</a> section below.
</p>

<p>
As a side note:
The OpenBSD developers have embargoed Nvidia on their system.
If more operating systems would follow their example,
instead of showing their finger in frustration
(looking at you Linus Torvalds),
Nvidia might just take a hint and clean up their act.
</p>

<p>
<i>
To be fair,
other vendors like Intel,
have also shown a shocking lack of concern for the quality of their own product.
Of course Intels specialty is multi-processing and virtualization,
not graphics,
so it&#39;s in those areas that they bury their bodies.
As far as graphics are concerned,
Intel should not give you any problems on the console.
</i>
</p>

<h3 id="desktop">Getting to the Desktop again</h3>

<p>
If you have a graphical desktop already running,
getting to it from the console is simply a question of finding out where it is.
If you are unsure just hit <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>F1</kbd>,
then <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>F2</kbd>,
and so on all the way up to <kbd>F12</kbd> until you hit it
(it is often at <kbd>F5</kbd> or <kbd>F7</kbd> but it varies).
Note that while some systems allow you to use the shorthand <kbd>Alt</kbd> + <kbd>Fn</kbd>,
when switching consoles,
you need to use the full keybinding sequence <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>Fn</kbd>,
when switching back and forth between the graphical environment and the consoles.
</p>

<p>
You can also start a graphical environment from a console.
If no graphical environment is running just type <samp>startx</samp>.
This will launch the systems default graphical environment,
which is often <samp>twm</samp>,
a horribly antiquated window manager.
(many who see this for the first time do not realize they are running a desktop,
they just assume that the computer got broken somehow)
You can configure startx to run something else by adding instructions in <samp>~/.xinitrc</samp>
(that is <samp>.xinitrc</samp> in your home directory).
Here is a short example that sets the keyboard layout to Italian and launches Xfce:
</p>

<pre><samp>
setxkbmap it
exec dbus-launch --exit-with-session startxfce4
</samp>
</pre>


<p>
<i>PS:</i>
Getting the launch instructions right for a modern desktop,
such as KDE or GNOME,
can be tricky.
If you&#39;re having problems starting them I suggest you first test X
(the traditional graphical engine in UNIX),
with a simple window manager,
such as <samp>exec openbox</samp>,
to check that the actual graphical environment is working.
If it is,
you have probably misconfigured the KDE/GNOME launch instructions.
</p>

<p>
If a graphical environment is already running you need to launch your new desktop in a different virtual screen.
You can do so like this: <samp>startx -- :2</samp>,
the number here is arbitrary,
what matters is that the screen number must be unique.
</p>

<h3 id="configuration">Configuring the Console on various Systems</h3>

<h4 id="multi-monitor">Multiple Monitors</h4>

<p>
Multi-Monitor setups is not possible on any UNIX console.
That is to say,
you can have as many monitors as you like,
but they will all show the same screen.
Multitasking however is possible,
for one,
you can configure a number of
<a href="#consoles">virtual consoles</a>
and switch between them.
(see also the
<a href="#tmux">tmux</a> section)
Secondly,
you can have a multi-monitor setup in X,
and run a
<a href="#console_desktop">&#34;console-like&#34;</a>
desktop,
such as dwm.
</p>

<h4 id="linux">Linux: Generic Instructions</h4>

<p>
Linux will usually configure a number of consoles by default,
6 consoles and the graphical environment on the seventh seems to be a popular configuration.
You can configure an arbitrary number of consoles on Linux,
see the next sections for further details.
You can also use the short hand <kbd>Alt</kbd> + <kbd>Fn</kbd> and <kbd>Alt</kbd> + <kbd>Arrow-Key</kbd> to change consoles.
</p>

<p>
You can set keyboard layout with <samp>loadkeys</samp>,
such as <samp>loadkeys dvorak.map</samp>.
The keyboard maps are often located in <samp>/usr/share/keymaps</samp> or <samp>/usr/share/kbd/keymaps</samp>.
(<i>PS:</i>
This approach should also work on System-D distros,
but did not work for me on Debian.
You could try <samp>dpkg-reconfigure keyboard-configuration</samp> instead
(naturally this will only work on Debian-like distros)).
You can change fonts with <samp>setfont</samp>,
such as <samp>setfont -v Uni3-Terminus12x6</samp>,
the console fonts are usually located in <samp>/usr/share/consolefonts</samp> or <samp>/usr/share/kbd/consolefonts</samp>.
</p>

<p>
The Linux console supports multiple colors and you can use <samp>echo</samp> to send control sequences to manipulate the color settings.
Adding this to the end of <samp>~/.profile</samp> will make your console use the Solarized color theme:
</p>

<pre><samp>
# solarize the tty
if [ &#34;$TERM&#34; = &#34;linux&#34; ]; then
	echo -en &#34;\e]P0073642&#34; #black
	echo -en &#34;\e]P1dc322f&#34; #darkgray
	echo -en &#34;\e]P2859900&#34; #darkred
	echo -en &#34;\e]P3b58900&#34; #red
	echo -en &#34;\e]P4268bd2&#34; #darkgreen
	echo -en &#34;\e]P5d33682&#34; #green
	echo -en &#34;\e]P62aa198&#34; #brown
	echo -en &#34;\e]P7eee8d5&#34; #yellow
	echo -en &#34;\e]P8002b36&#34; #darkblue
	echo -en &#34;\e]P9cb4b16&#34; #blue
	echo -en &#34;\e]PA586e75&#34; #darkmagenta
	echo -en &#34;\e]PB657b83&#34; #magenta
	echo -en &#34;\e]PC839496&#34; #darkcyan
	echo -en &#34;\e]PD6c71c4&#34; #cyan
	echo -en &#34;\e]PE93a1a1&#34; #lightgray
	echo -en &#34;\e]PFfdf6e3&#34; #white
	clear #for background artifacting
fi
</samp>
</pre>


<h4 id="framebuffer">Linux Framebuffer</h4>

<p>
Not only can the Linux console display any number of colors,
but it is also capable of displaying real graphics.
It can do so using the framebuffer device.
In order to use it you must first make sure your user has permission to access <samp>/dev/fb0</samp> and the files under <samp>/dev/input</samp>.
This usually mean you need to add your user to the groups <samp>video</samp> and <samp>input</samp>,
you can do so by running this command: <samp>usermod -a -G video,input myusername</samp>.
You also need to install the <samp>fbdev</samp> driver,
if it isn&#39;t already included.
The method of doing so varies from distro to distro.
For instance on Slackware you can do this: <samp>installpkg /mnt/cdrom/extra/xf86-video/*.txz</samp>, 
and on Debian: <samp>apt install xserver-xorg-video-fbdev fbset gpm</samp>.
Look up your distros documentation.
</p>

<p>
Two examples of a programs you can use on the Linux framebuffer is <samp>fbterm</samp> and <samp>fbi</samp>.
The <samp>fbterm</samp> terminal can use any fonts available under the graphical environment,
which easily enables you to have support for exotic languages like Arabic or Chinese.
In combination with the image viewer <samp>fbi</samp>,
you can also set a wallpaper for this terminal.
(<i>Ps</i>:
You cannot launch another framebuffer program from within fbterm,
you need to do that from a regular console)
</p>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/fbterm.png"></a>
</p>

<pre><samp>
#!/bin/sh
# fbtermbg - start fbterm with wallpaper
# usage:  fbtermbg wallpaper
# depend: fbi

(sleep 1; cat /dev/fb0 &gt; /tmp/wallpaper.fbimg) &amp;
fbi -t 2 -1 --noverbose -a $1
export FBTERM_BACKGROUND_IMAGE=1
cat /tmp/wallpaper.fbimg &gt; /dev/fb0
fbterm
</samp>
</pre>


<p>
Some framebuffer programs will hijack your screen,
so that you cannot switch to other consoles or the graphical environment.
Don&#39;t panic!
Everything should return to normal once you have quit the program.
(<i>Ps</i>:
If your console is all garbled after you have quit a framebuffer program,
the <samp>reset</samp> command should fix it)
</p>

<h4 id="systemv">Non-System-D Linux</h4>

<p>
Legacy Linux systems,
and a few modern exceptions,
such as Slackware, Gentoo and CRUX,
do not use System-D.
</p>

<p>
You can change virtual console settings in <samp>/etc/inittab</samp>.
To add an eighth tty in Slackware,
add this line to <samp>/etc/inittab</samp>:
</p>
<pre><samp>
c8:12345:respawn:/sbin/agetty 38400 tty8 linux
</samp>
</pre>

<p>
This takes effect after a reboot.
In non-System-D Linux you can also switch to tty13-24 with <kbd>AltGr</kbd> + <kbd>Fn</kbd>.
</p>

<p>
Slackware boots in a text based environment by default,
to change this to a graphical login,
change the line:
<samp>id:3:initdefault</samp> to <samp>id:4:initdefault</samp> in <samp>/etc/inittab</samp>.
On non-System-D Linux runlevel <b>3</b> is text mode login,
where as runlevel <b>4</b> is graphical login.
The process described here should be fairly similar to any Linux distribution that doesn&#39;t use System-D.
</p>

<h4 id="systemd">System-D Linux</h4>

<p>
Most modern Linux systems,
including Debian, Redhat, SUSE, Arch,
and quite a few others,
use System-D.
</p>

<p>
To change the number of consoles, to say 12, in Debian,
uncomment <samp>NAutoVTs</samp> in <samp>/etc/systemd/logind.conf</samp> and set it to <samp>NAutoVTs=12</samp>.
This will take effect after a reboot.
On Linux systems with System-D, 
you can switch between the tty13-24 with <kbd>Shift</kbd> + <kbd>Alt</kbd> + <kbd>Fn</kbd>.
</p>

<p>
Configuring Debian to boot into text mode instead of a graphical login,
do this: <samp>systemctl set-default multi-user.target</samp>,
to switch back to graphical login do this:
<samp>systemctl set-default graphical.target</samp>.
The process described in this section should be fairly similar to any Linux distribution that uses System-D.
</p>

<h4 id="nonlinux">Non-Linux Systems: A Reminder</h4>

<p>
Linux users often take a lot for granted,
they tend to get horrified when discovering that a different UNIX system doesn&#39;t have some functionality they have gotten used to,
or even if they just do things differently.
(they may even shout <i>&#34;this isn&#39;t UNIX!!!&#34;</i> without realizing the irony - it&#39;s usually Linux that&#39;s doing things in a non-Unixy fashion)
So if you&#39;re planning to use a BSD system or some other UNIX variety,
and have a Linux background,
have an open mind and be prepared to adjust your expectations!
</p>

<p>
When it comes to the console,
non-Linux systems will not support graphics on the framebuffer,
nor support exotic UTF-8 characters (ei. English only),
and color and font support is often very limited.
In fact many ncurses applications may not work well on non-Linux consoles.
Some systems also restrict how many consoles you are allowed to have.
If you think this all sounds horribly limiting,
remember that real UNIX graybeards consider &#34;graphics&#34;,
&#34;colors&#34; and non-ASCII text to be script-kiddie fads.
(having that said,
all of these restrictions can be easily overcome by simply running
<a href="#console_desktop">terminal emulators in a graphical desktop</a>).
Lastly keybindings might be a little different,
although <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>Fn</kbd> will always work.
</p>

<p>
Despite these restrictions however,
you can still do neat things on any UNIX console with a little knowhow.
The above mentioned trick to make a Solarized console theme in Linux will not work on most UNIX consoles since they don&#39;t support 256 colors,
but virtually all of them have 8 color ANSI support,
so you can do some basic color tweaking.
Here is a simple and portable script that can set a few basic tty color schemes
(unlike the Linux trick though,
the themes are not preserved if you run a terminal application with colors,
such as vim or less,
so a better solution is to configure your system to use the colors you want
- more on that later):
</p>

<pre><samp>
#!/bin/sh
# ttycolor - choose tty colors
# usage: ttycolor theme
# bugs:  not persistent across colorful tty apps
#
# explanation:
# printf &#39;\e[1m&#39;  - turn on boldface (or &#34;light&#34; color)
# printf &#39;\e[0m&#39;  - turn off boldface (or &#34;dark&#34; color)
# printf &#39;\e[4nm&#39; - specify background color (&#34;boldface&#34; has no effect)
# printf &#39;\e[3nm&#39; - specify foreground color, where n is:
# 0 = black 2 = green   4 = blue    6 = cyan
# 1 = red   3 = yellow  5 = magenta 7 = white

usage(){
	echo &#39;Usage: ttycolor (geek|tron|minoca|sun|obsd|nuke|default)&#39; &gt;&amp;2
	exit 1
}
if [ ! $# = 1 ]; then
	usage
fi

# set tty colors
case $1 in
	geek) printf &#39;\e[0m\e[32m\e[40m&#39; ;;	# green on black
	tron) printf &#39;\e[1m\e[36m\e[40m&#39; ;;	# cyan on black 
	minoca) printf &#39;\e[1m\e[33m\e[42m&#39; ;;	# yellow on green
	sun)  printf &#39;\e[0m\e[30m\e[47m&#39; ;;	# black on white
	obsd) printf &#39;\e[1m\e[37m\e[44m&#39; ;;	# white on blue
	nuke) printf &#39;\e[1m\e[33m\e[41m&#39; ;;	# yellow on red
	default) printf &#39;\e[0m\e[37m\e[40m&#39; ;;	# white on black
	*) usage ;;
esac
clear
</samp></pre>



<h4 id="freebsd">FreeBSD and DragonFly BSD</h4>

<p>
<i>FreeBSD</i> has 8 virtual consoles configured and the graphical interface on the ninth by default.
Modern versions of FreeBSD use the <samp>vt(4)</samp> console driver.
It allows you to configure up to 16 consoles,
and switch to tty13-16 with <kbd>Shift</kbd> + <kbd>Alt</kbd> + <kbd>F1</kbd> ... <kbd>F4</kbd>.
You can also use the <kbd>Alt</kbd> + <kbd>Fn</kbd> shortcut,
but not the arrow keys.
To scroll backwards and read previous output hit <kbd>Scroll Lock</kbd>,
and then use <kbd>Page Up</kbd> and <kbd>Page Down</kbd>,
hit <kbd>Scroll Lock</kbd> again when you are done.
To configure more than 8 consoles edit <samp>/etc/ttys</samp>,
for instance this line:
<samp>ttyv9 &#34;/usr/libexec/getty Pc&#34; xterm on secure</samp>
will enable a ninth console.
To enable all 16 consoles use <samp>ttyva</samp> ... <samp>ttyvf</samp>,
don&#39;t use <samp>ttyv10</samp> ... <samp>ttyv15</samp>!
You can tweak the other console settings by adding options to <samp>/etc/rc.conf</samp>.
For instance adding these lines:
</p>

<pre><samp>
moused_enable=&#34;YES&#34;
allscreens_flags=&#34;-f 8x8 /usr/share/vt/fonts/terminus-b32.fnt green&#34;
keymap=&#34;us.dvorak.kbd&#34;
kld_list=&#34;i915kms&#34;
</samp>
</pre>


<p>
will enable the console mouse,
use large green terminus fonts and the dvorak keyboard layout.
Lastly it will load the intel graphics firmware,
you need to have the <samp>drm-kmod</samp> package installed for this to work
(if you are using nvidia or radeon you need to change this line accordingly).
You can interactively select a console font with <samp>vidfont</samp>,
or use the <samp>vidcontrol</samp> command to adjust all of the above settings.
</p>

<p>
Even with 16 ttys configured in <samp>/etc/ttys</samp>,
FreeBSD limits you to a maximum of 12 consoles by default,
to add up to 16,
you need to tweak the kernel a bit:
</p>

<pre><samp>
# <i>cd /usr/src/sys/$(uname -m)/conf</i>
# <i>cp GENERIC MYKERN</i>
# <i>sed -i &#39;&#39; &#39;s/GENERIC/MYKERN/&#39; MYKERN</i>
# <i>echo options VT_MAXWINDOWS=16 &gt;&gt; MYKERN</i>
# <i>cd /usr/src</i>
# <i>make buildkernel KERNCONF=MYKERN</i>
# <i>make installkernel KERNCONF=MYKERN</i>
# <i>shutdown -r now</i>
</samp>
</pre>


<p>
<i>DragonFly BSD</i>
uses the old <samp>sc(4)</samp> console driver from FreeBSD,
but otherwise the setup is exactly the same.
By the way,
you don&#39;t need to tweak the kernel in order to enable all 16 consoles,
like you do in FreeBSD.
(<i>PS:</i>
the sc driver might have problems switching between the graphical environment and consoles)
</p>

<p>
<i>
PS: BSD systems write kernel messages to the first console.
This can be quite annoying if you happen to be working on other things there,
so work on a different console then the first one to avoid much consternation.
</i>
</p>

<h4 id="openbsd">OpenBSD</h4>
<p>
OpenBSD uses the <samp>wscons(4)</samp> console driver.
It requires you to switch between consoles using
<kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>Fn</kbd>,
you cannot use the shorthand
<kbd>Alt</kbd> + <kbd>Fn</kbd>.
This is a design choice, 
made to avoid keybinding conflicts.
Also there is no way to physically switch beyond 12 consoles.
</p>

<p>
In <i>OpenBSD</i> you have five consoles enabled by default,
the fifth tty is reserved for the graphical environment.
Adding more consoles in done in <samp>/etc/ttys</samp>:
</p>
<pre><samp>
ttyC7 &#34;/usr/libexec/getty std.9600&#34; pccon0 on secure
</samp>
</pre>

Oh, and by the way once your editing /etc/ttys,
change the <samp>vt220</samp> option for your active consoles to <samp>pccon0</samp>.
vt220 is a <s>ultra-conservative</s> safe choice,
but pccon0 has more modern capabilities,
such as unicode, colors and curses.
(<i>PS</i>:
console 11 and 12 must be <samp>ttyCa</samp> and <samp>ttyCb</samp>)


<p>
Rebooting will not activate your new consoles however,
you need to &#34;create&#34; them first.
Doing so manually is a bit tedious,
instead we can recompile the kernel with some new settings:
</p>

<pre><samp>
# <i>cd /usr/src/sys/arch/$(uname -m)/conf</i>
# <i>cp GENERIC.MP CUSTOM</i>
</samp>
</pre>


<p>
(Assuming you are running a multi-processor kernel,
if not copy GENERIC)
Now open up <samp>CUSTOM</samp> in an editor and add the following lines:
</p>

<pre><samp>
option WS_KERNEL_FG=WSCOL_WHITE
option WS_KERNEL_BG=WSCOL_BLACK
option WS_DEFAULT_FG=WSCOL_GREEN
option WS_DEFAULT_BG=WSCOL_BLACK
option FONT_BOLD8x16
</samp>
</pre>


<p>
These settings will result in kernel messages being written in a white font,
and normal text in green.
We also changed the font to a smaller type,
fitting more text onto our screen
(you&#39;ll find a list of available fonts in <samp>/usr/src/sys/dev/wsfont/wsfont.c</samp> if you have installed sources).
Finally change the <samp>WSDISPLAY_DEFAULTSCREEN=6</samp> to <samp>WSDISPLAY_DEFAULTSCREEN=12</samp> in <samp>GENERIC</samp>.
(regardless of whether you are running a multi-processing kernel or not)
Now that the customization&#39;s are done,
we can recompile:
</p>

<pre><samp>
# <i>config CUSTOM</i>
# <i>cd ../compile/CUSTOM</i>
# <i>make clean</i>
# <i>make</i>
# <i>make install</i>
# <i>shutdown -r now</i>
</samp>
</pre>


<p>
<i>PS:</i>
X is big, bloated and old,
it is a mayor security risk!
The OpenBSD developers are somewhat conscientious about security...
They have therefore reconfigured X to run in user mode,
denying it any direct access to the system.
This is great for security,
but a consequence of doing so is that you cannot run more than one graphical environment at a time.
You can use <samp>Xephyr</samp> or <samp>Xnest</samp> to nest X instances inside each other though
(eg. <samp>(Xephyr :2 -screen 1920x1080 &amp;); sleep 1; DISPLAY=:2 openbox</samp>).
Also the normal way of starting X in OpenBSD from the console is not with <samp>startx</samp>,
but rather <samp>doas xenodm</samp>,
which starts the xdm-like login manager.
Finally,
as mentioned OpenBSD does not support Nvidia cards.
Graphics may still &#34;work&#34; on such cards,
but you will only get generic VESA output
(very poor resolution).
</p>

<p>
<i>
PS: OpenBSD, like all BSD systems, write kernel messages to the first console.
So it&#39;s a good idea to work on a different console to avoid interruptions.
</i>
</p>

<h4 id="netbsd">NetBSD</h4>

<p>
NetBSD also uses the <samp>wscons(4)</samp> console driver,
like OpenBSD.
It requires you to switch between consoles using
<kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>Fn</kbd>,
you cannot use the shorthand
<kbd>Alt</kbd> + <kbd>Fn</kbd>.
There is no way to physically switch beyond 12 consoles.
</p>

<p>
Configuring the <i>NetBSD</i> console is fairly similar to OpenBSD.
Add new consoles to <samp>/etc/ttys</samp>, for instance:
</p>

<pre><samp>
# <i>cd /usr/src/sys/arch/$(uname -m)/conf</i>
# <i>cp GENERIC CUSTOM</i>
# <i>vi CUSTOM</i>
</samp>
</pre>


<p>
Now change <samp>WS_KERNEL_FG=WSCOL_GREEN</samp> to <samp>WS_KERNEL_FG=WHITE</samp>,
and add <samp>WS_DEFAULT_FG=WSCOL_GREEN</samp>.
Uncomment <samp>WSDISPLAY_DEFAULTSCREENS=4</samp> and change it to <samp>WSDISPLAY_DEFAULTSCREENS=8</samp>,
and add <samp>FONT_DEJAVU_SANS_MONO12x22</samp>
(you&#39;ll find a list of available fonts in <samp>/usr/src/sys/dev/wsfont/wsfont.c</samp> if you have installed sources).
Then compile the kernel with these changes:
</p>

<pre><samp>
# <i>config CUSTOM</i>
# <i>cd ../compile/CUSTOM</i>
# <i>make depend</i>
# <i>make</i>
# <i>mv /netbsd /netbsd.old</i>
# <i>mv netbsd /</i>
# <i>shutdown -r now</i>
</samp>
</pre>


<p>
By default the NetBSD kernel only allows you to have a maximum of 8 consoles.
Enabling more than that would require some serious kernel hacking,
I recommend using <a href="#tmux"><samp>tmux</samp></a> instead...
</p>

<p>
<i>
PS: NetBSD, like all BSD systems, write kernel messages to the first console.
So it&#39;s a good idea to work on a different console to avoid interruptions.
</i>
</p>

<h4 id="illumos">Solaris and Illumos</h4>

<p>
Oddly enough virtual consoles have traditionally not been available on Solaris,
and it does not come enabled by default in newer versions,
such as OpenIndiana,
either.
To add six consoles in OpenIndiana for instance,
you need to run:
</p>

<pre><samp>
# <i>svcadm enable vtdaemon</i>
# <i>for i in 2 3 4 5 6; do</i>
&gt; 	<i>svcadm enable console-login:vt$i</i>
&gt; <i>done</i>
# <i>svccfg -s vtdaemon setprop options/secure=false</i>
# <i>svccfg -s vtdaemon setprop options/hotkeys=true</i>
# <i>svcadm refresh vtdaemon</i>
# <i>svcadm restart vtdaemon</i>
</samp>
</pre>


<p>
By default you are only allowed to activate a maximum of 6 consoles.
Like Linux you can change between consoles using the <kbd>Alt</kbd> + <kbd>Fn</kbd> for ttys 1-12,
and <kbd>AltGr</kbd> + <kbd>Fn</kbd> for ttys 13-24,
or you can use the <kbd>Alt</kbd> + <kbd>Arrow-Key</kbd> shortcuts.
To get back to the desktop hit <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>F7</kbd>.
Not all graphical drivers will allow you to switch between console and desktop however.
On one of my test machines I had to disable the graphical environment with <samp>svcadm disable lightdm</samp> and do a cold reboot.
From the console I could then enable the desktop again with <samp>svcadm enable lightdm</samp>,
but to get to the console again I would have to do another disable and reboot.
</p>

<p>
I was able to work around these problems by configuring X to use the generic vesa driver,
but naturally this meant that I had a very poor screen resolution.
Hopefully your graphic driver will be more cooperative.
If not it might be better to ignore the tty consoles altogether and use
<a href="#console_desktop">terminal emulators in a graphical desktop</a> instead
(not all of the applications mentioned in this reference are available in the Solaris repositories).
But if you really want to use the vesa graphics driver you can do so by adding this file in <samp>/etc/X11/xorg.conf.d/vesa.conf</samp>:
</p>

<pre><samp>
Section &#34;Device&#34;
	Identifier &#34;Card0&#34;
	Driver &#34;vesa&#34;
EndSection
</samp>
</pre>


<p>
The only way I have managed to add more then 6 consoles in Solaris is the following hackish method:
edit <samp>/lib/svc/manifest/system/console-login.xml</samp> as root,
find the <samp>&lt;instance name=&#39;vt6&#39; enabled=&#39;false&#39;&gt;</samp> line and copy this until the trailing <samp>&lt;/instance&gt;</samp>.
Edit the copy so that it reads <samp>vt8</samp> and <samp>/dev/vt/8</samp>,
instead of <samp>vt6</samp> and <samp>/dev/vt/6</samp>,
in the three places that these values are mentioned.
You can now repeat this process for vt&#39;s 9-15.
Reboot and run the above svcadm commands for vt&#39;s 9-15 and you now have 14 consoles (vt7 is still reserved for the desktop).
If you want more then 14 consoles you need to make more device files in <samp>/dev/vt</samp> first,
don&#39;t ask me how...
</p>

<p>
Setting the console keyboard layout,
to say French, 
is done with <samp>kbd -s French</samp>.
To choose a language interactively just type <samp>kbd -s</samp>.
In theory,
running this command as root should change your default console keyboard layout permanently,
but due to a bug in the version of OpenIndiana I tested this on,
it got reset to US qwerty on every reboot.
I have yet to figure out how to adjust fonts and default colors in the Solaris console,
or use the mouse and scrollback buffer
(I suspect this doesn&#39;t work on all hardware).
</p>

<h3 id="organize">Getting Organized</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/organized.png"></a>
</p>

<p>
The process,
nay the <i>art</i>,
of getting organized is a complex and abstract topic.
We will not even try to present a self-help-book-like theory of how to do this!
(there are plenty of those on Amazon if you are into that sort of thing...)
What we will do is show you the tools you need,
and leave it as an exercise for the reader to figure out what to do with them...
(sidenote: one of the &#34;benefits&#34; of using the console is that you actually <i>have to</i> get organized)
</p>

<p>
You are probably familiar with the basic tools such as 
<samp>ls</samp>, <samp>cd</samp>, <samp>mkdir</samp>, <samp>rm</samp>, <samp>ln</samp>, <samp>pwd</samp> and so on.
The problem of organizing yourself on the command line though,
is that your files are largely out of view.
<i>&#34;Out of sight, out of mind&#34;</i> as they say.
You can quickly check what the filesystem looks like with the <samp>tree</samp> command.
(if there is to much output try <samp>tree -L 1</samp> or <samp>-L 2</samp>).
Another fantastic tool to quickly get an overview of your files,
including their contents,
is the file manager <samp>ranger</samp>
(alternatively <samp>mc</samp>).
On the other hand,
if you just need to figure out what&#39;s taking so much space of your harddrive try <samp>ncdu</samp>.
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/tree.png"></a>
</p>

<p>
Sometimes though you don&#39;t need to get a general overview,
but find a specific file that you have lost.
The quickest way to do this is <samp>locate myfile</samp>.
But the <samp>locate</samp> command has a weakness,
it relies on a database that needs to be updated manually
(read the man page for the specifics).
If the database is out of date, it may not contain the file your looking for.
(tip: update the locate database periodically with a cron job)
Worse, you may not remember the exact name,
you only remember certain details,
such as general filesize and when you last worked on it.
<samp>find</samp> is your friend!
This command can do some impressive file searching,
here are some examples:
</p>

<p>
Search for a directory named exactly &#34;MyDiR&#34; somewhere under /some/path:
</p><pre><samp>
$ <i>find /some/path -type d -name MyDiR</i>
</samp>
</pre>


<p>
Search for a pdf file somewhere under the current directory that is more then 10 megabytes in size but less then 100:
</p><pre><samp>
$ <i>find . -iname *.pdf -size +10M -size -100M</i>
</samp>
</pre>


<p>
Case insensitive search for a file called &#34;mydir&#34; somewhere under the current directory,
modified within the last 10 days and belonging to the &#34;www&#34; group:
</p><pre><samp>
$ <i>find . -type f -iname mydir -group www -mtime -10</i>
</samp>
</pre>


<p>
Last but not least,
don&#39;t forget the invaluable <samp>grep</samp> command.
With it you can recursively search for any file containing a certain text,
eg:
</p><pre><samp>
$ <i>grep -R &#34;UNIX is awesome&#34; /some/path</i>
</samp>
</pre>


<h3 id="jobs">Multitasking: Jobs</h3>

<p>
A terminal can also run multiple programs at once.
You have probably launched programs in the background before with <samp>command &amp;</samp>.
What you may not realize is that you can easily switch programs from the background to the foreground arbitrarily.
To demonstrate:
Type <samp>sleep 60 &amp;</samp> and hit enter, three times,
now run <samp>jobs</samp>,
and you will see these three background processes listed.
Put job number 2 to the foreground with <samp>fg 2</samp>.
Your console is now unresponsive,
it is busy sleeping.
Hit <kbd>Ctrl</kbd> + <kbd>z</kbd> and you will suspend the process to the background again.
Run <samp>jobs</samp> again and notice that job nr 2 doesn&#39;t have a <b>&amp;</b> sign,
it is currently paused.
You can continue the process in the background with <samp>bg 2</samp>.
</p>

<p>
Of course managing multiple jobs in this way is tedious.
Some times however you might find that you need to halt the program you are running,
and do something real quick.
Well that&#39;s easy,
hit <kbd>Ctrl</kbd> + <kbd>z</kbd>,
do your thing,
and run <samp>fg</samp> when your done.
Presto!
Your program resumes like nothing happened.
</p>

<h3 id="tmux">Multitasking: Tmux</h3>

<p>
For serious multitasking on the console you need terminal multiplexers.
Think of a multiplexer as a window manager for the terminal.
There are many alternatives,
but we will focus on <samp>tmux</samp>
(The classic multiplexer <samp>screen</samp> has similar capabilities,
while <samp>dvtm</samp> focuses more on window tiling).
</p>

<p>
To quickly demonstrate some of it&#39;s abilities do the following:
Fire up <samp>tmux</samp> and hit <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>c</kbd>.
At the bottom line you will now see <samp>0:bash- 1:bash*</samp>.
This means that there are two bash programs running,
you are now seeing the program with an asterix, <samp>1:bash*</samp>.
You can change back to <samp>0:bash</samp> by hitting <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>0</kbd>,
and then back to <samp>1:bash</samp> again with <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>1</kbd>.
But tmux can do more...
Hit <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>%</kbd>,
and you will see the screen split vertically.
Hit <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>&#34;</kbd>,
and it will split horizontally.
You can navigate between these window frames by hitting <kbd>Ctrl</kbd> + <kbd>b</kbd> and then one of the <kbd>Arrow</kbd> keys.
To resize the frames,
do the same,
but keep holding down <kbd>Ctrl</kbd> as you use the <kbd>Arrow</kbd> keys.
</p>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/tmux.png"></a>
</p>

<p>
If you hit <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>d</kbd>,
tmux will quit.
But you haven&#39;t just exited the program,
tmux is <i>detached</i>.
If you run <samp>ps -ely | grep tmux</samp>,
you will see that it is still running.
You can connect to this <samp>tmux</samp> session again by running the command <samp>tmux attach</samp>.
This functionality is invaluable when working remotely on a server.
If the internet connection is broken when you had tmux running,
just log in again and run <samp>tmux attach</samp>,
and you can continue where you left off.
Naturally you can have many tmux sessions running in the background,
use <samp>tmux ls</samp> to list them.
</p>

<p>
There is an absurd amount of things you can do with this program.
Check the <samp>tmux</samp> manpage for the gory details.
You can also check the available key-bindings with <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>?</kbd>.
(the notation here can be a bit confusing:
<samp>bind-key</samp> is usually set to <kbd>Ctrl</kbd> + <kbd>b</kbd>,
so <samp>bind-key -T prefix d detach-client</samp> just means 
&#34;hit <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>d</kbd> to detach-client&#34;)
</p>

<h3 id="mouse">Copy Pasting: The Console Mouse</h3>

<p>
The console mouse daemon in Linux is <samp>gpm</samp>.
Many distros will have this enabled by default,
or at least will enable it if you install gpm.
In Slackware you can start the console mouse by:
<samp>chmod +x /etc/rc.d/rc.gpm</samp> and then reboot.
On System-D distros you can enable it with <samp>systemctl gpm.service start</samp>.
When <samp>gpm</samp> is running you should be able to see a square jump across the screen when you move your mouse,
this is the mouse &#34;pointer&#34;.
</p>

<p>
Copy pasting with <samp>gpm</samp> is actually straight forward.
left click and drag to mark text,
any marked text is automatically copied to the <samp>gpm</samp> clipboard.
You can paste it by middle clicking
(if you don&#39;t have a middle mouse button click both buttons simultaneously).
Why the middle mouse button?!?
Actually this is the standard UNIX method,
go ahead and try it on your desktop!
The inefficient left click + copy + left click + paste method stems from Windows.
</p>

<p>
Pasting text straight to the command prompt is not that practical however,
and opening up a text editor will clear the clipboard!
So how do we copy something and save it to a file?
Simple:
Run <samp>cat &lt;&lt; eof &gt; myfile</samp> and hit <kbd>enter</kbd>.
Now copy paste what you want,
when your finished write <samp>eof</samp> and hit enter.
The text is now saved in <samp>myfile</samp>.
If you find this solution confusing,
I recommend reading up a bit on shell redirection.
</p>

<p>
<i>Ps</i>:
BSD systems use <samp>moused</samp> as their console mouse driver,
but it works in just the same way as <samp>gpm</samp>
(Solaris systems don&#39;t have a console mouse AFAIK).
</p>

<h3 id="copy_paste_tmux">Copy Pasting: Tmux</h3>

<p>
<samp>tmux</samp> also works great for copy pasting text,
especially since you can run windows side by side and copy paste between them.
But learning the keybindings will take a bit of practice.
First hit <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>[</kbd> (ei. open bracket) to enter <i>copy mode</i>,
in this mode you can move the cursor around freely.
Navigate to the start of the text you want to copy and hit <kbd>Ctrl</kbd> + <kbd>Space</kbd>,
then navigate to the end of the text 
(the section you want should now be highlighted)
and hit <kbd>Alt</kbd> + <kbd>w</kbd>.
The text is now copied to the tmux clipboard.
You can paste it any time with <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>]</kbd> (ei. close bracket).
You can manipulate the clipboard in many useful ways,
read the documentation for further details.
</p>

<p>
If the above keybindings seemed weird,
your probably not to familiar with <samp>emacs</samp>.
By default tmux uses the <samp>emacs</samp> style keybindings in copy mode.
You can use <samp>vi</samp> style instead if you want,
just add <samp>set-option -g mode-keys vi</samp> to ~/.tmux.conf.
You can now copy-paste by hitting <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>[</kbd> to enter copy mode.
Start marked text with <kbd>Space</kbd>,
end it with <kbd>Enter</kbd>.
Finally paste it with <kbd>Ctrl</kbd> + <kbd>b</kbd> and then <kbd>]</kbd>.
</p>

<h3 id="sysadmin">Sysadmin</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/sysadmin.png"></a>
</p>

<p>
Now,
I know I promised that I wouldn&#39;t talk much about system administration.
But if you are going to use the console as a desktop,
you still need to know how do do some basic things,
like shutting down the system and so on.
In the following paragraphs we will therefore consider some basic sysadmin topics.
There sections are quite verbose since we are dealing with multiple operating systems,
but again,
you only need to read whatever is relevant for your setup.
</p>

<h3 id="shutdown">Shutting Down</h3>

<p>
There are various ways to shut down a computer,
many systems have
<samp>halt</samp>
and
<samp>reboot</samp>
for instance.
These commands are often just aliases for the
<samp>shutdown</samp>
command,
which is extremely ubiquitous
(even Windows has it for crying out loud!).
But it seems like every incarnation of this command behaves differently.
</p>

<ul>
<lh>Shutting down (now!) on various systems:</lh>
<li>Linux: <samp>shutdown -h now</samp></li>
<li>FreeBSD and DragonFly: <samp>shutdown -p now</samp></li>
<li>OpenBSD and NetBSD: <samp>shutdown -hp now</samp></li>
<li>Solaris/Illumos: <samp>shutdown -y -g 0 -i 5</samp></li>
<li>Windows/DOS: <samp>shutdown /s /t 0</samp></li>
</ul>

<ul>
<lh>Restarting (now!) on various system:</lh>
<li>Linux and BSD&#39;s: <samp>shutdown -r now</samp></li>
<li>Solaris/Illumos: <samp>shutdown -y -g 0 -i 6</samp></li>
<li>Windows/DOS: <samp>shutdown /r /t 0</samp></li>
</ul>


<h3 id="monitoring">Monitoring</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/glances.png"></a>
</p>

<p>
	One of the popular command line thrills,
	is to watch colorful streaming text,
	of presumably important information.
	The granddaddy monitoring application,
	is of course <samp>top</samp>.
	Which is the closest thing you will come to a taskmanager for the terminal
	(there is also the slightly more hip variant,
	<samp>htop</samp>).
	The BSD&#39;s ship with a very nice system monitoring app in addition,
	called <samp>systat</samp>.
	A nice alternative to <samp>systat</samp>,
	especially for non-BSD systems,
	is <samp>glances</samp>.
	And there are many,
	many other monitoring apps available.
	Just search your repository for programnames like &#34;top&#34; and &#34;mon&#34;.
	Personally I don&#39;t find these programs all that useful,
	but they are handy when you want to make a cool screenshot of your terminal ;)
</p>

<h3 id="disk">Disk Management</h3>

<p>
To check overall disk usage run the <samp>df -h</samp> command.
You can also check how much space a directory uses with <samp>du -hs mydir</samp>,
or recursively check how much space each file in this directory uses with <samp>du -ha mydir</samp>.
</p>

<p>
You can quickly check what disks are mounted on your system with <samp>mount | column -t</samp>,
or by checking the systems disk configuration file <samp>/etc/fstab</samp>.
Note that disks are handled very differently on UNIX then on Windows.
In Windows each disk is its own top level directory beginning with its drive letter,
such as <samp>C:\</samp>.
In UNIX a disk is represented as a file in <samp>/dev</samp> and is usually called something like <samp>sda</samp>,
and in contrast to Windows it can be mounted anywhere on the filesystem.
For example a common configuration is to put the root filesystem,
<samp>/</samp>,
on a fast but small SSD harddisk,
and have the home partition,
<samp>/home</samp>,
on a slower but bigger harddisk.
Or to have partitions that change files rapidly,
like <samp>/tmp</samp> or <samp>/var</samp>,
or faster harddisks.
The point is that you can arrange the disks anywhere you want in the filetree,
and with new filesystems like ZFS,
UNIX systems allow for even greater flexibility!
</p>

<p>
We cannot go into the finer details of every UNIX filesystem,
but as an example,
lets repartition and reformat a USB memory stick with the ultra archaic and portable DOS filesystem, 
and mount it:
</p>

<h4 id="disk_linux">Linux</h4>

<p>
After attaching the USB stick to your computer,
you can run the <samp>dmesg | tail</samp> command to see if your system has detected it.
You should be able to see something similar to this line towards the end:
</p>

<p>
<samp>[ 4198.053323] sd 8:0:0:0: [sdd] Attached SCSI removable disk</samp>
</p>

<p>
Don&#39;t worry to much about the details here,
what&#39;s important is that the kernel detected a <samp>removable disk</samp> and called it <samp>sdd</samp>.
Armed with this information we can now reformat our disk:
</p>

<pre><samp>
# <i>fdisk /dev/sdd</i>
&gt; <i>p</i> # Print a list of partitions that are on the disk
&gt; <i>d</i> # Delete the partition(s)
&gt; <i>n</i> # Create a new partition (just go with the defaults)
&gt; <i>t</i> # Change the partition type to <i>b</i> - W95 FAT32
&gt; <i>p</i> # List partitions and verify that everything looks correct
&gt; <i>w</i> # Write changes to disk
</samp>
</pre>


<p>
There are more user friendly alternatives to fdisk such as <samp>cfdisk</samp>,
but the classic <samp>fdisk</samp> command is easy enough once you have used it a couple of times.
Even though we have now created a new partition table on our memory stick,
we haven&#39;t actually created a filesystem on it.
Assuming the memory stick has only one partition,
we can create a fat filesystem on it like so:
<samp>mkfs.vfat /dev/sdd1</samp>
</p>

<p>
Now that our memory stick has a freshly reformatted filesystem,
how do we use it?
Well we need to mount it somewhere on the filesystem.
For instance if you run the command <samp>mount /dev/sdd1 /home/myuser/Documents</samp>,
you can access the memory stick from this directory.
Of course that&#39;s a rather daft place to put it since you then cannot access your documents.
So lets place it somewhere else
(don&#39;t worry,
your documents will pop back once we unmount the memory stick):
</p>

<pre><samp>
# <i>umount /home/myuser/Documents</i>
# <i>mkdir -p /mnt/usb</i>
# <i>mount /dev/sdd1 /mnt/usb</i>
</samp>
</pre>


<p>
And safely remove it by:
</p><pre><samp>
# <i>umount /mnt/usb &amp;&amp; eject /dev/sdd1</i>
</samp>
</pre>


<h4 id="disk_bsd">BSD</h4>

<p>
You can check what the usb stick is called with the <samp>dmesg | tail</samp> command,
or just by logging into tty1 and see what the kernel has written there.
On FreeBSD/DragonFly the device will be called something like <samp>da0</samp> and the first partition is <samp>da0s1</samp>.
On OpenBSD and NetBSD the device will be called something like <samp>sd0</samp>,
and you can then check what the partitions are called with <samp>disklabel sd0</samp>.
</p>

<p>
The <samp>fdisk</samp> command is slightly different on all the BSD versions,
so read the man page before using it.
On FreeBSD/DragonFly and NetBSD you can run <samp>fdisk -u diskname</samp>,
and an interactive process will guide you through the partitioning.
(make sure you choose file type <samp>11</samp> on your FAT partition).
In OpenBSD run <samp>fdisk -e diskname</samp> to edit the partition,
use file type <samp>0b</samp> for your FAT partition.
</p>

<p>
When all that is done you can use <samp>newfs_msdos disknamepartition</samp>
to create a new FAT 32 filesystem on it.
(on FreeBSD/DragonFly <samp>disknamepartition</samp> might be <samp>da0s1</samp>,
on OpenBSD/NetBSD it might be <samp>sd0i</samp> - check with <samp>disklabel</samp>)
</p>

<p>
On FreeBSD mount and safely remove it like so:
</p>

<pre><samp>
# <i>mkdir -p /mnt/usb</i>
# <i>mount -t msdosfs /dev/da0s1 /mnt/usb</i>
# <i>umount /mnt/usb</i>
# <i>sync</i>
</samp>
</pre>


<p>
On OpenBSD/NetBSD mount and safely remove it like so:
</p>

<pre><samp>
# <i>mkdir -p /mnt/usb</i>
# <i>mount /dev/sd0i /mnt/usb</i>
# <i>umount /mnt/usb</i>
# <i>eject /dev/sd0i</i>
</samp>
</pre>


<h4 id="disk_illumos">Solaris and Illumos</h4>

<p>
After you have inserted the USB stick,
you can look for its device name with the <samp>rmformat</samp> command.
It should produce an output similar to this:
</p>

<pre><samp>
Looking for devices...
	1. Logical Node: /dev/rdsk/c0t0d0p0
		...
		Connected Device: USB DISK 2.0 1219
		...
</samp>
</pre>


<p>
You can now edit the partition table of the disk with <samp>fdisk /dev/rdsk/c0t0d0p0</samp>.
The Illumos/Solaris <samp>fdisk</samp> program is similar to <samp>cfdisk</samp> on Linux and is straight forward to use.
Just make sure you create a <samp>D</samp> partition type and specify its size as <samp>100</samp> 
(assuming you want a single FAT 32 partition on the usb stick).
</p>

<p>
Finally create a FAT 32 filesystem on this partition with:
<samp>mkfs -F pcfs -o fat=32 /dev/rdsk/c0t0d0p0:c</samp>.
The memory stick should automatically be mounted under <samp>/media</samp>,
but you can manually mount it to a different location if you want:
</p>

<pre><samp>
# <i>umount /media/usbstick-name</i>
# <i>mkdir -p /mnt/usb</i>
# <i>mount -F pcfs /dev/dsk/c0t0d0p0:c /mnt/usb</i>
</samp>
</pre>


<p>
And safely remove it by:
</p><pre><samp>
# <i>umount /mnt/usb &amp;&amp; eject /dev/dsk/c0t0d0p0</i>
</samp>
</pre>


<p>
PS:
The <i>raw</i> disk devices in Illumos/Solaris is under <samp>/dev/rdsk</samp>.
It&#39;s this device you use when formatting a disk.
When mounting a disk however you use the <i>block</i> device under <samp>/dev/dsk</samp>.
</p>

<h4 id="disk_alternatives">Alternatives to FAT</h4>

<p>
The archaic FAT filesystem from MS-DOS is awkward to use under the best of circumstances.
It cannot store any files larger than 4 Gb,
and even worse it has no concept of UNIX file permissions,
these vital security settings will be wiped when you copy them over to a FAT memory stick.
You can work around this problem by bundling your files into a <samp>tar</samp> archive.
The file permissions will then be preserved, but it is awkward...
</p>

<p>
So why are people still using this rusty old filesystem,
aren&#39;t there any better alternatives?!?
Yes and no.
A popular choice is the newer Windows filesystem NTFS since it can store files larger than 4 Gb.
Of course it to has no concept of UNIX file permissions either,
so for UNIX users this isn&#39;t a good alternative.
(And even though Linux can use this filesystem there is considerably <i>less</i> support in the UNIX world for NTFS then FAT)
Why not just use a native UNIX filesystem on the memory stick?
</p>

<p>
You can,
and in many ways it is simpler then putting a FAT filesystem on it.
Tools such as <samp>mount</samp> and <samp>newfs</samp> for instance will assume a native filesystem by default.
And of course you can store large files on it,
and keep your permission settings.
But there is a catch!
Native UNIX filesystems have virtually <i>no</i> support on other operating systems,
including different versions of UNIX!
If you happen to only use FreeBSD machines at home and at work,
then by all means,
put UFS on your memory sticks!
But don&#39;t be surprised when Solaris refuses to mount them,
even though it too uses &#34;UFS&#34;.
The most portable UNIXy filesystem is probably old versions of the Linux EXT filesystem,
such as EXT2 or EXT3.
</p>

<p>
For better or worse,
DOS was a very simple and hugely popular operating system,
so support for its filesystem is ubiquitous.
There may not be many good alternatives to FAT,
but there are good alternatives to memory sticks,
such as
<samp>sftp</samp>, <samp>scp</samp> or <samp>sshfs</samp>,
which are all part of the <samp>ssh</samp> suit of programs.
Another excellent tool for syncing files across the network is of course <samp>rsync</samp>.
You can also set up permanent network file shares with NFS or Samba.
And of course ZFS filesystems allow you to easily share files across the network with other ZFS filesystems.
</p>

<h3 id="power">Power Management</h3>

<p>
On Linux you can use the <samp>acpi</samp> command to check your battery status and the <samp>powertop</samp> command to check which nasty interactive programs are sucking your battery dry.
You can suspend and hibernate System-D distros with <samp>systemctl suspend</samp> and <samp>systemctl hibernate</samp>.
For non-System-D disros you can probably use the <samp>pm-suspend</samp> and <samp>pm-hibernate</samp> commands from the <samp>pm-utils</samp> package.
</p>

<h4 id="power_freebsd">FreeBSD</h4>

<p>
You can check how much battery life you have left with <samp>acpiconf -i 0 | grep &#39;Remaining capacity&#39;</samp>
(your battery may have a different numerical ID then &#34;0&#34;).
If you enable apm services,
by adding <samp>apm_enable=&#34;YES&#34;</samp> and <samp>apmd_enable=&#34;YES&#34;</samp> to <samp>/etc/rc.conf</samp>,
you can:
</p>

<ul>
  <li><samp>acpiconf -s 1</samp>, put machine in standby mode</li>
  <li><samp>acpiconf -s 3</samp>, suspend machine</li>
  <li><samp>acpiconf -s 3</samp>, hibernate machine</li>
</ul>


<h4 id="power_openbsd">OpenBSD</h4>

<p>
If you enable the <samp>apmd(8)</samp> daemon by adding <samp>apmd_flags=&#34;&#34;</samp> to <samp>/etc/rc.conf.local</samp>,
you can:
</p>

<ul>
  <li><samp>apm -m</samp>, list how many minutes of battery life are left</li>
  <li><samp>apm -S</samp>, put machine in standby mode</li>
  <li><samp>apm -z</samp> or <samp>zzz</samp>, suspend machine</li>
  <li><samp>apm -Z</samp> or <samp>ZZZ</samp>, hibernate machine</li>
</ul>

<p>
You can still check your battery status even if you don&#39;t have <samp>apm</samp>,
by using <samp>sysctl</samp>.
Usually something like this will work: <samp>sysctl hw.sensors.acpibat0</samp>.
Figuring out exactly how much time you have left on your battery require a bit of arithmetic,
here is a simple example script:
</p>

<pre><samp>
#!/bin/sh
# battery - print how much battery life is left
# usage: battery

remaining=$(sysctl hw.sensors.acpibat0 | sed &#39;s/.*=//&#39; | awk &#39;/remaining/ { print $1 }&#39;)
chargerate=$(sysctl hw.sensors.acpibat0 | sed &#39;s/.*=//&#39; | awk &#39;/rate/ { print $1 }&#39;)
echo $(echo &#34;scale=2; ($remaining / $chargerate) * 60&#34; | bc) minutes of battery life left
</samp>
</pre>


<h4 id="power_netbsd">NetBSD</h4>

<p>
Like OpenBSD,
NetBSD also uses the <samp>apmd(8)</samp> daemon for power management.
Enable it by adding <samp>apmd=YES</samp> to <samp>/etc/rc.conf</samp>.
You can now:
</p>

<ul>
  <li><samp>apm -m</samp>, list how many minutes of battery life are left</li>
  <li><samp>apm -S</samp>, put machine in standby mode</li>
  <li><samp>apm -z</samp> or <samp>zzz</samp>, suspend machine</li>
</ul>

<h4 id="power_illumos">Solaris and Illumos</h4>

<p>
As far as I know Solaris/Illumos only support suspend for SPARC architectures with <samp>sys-suspend(1)</samp>.
You can retrieve battery information with the <samp>kstat</samp> command,
but like the non-apm OpenBSD solution you need to manually work out what this information means in practice.
Here is a simple example script that prints remaining battery percentage:
</p>

<pre><samp>
#!/bin/sh
# battery - print how much battery life is left
# usage: battery

lastfull=$(kstat acpi_drv | awk &#39;/last_cap/ { print $2 }&#39;)
remaining=$(kstat acpi_drv | awk &#39;/rem_cap/ { print $2 }&#39;)
echo $(echo &#34;($remaining * 100) / $lastfull&#34; | bc)% remaining
</samp>
</pre>


<h3 id="security">Security</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/security.png"></a>
</p>

<p>
	There is no such thing as a 100% secure system,
	rather,
	it&#39;s more a question of how much effort you are willing to put into it.
	Installing a shark infested moat around your house may provide good protection against common burglars,
	but not against paratroopers for instance.
	Pros and cons must be carefully weighed.
	Private citizens usually don&#39;t need to worry about paratroopers,
	but government agencies might.
	Is the expense and maintenance worth it?
	Is the added protection worth the inconvenience of having your clumsy kids accidentally tripping into the moat?
	(this absurd analogy is more relevant to system administration - indeed parenting - then you may think).
	In that vein,
	we will not talk about over engineered security mechanisms such as ACL, SELinux, PAM, Docker and so on,
	we will only talk about security basics that all system administrators need to know,
	and know well.
	Naturally the importance of system administration is directly proportionate to the number of users on the machine.
	If you only administrate yourself,
	the following topics are merely important.
	On a production server it&#39;s a matter of life and death!
</p>

<h4 id="user_mng">Users and Groups</h4>

<p>
	The core security concept in UNIX is managing user and group <i>permissions</i> to files.
	By setting file permissions you can include or exclude users from collaborating in common projects,
	from tweaking system configurations,
	and from running certain programs.
	Consider the following example:
</p>

<pre><samp>
	$ <b>ls -ld $HOME</b>
	drwxr-xr-x 81 dan dan 2560 May 26 15:38 /home/dan
	$ <b>ls -l /bin/sh</b>
	-r-xr-xr-x 3 root bin 617544 Apr 19 18:16 /bin/sh
	$ <b>chmod +w /bin/sh</b>
	chmod: /bin/sh: Operation not permitted
	$ <b>cp /bin/sh $HOME/sh</b>
	$ <b>chmod +w $HOME/sh</b>
	$ <b>ls -l $HOME/sh</b>
	-rwxr-xr-x 1 dan dan 617544 May 26 15:39 /home/dan/sh
</samp>
</pre>


<p>
	The information we are interested in here is the first string of characters after the <samp>ls -l</samp> commands.
	Ignoring the very first character,
	which tells us if it&#39;s an ordinary file or a directory,
	the characters show us whether or not the file has <b>read</b>,
	<b>write</b> or <b>execute</b> permissions for the <b>owner</b>,
	the <b>group</b> and <b>everyone</b> else.
	<samp>/home/dan</samp> has owner <samp>dan</samp> and group <samp>dan</samp>,
	with permission <samp>rwxr-xr-x</samp>.
	That is,
	the <b>owner</b> dan has permission to read,
	write and execute,
	<b>rwx</b>.
	The <b>group</b> dan has permission to read and execute,
	<b>r-x</b>.
	And so does <b>everyone</b> else,
	the last <b>r-x</b>.
	So no one except the file owner in this case can edit this directory.
	But everyone can look at the files,
	and indeed make a copy of the files to their directory and freely edit the copies.
	This last point is illustrated above,
	where we first tried to give write permissions to <samp>/bin/sh</samp>
	(a rather daft thing to do!).
	This was denied because only the file owner,
	<b>root</b>,
	is allowed to do so.
	Hence we made a private copy of it,
	and then made the necessary adjustments
	(naturally the owner of a copy is whoever made the copy).
	Note the security implications here:
	Anyone who can <i>read</i> a file,
	can make a copy,
	and subsequently modify and execute the copy!
</p>

<p>
	UNIX has always been an open share and share alike environment,
	business practices of AT&amp;T not withstanding,
	and the default file permissions reflect this somewhat.
	If we don&#39;t want to allow everyone access to snoop and copy our private files,
	we can simply run this command
	<samp>chmod 750 $HOME</samp>.
	With this set,
	our files are safe from prying eyes
	(well, not really - more on that later).
	If we want to grant other users the exclusive rights to read and copy our files,
	to work on some common project for instance,
	we can add them to the <b>dan</b> group.
	We could also have written the above command like so:
	<samp>chmod o-wx $HOME</samp>.
	This later form is perhaps easier to understand,
	it reads:
	for <b>others</b> (ei. everyone else) remove <b>write</b> and <b>execute</b> permissions.
	If we wrote <samp>ug+r</samp>,
	it would mean,
	for <b>user</b> (ei. the owner) and <b>group</b> give <b>read</b> permission.
	Often you will see the octal form however,
	which can be tricky to understand,
	but you only need to know a handful of common values to get by:
</p>

<ul>
		<li>755 - owner has rwx, group and others have r-x</li>
		<li>644 - same as the above, but nobody has execute permissions</li>
		<li>750 - owner has rwx, group has r-x, everyone else have no access</li>
		<li>640 - same as the above, but owner and group cannot execute file</li>
		<li>600 - only the owner can read or write this file</li>
	</ul>


<p>
	Now running the command <samp>chmod 750 $HOME</samp> will indeed prevent (almost) anyone from tampering with our home directory,
	but what about all of the files <i>within</i> this directory?
	Actually,
	in this case,
	a <samp>750</samp> permission in <samp>$HOME</samp> will prevent (almost) anyone outside of the dan group to see or use files anywhere below this directory.
	But there are situations where it might be desirable to recursively set file permissions throughout a directory.
	So lets assume that we want to set a <samp>750</samp> permission for all files and directories under <samp>$HOME</samp>,
	we could do so with the following command:
	<samp>chmod -R 750 $HOME</samp>.
	But this is a very sloppy thing to do!
	The problem is that we don&#39;t really want execute permissions on ordinary files,
	except of course our custom shell scripts and assorted programs in <samp>~/bin</samp>,
	we want a <samp>640</samp> permission on plain files,
	and only a <samp>750</samp> permission for directories
	(directories NEED execute permission!).
	Setting unnecessary execute permissions on plain files will not exactly mean the end of humanity,
	but it is definitely an uncouth move,
	and it will earn you newb points!
	The correct solution would be something more akin to this:
</p>

<pre><samp>
	$ <b>find $HOME \( -path &#34;*/bin/*&#34; -prune \) -o \
	              \( \( -type d -a -exec chmod 750 {} \; \) -o \
	                 \( -type f -a -exec chmod 640 {} \; \) \)</b>
</samp>
</pre>


<p>
	It&#39;s OK to admit that the above command scares you.
	We could simplify this operation by doing it in stages,
	and actually,
	it&#39;s fine if you just lazily use <samp>chmod -R</samp> in the privacy of your own home.
	I will not tell on you.
	Sloppiness isn&#39;t really a major issue unless you are working professionally as a sysadmin.
	If that is the case,
	the above command is nothing less then job security.
	Just make sure you type this whenever your boss is looking over your shoulder.
</p>

<p>
	To illustrate user and group management,
	we create a new user (bob),
	a new group (manhat),
	assign bob to this group,
	set the new user and group as owners for some files (in /var/manhattan),
	and lastly make this directory top secret for anyone outside of this group:
</p>

<pre><samp>
	# <b>adduser bob</b>
	# <b>groupadd manhat</b>
	# <b>usermod -a -G manhat bob</b>
	# <b>chown -R bob:manhat /var/manhattan</b>
	# <b>chmod 770 /var/manhattan</b>
</samp>
</pre>


<p>
	You can manipulate these new user and group settings by hacking the files in <samp>/etc/passwd</samp> and <samp>/etc/group</samp> as root,
	and in the heyday of AT&amp;T UNIX this was in fact the only way to add new users to the system.
	But this kind of wild west approach is considered bad practice today,
	its safer to use dedicated commands such as <samp>usermod</samp> and <samp>groupmod</samp>.
	To quickly check what groups you are a member of,
	type <samp>groups</samp>.
	The example above is on a Linux machine,
	annoyingly there is considerable variation in how users and groups are managed across UNIX systems.
	NetBSD and Solaris do not have <samp>adduser</samp>,
	use <samp>useradd -m bob</samp> instead.
	In FreeBSD <samp>groupadd</samp> and <samp>usermod</samp> must be prepended with <samp>pw</samp>,
	so <samp>pw groupadd manhat</samp>.
	In NetBSD and OpenBSD the usermod example would simply be
	<samp>usermod -G manhat bob</samp>.
	In Linux however this command,
	without the <samp>-a</samp> flag,
	will add bob to the manhat group,
	but remove him from any other group not mentioned.
	FreeBSD and Solaris essentially work the same way,
	but they don&#39;t have the append feature at all.
	So you either need to manually specify a full list of groups,
	eg. <samp>usermod -G adm,games,staff,manhat bob</samp>,
	or you need to construct an ungainly command such as:
	<samp>usermod -G $(awk -F: &#39;/bob/ { printf $1 &#34;,&#34; }&#39; /etc/group)manhat bob</samp>
	(these examples are for Solaris,
	in FreeBSD the later would be:
	<samp>pw usermod bob -G `awk -F: &#39;/bob/ { printf $1 &#34;,&#34; }&#39; /etc/group`manhat</samp>).
	There are other subtle differences and peculiarities to be aware of.
	BSD&#39;s have the unique concept of login classes,
	and Solaris has a thing about &#34;profiles&#34; for instance.
	As always,
	the sysadmins primary task is to read the manpages carefully!
</p>

<h4 id="sudo">To Be or Not to Be Root?</h4>

<p>
	It turns out that the secret manhattan project above isn&#39;t quite as secure as we may think.
	You see,
	UNIX systems have an all-powerful user called <b>root</b>.
	The root user can do <i>anything</i>,
	no restrictions whatsoever
	(of course the root user can set restrictions on himself,
	but he can also rescind them).
	This concept is a lot more powerful then a &#34;system administrator&#34;,
	that you will see on some non-UNIXy systems.
	The root user is not only able to configure the system any way he wants,
	but he can engage in deep brain surgery and wanton destruction as he pleases.
	Beyond file encryption it is impossible to hide anything from root.
	Windows users may find this disconcerting,
	but in actuality they have the exact same issue,
	it&#39;s just that their &#34;root&#34; user is an unknown,
	plausibly evil,
	corporate entity called Microsoft
	(MacOS and Android (and Ubuntu for that matter),
	being UNIX after all,
	have a real root
	- but like Microsoft,
	they try very hard to hide this fact from the user).
</p>

<p>
	You can switch to the root user by typing the command <samp>su</samp>
	(or <samp>su -</samp> to simulate a full login),
	followed by the root password.
	By the way,
	you can use this command to switch to any user you have the password for,
	eg. <samp>su bob</samp>.
	It goes without saying that your user passwords should be a well guarded secret.
	But the <i>root</i> password is something you do not share even with your closest confidant!
	To quote Micah 7:5:
</p>

<blockquote>
<i>
	``Trust ye not in a friend,
	put ye not confidence in a guide:
	keep the doors of thy mouth from
	her that lieth in thy bosom&#39;&#39;
</i>
</blockquote>

<p>
	With careful group management,
	it is quite possible to delegate system administration tasks to users without giving them root access.
	Users working on a web server may be part of the <samp>www</samp> group,
	in order to work on files in <samp>/var/www</samp> for instance.
	If these users also need to run some database,
	or other web server maintenance program,
	the sysadmin can just run <samp>chgrp www</samp> on these programs,
	and set permissions to 550,
	in order to allow <samp>www</samp> users to run them,
	but no one else.
	But root is so powerful,
	that the system administrator himself should not use it,
	if it can be avoided.
	To illustrate the danger,
	suppose you meant to type
	<samp>rm -rf $HOME/*</samp>
	but mistyped it:
	<samp>rm -rf $HIME/*</samp>.
	Congratulations!
	You have now deleted all files on your computer.
	Another,
	more subtle example:
	Suppose you are working in <samp>/var/www/mysite</samp>,
	and decide to delete the whole mess:
	<samp>rm -rf ../*</samp>
	Permission denied!
	<i>Oh really</i>,
	you think smugly to yourself,
	and type:
	<samp>su -</samp>,
	and then
	<samp>rm -rf ../*</samp>.
	Congratulations!
	You have now deleted all files on your computer
	(do you see why?).
	The point?
	Don&#39;t use root!
	This is where <samp>sudo</samp> comes into play.
	In it&#39;s simplest form,
	you can edit <samp>/etc/sudoers</samp>,
	and uncomment the line that says
	<samp>#%wheel ALL=(ALL) ALL</samp>,
	that is,
	remove the # sign.
	Then make sure that your user is a part of the <samp>wheel</samp> group,
	eg. <samp>usermod -a -G wheel myuser</samp> in Linux
	(some distros use <samp>sudo</samp> instead of <samp>wheel</samp> here).
</p>

<p>
	PS: Whenever you need to run some dangerous command,
	it&#39;s a good idea to check first with <samp>echo</samp>.
	For instance,
	the two disastrous file nuking commands mentioned above,
	could have easily been averted with a simple sanity check:
	<samp>echo rm -rf...</samp>
</p>


<p>
	With this in place,
	you can run <samp>sudo command</samp>,
	to execute this one command &#34;as root&#34;.
	That still makes you disturbingly powerful of course,
	but it is marginally better then monkeying about blindly as the root user,
	at the very least it makes you open up the briefcase before you hit the red button.
	Sudo also logs any commands executed by it.
	So assuming the computer survives the attempt,
	you will know who to blame when the dust settles.
	The true beauty of <samp>sudo</samp> however,
	is that it allows you do define very fine grained privileges.
	The above line could have been
	<samp>bob 192.168.0.12 = (operator) /bin/kill, /usr/bin/lprm</samp>,
	for instance.
	Meaning that the user bob can run the commands <samp>kill</samp> and <samp>lprm</samp> on the machine 192.168.0.12,
	but only as the operator user
	(eg. <samp>sudo -u operator kill</samp>).
	You can define aliases for users and commands and things,
	in order to administrate this.
	If we defined <samp>Host_Alias	CSNETS = 192.168.0.12, 128.138.204.0/24, 128.138.242.0</samp> for example,
	we could have written CSNETS instead of 192.168.0.12,
	to allow bob access to this list of machines.
</p>

<p>
	PS: Not all variants of UNIX come with sudo by default,
	and some have their own sudoy kind of commands
	(eg. <samp>pfexec</samp> in Solaris and <samp>doas</samp> in OpenBSD).
	But all UNIX systems have sudo in their repositories at least.
</p>

<h4 id="ssh">Remote Connections</h4>

<p>
	About a thousand years ago,
	when vikings roamed the sea and pillaged unsuspecting Monasteries,
	people used <samp>telnet</samp> to login to their remote UNIX machines.
	It was truly a barbaric time when &#34;security&#34; was an unknown concept.
	Today of course we use <samp>ssh</samp> to connect safely,
	and civilly,
	to our remote machines.
	But simply having <samp>ssh</samp> will not magically make the world around you safe.
	You need to use this tool <i>correctly</i>.
	In a word,
	this means:
	disable password authentication.
</p>

<p>
	By default,
	an ssh server will accept a password login from anyone who has an account on the machine.
	Naturally this has to be the default,
	it would be impossible to set up a remote server otherwise.
	But the very first thing you should do on your shiny new server,
	is to set up public key authentication and then DISABLE password authentication!
	Passwords are a good way to protect your laptop from benevolent coworkers,
	it is NOT a safe way to protect your server out there on the hostile internet.
	There exists a network of bots on the web,
	dubbed the &#34;Hail Mary Cloud&#34;,
	that will systematically probe any ssh server.
	This cloud will try to login to your server a few times from one ip address,
	then try again with another ip,
	and so on and so on...
	If you allow password authentication on your remote ssh server,
	it will get compromised,
	its simply a matter of time.
</p>

<p>
	The answer to this problem is public keys.
	To understand why,
	we can use a simple analogy:
	Suppose you have set up a secret pirate club in downtown New York,
	with a big flashy neon sign that says
	&#34;secret password required upon entry!&#34;
	Well,
	daily you&#39;ll be pestered with kids trying to guess the password,
	and eventually one of them will get it right,
	before long half of New York City will enter your top secret pirate den.
	The point?
	Use keys.
	Anyone who now wants to sneak into your club,
	must first accost a pirate and steal his key.
	Naturally,
	the bouncer should still ask for a secret password,
	for added security against such an event.
	To create an ssh key on your laptop run <samp>ssh-keygen</samp>.
	Once this is done,
	copy your key over to the server with:
	<samp>cat ~/.ssh/id_rsa.pub | ssh myserver &#39;cat &gt;&gt;~/.ssh/authorized_keys&#39;</samp>.
	When you now log on to your server with <samp>ssh</samp>,
	it should say: <samp>Enter passphrase for key...</samp>.
	When you have verified in this way that your key is working,
	go ahead and disable password authentication on your ssh server.
	Edit <samp>/etc/ssh/sshd_config</samp>,
	and add these options:
</p>

<pre><samp>
	ChallengeResponseAuthentication no
	PasswordAuthentication no
	PubkeyAuthentication yes
</samp>
</pre>


<p>
	From the server you can copy your <samp>authorized_keys</samp> file to other ssh servers with:
	<samp>ssh-copy-id</samp>,
	to allow your laptop to access these remote machines using the same key.
	<i>However</i>,
	you want to create unique keys for <i>each</i> physical laptop/workstation that you are using.
	It is possible to use one key for multiple machines,
	just as it is possible to use one physical key for many houses,
	but it is very dumb thing to do!
	It is also possible to set up your ssh key without requiring a passphrase.
	This is actually <i>slightly</i> more secure than using password authentication,
	but it is nevertheless <i>bad</i> practice.
	The passphrase isn&#39;t used to authenticate against the server,
	the key is used for that,
	rather,
	the passphrase is used to decrypt a key <i>locally</i>.
	The reason for this security measure is to protect your key in case it is stolen.
	If your laptop is compromised,
	and they are easily compromised,
	the intruder can use unencrypted keys to access your remote servers.
	If your keys are encrypted with a passphrase however,
	the keys are of no use to the intruder.
</p>

<p>
	Once you have enabled key authentication,
	you can simplify things a bit further by using an ssh agent.
	On the console,
	you can type <samp>ssh-agent sh</samp>
	(or use whatever shell you prefer),
	and then <samp>ssh-add</samp>.
	You will be asked to type in your passphrase.
	Once done,
	the decrypted ssh keys will be saved in memory,
	and subsequently used whenever you run an <samp>ssh</samp> command.
	So in effect,
	you type the passphrase once,
	and use <samp>ssh</samp> throughout the day without typing in any passwords.
	This convenient approach is <i>not safe</i> if you share your computer with multiple users.
	Before taking a break at work,
	type <samp>ssh-add -D</samp> to flush the keys,
	then retype <samp>ssh-add</samp> when you get back from lunch
	(and obviously - shut down the computer before you leave for the day).
</p>

<p>
	PS: Unfortunately the method of starting an ssh agent varies considerably between desktop environments and login managers,
	not to mention Windows.
	So consult your operating systems/desktops documentation,
	if you want to set up an ssh agent outside of the text console
	(also,
	the <samp>ssh-agent</samp> command must be executed on each virtual console you wish to use it on).
	To be clear: it&#39;s not very hard to set up,
	but it&#39;s hard to <i>document</i>,
	since it varies so.
</p>

<p>
	You can do a <i>lot</i> of stuff with ssh.
	You can use it to secure network traffic that isn&#39;t otherwise encrypted.
	You can do remote desktop work with it.
	You can set up your own private VPN with ssh,
	and you can mangle the network in all kinds of other interesting ways.
	These topics are well outside the scope of this article,
	if you are interested,
	check out <i>SSH Mastery</i> by Michael W. Lucas.
	Lucas has a wide array of other high quality books that security minded UNIX sysadmins will likely find both beneficial and humorous.
	Some suggestions are: <i>Sudo Mastery</i>,
	<i>PAM Mastery</i>,
	<i>PGP &amp; GPG</i> and many others.
	Check out
	<a href="https://mwl.io">his website</a>
	if you are interested.
</p>

<h4 id="passwords">Passwords</h4>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/password_strength.png"></a>
</p>

<p>
	Like SSH,
	things are not magically secure just because you have a password.
	You need to use passwords <i>correctly</i>.
	There are two steps involved.
	First,
	you want long passwords that isn&#39;t easy to break.
	A good way is to find some obscure text that is very unique to you,
	an old Christmas card from a long gone relative,
	a really obscure magazine from the attic of your grandfather,
	or just some random sentence that only you can understand.
	Do not use short passwords,
	however obfuscated,
	nor anything from pop culture.
	&#34;He&#39;s dead Jim&#34; or &#34;p455w0rd&#34; are <i>not</i> safe passwords!
	&#34;H√∏yesterettsjustitiariussjefsassistenten e en bondekn√∏lbavianbajas fra H√•logalandbisped√∏mmes ytterste gudsf√∏rlatte feskev√¶r!!!&#34;
	<a text="Loosely translated: " the="" supreme="" justices's="" chief="" assistant="" is="" an="" ape="" scalawag="" bumpkin="" from="" the="" remotest="" godforsaken="" fishing="" village="" in="" the="" halogaland="" parish"="">*</a>
	is a resonably good password
	(and easily remembered if you happen to be a Northern-Norwegian).
</p>

<p>
	Secondly,
	and <i>most importantly</i>,
	use different passwords for different things.
	Do NOT use the same password over and over again
	(and for the love of Mike - do NOT write down your passwords on post-it notes!).
	<i>But I cannot remember a whole bunch of passwords!</i>
	you may think.
	Of course you can&#39;t,
	nobody can.
	If you are trying to remember your passwords,
	<i>you are doing it wrong!</i>
	Use a password manager.
	A password manager is like a secure post-it note.
	It requires a password to open,
	and once opened,
	you can freely read and edit a list of your passwords.
	So in effect,
	you use one password to access all your other passwords.
	If you are working on a graphical desktop,
	I recommend that you use KeePass,
	or one of it&#39;s variants (eg. KeePassXC).
	If you are working on the console,
	you can easily
	<a href="#password_mng">make your own password manager</a>.
</p>

<h3 id="interactive">Making Things Interactive</h3>

<p>
Another problem with using the console as a desktop is that things aren&#39;t interactive,
there&#39;s no menu for finding applications or clickable icons for launching your favorite programs,
even just a flippin progress bar for your <samp>cp</samp> would be nice!
Settle down,
there are solutions for all of this and more...
</p>

<h4 id="shortcuts">Creating Shortcuts</h4>

<p>
Although you cannot create graphical icons for launching a program in the console,
you certainly can create shortcuts.
For example,
you can add this to your <samp>~/.profile</samp>
(or <samp>~/.bashrc</samp> if you plan to use them from X):
</p>

<pre><samp>
alias web=links
alias edit=nano
alias files=mc
alias play=mplayer
alias picture=fbi
alias game=myman
</samp>
</pre>


<p>
You can now edit files by typing <samp>edit</samp>,
play video and music with <samp>play</samp>,
view your files with <samp>files</samp>,
and so on.
If you are having trouble remembering your own aliases,
just run the command <samp>alias</samp> to see a list of them.
</p>

<p>
Aliases are also useful for running a command with a default set of flags,
for example I usually set <samp>alias lynx=&#39;lynx -accept_all_cookies -assume_charset=utf8 -tagsoup&#39;</samp>,
which makes the console browser <samp>lynx</samp> behave nicer.
Aliases are nice for oneliners,
but for serious automation you need shell scripts.
A good tip is to place this is your <samp>~/.profile</samp>
(or other appropriate place):
<samp>export PATH=$HOME/bin:$PATH</samp>.
This line adds <samp>$HOME/bin</samp> to your list of default program paths,
you can now write your shell scripts in this directory,
and launch them from anywhere.
</p>



<p>
Serious powerusers <i>do not</i> use menus of course,
like an efficient dictator in a banana republic,
he simply states his will in clear unmistakable language and watches it happen,
he does not ask to see the <i>menu</i> first!
But suppose you are a sysadmin in a company,
and the above set of aliases are just too hard for one of your newb colleagues to remember.
The only way this poor fellow can manage to launch an application is if he can write the command <samp>thing</samp>,
and then select his desired application from a menu.
Can you still force this <s>luser</s> user to use the console?
</p>

<p>
Certainly,
if all you need is a static menu,
then <samp>select</samp> might do the trick
(PS: not all UNIX versions of <samp>sh</samp> support <samp>select</samp> - and not all versions of select behave in the same manor):
</p>

<pre><samp>
#!/bin/sh
# thing - launch applications
# usage: thing

selectfile(){
    echo -n &#34;File: &#34;
    read file
    if [ ! -f &#34;$file&#34; ]; then
        echo &#34;Error: file doesn&#39;t exist!&#34;
        exit
    else
        exec &#34;$1&#34; &#34;$file&#34;
    fi
}

select prog in Web Edit Files Play Picture Game; do
    case $prog in
        Web)    echo -n &#34;URL: &#34;
                read url
                exec links $url
                ;;
        Edit)   selectfile nano ;;
        Files)  exec mc ;;
        Play)   selectfile mplayer ;;
        Pict*)  selectfile cacaview ;;
        Game)   exec vitetris ;;
        *)      echo &#34;Please choose a number!&#34;
    esac
done
</samp>
</pre>


<p>
You can also easily write a welcome message that all users will see as they login to the system,
just by putting the text into <samp>/etc/motd</samp>
(motd means &#34;message of the day&#34;).
If you just want to give a specific user a message as he logs in,
you can just put something like this is his <samp>~/.profile</samp> (or <samp>~/.bashrc</samp>):
<samp>cat /path/to/some/instructions</samp>,
or even just:
<samp>echo to do something dear newbie type &#34;thing&#34; without the quote marks.</samp>
(admittedly,
the kind of user who needs such a menu,
would have a hard time understanding how to type &#34;thing&#34; without the quote marks...)
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/gui.png"></a>
</p>

<p>
If you want a more &#34;GUI-like&#34; experience though,
<samp>dialog</samp> is your friend.
This program can create a large set of standard GUI widgets with ncurses graphics,
such as radiolists,
progressbars,
file and calendar selections etc...
You can even play Microsoft and create a whole chain of &#34;are you sure&#34;,
&#34;are you *REALLY* sure&#34; yes-or-no boxes to make that professional vibe and annoy your users to no end.
The above example in <samp>dialog</samp> would be:
</p>

<pre><samp>
#!/bin/sh
# thing - launch applications, using ncurses
# usage: thing

tmp=/tmp/menu
while true; do
    dialog --menu &#34;Startup Menu&#34; 0 0 0 1 &#34;Web&#34; 2 &#34;Edit&#34; 3 &#34;Files&#34; 4 &#34;Play&#34; 5 &#34;Picture&#34; 6 &#34;Game&#34; 2&gt; $tmp
    if [ $? = 1 ]; then
        exit
    fi

    selectfile(){
        dialog --title &#34;Files&#34; --fselect $HOME/ 0 0 2&gt;$tmp
        if [ $? = 0 ]; then
            file=$(cat $tmp)
            exec &#34;$1&#34; &#34;$file&#34;
        fi
    }

    prog=$(cat $tmp)
    case $prog in
        1)  dialog --title &#34;URL&#34; --inputbox &#34;Enter website address:&#34; 0 0 2&gt; $tmp
            if [ $? = 0 ]; then
               url=$(cat $tmp)
               exec links $url
            fi
            ;;
        2)  selectfile nano ;;
        3)  exec mc ;;
        4)  selectfile mplayer ;;
        5)  selectfile cacaview ;;
        6)  exec vitetris ;;
    esac
done
</samp>
</pre>


<h4 id="progress">Progressbars and Interactive Pipes</h4>

<p>
Most UNIX console programs follow &#34;the rule of silence&#34;.
This rule simply states that the users time and concentration is valuable,
so do your work silently and only report back if the task is complete or if something went horribly wrong,
don&#39;t pester him with trivia.
To be frank,
this concept is very hard for a casual desktop user even to understand.
You assume that my time and concentration is <i>valuable</i>,
what kind of lame excuse is that,
how dare you give me the silent treatment?!?
Imagine shouting at a respectful butler for delivering your letters like you asked him to,
<i>without</i> calling every other second to report how many steps he had taken towards the mailbox!
Truthfully,
modern computer systems have become little more then narcissistic training boxes.
Experienced UNIX users actually enjoy a system that doesn&#39;t constantly second guess them or bother them with irrelevant information.
The tranquility and peace of mind that the rule of silence provides is in fact one of the main benefits of using UNIX.
Sometimes however you need to know how a command is progressing,
is there a progressbar or something for the console?
</p>

<p>
Yes.
First though,
if you are lucky enough to use FreeBSD,
you can hit <kbd>Ctrl</kbd> + <kbd>t</kbd> at any time,
to see how a program is progressing.
GNU (read Linux) utilities does not have this feature,
but there is a program,
appropriately named <samp>progress</samp>,
which will tell you the progress of standard coreutils programs,
such as <samp>cp</samp> or <samp>mv</samp>.
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/console.png"></a>
</p>

<p>
You can also create your own progressbar with <samp>pv</samp> (pipe viewer),
it functions like <samp>cat</samp>,
but reports its progress.
So <samp>pv bigfile &gt; bigfilecopy</samp>,
will copy the file with a progressbar.
You can also stick <samp>pv</samp> in the middle of a pipeline and see how it&#39;s progressing,
eg. <samp>cat file | pv -s $(du file | awk &#39;{ print $1 }&#39;) | nc -w 1 somewhere.com 3000</samp>.
In this example we need to tell <samp>pv</samp> how large the file is with <samp>-s $(du file | awk &#39;{ print $1 }&#39;)</samp>.
Without this <samp>pv</samp> will still report write speed,
but it will not know when the job is nearing it&#39;s completion.
</p>

<p>
You can also manipulate pipelines interactively in other ways.
For example the <samp>percol</samp> program (Linux only) will let you interactively select elements from the pipe input and send it down the line,
eg. <samp>ls | percol | du -h</samp>.
A somewhat similar program from the <samp>moreutils</samp> package,
<samp>vipe</samp>,
which is also available on non-Linux systems,
will let you edit the input with <samp>vi</samp>,
once you exit the editor,
the modifications will be sent down the pipe.
</p>

<h4 id="auto">Autocompletion</h4>

<p>
You must know how to read and write in order to use the console,
but contrary to popular belief,
you don&#39;t need to write much.
Use the <samp>tab</samp> key to auto-complete filenames.
So don&#39;t type <samp>cd /really-long-AND-obscure_path/to_my_file-SomeWhErE</samp>,
just type <samp>cd /r</samp> then hit <samp>tab</samp>,
if it doesn&#39;t complete fully,
hit <samp>tab</samp> again to get a list of alternative matching files,
type one or two letters more and hit a final <samp>tab</samp>.
You have now typed a total of 9 keys,
instead writing out all the 53 characters by hand!
You should also learn to use some basic regex:
Don&#39;t run the command <samp>rm &#34;Aqua/I&#39;m A Barbie Girl.mp3&#34; &#34;Aqua/Doctor Jones.mp3&#34;</samp>,
run <samp>rm Aqua/*.mp3</samp>
(or better yet <samp>rm -rf Aqua &amp;&amp; echo Good Riddance!</samp>).
</p>

<p>
The <samp>bash-completion</samp> package will let your <samp>bash</samp> shell auto-complete more then just filenames.
But for serious auto-completion power I recommend switching your default shell to <samp>zsh</samp>
(And for your grandma I recommend <samp>fish</samp>).
</p>

<h4 id="fun">Having Fun</h4>

<p>
Alright,
you&#39;re thinking,
so you can do quite a lot of functional things with the console,
but to be honest:
The reason I still want to use the desktop,
is because it is fun!
I want to goof around with
<a href="#framebuffer">wallpapers</a>,
<a href="#misc">screensavers</a>,
<a href="#game">games</a>,
<a href="#desktop_console">3D desktop cubes</a>,
watch <a href="#video">youtube</a> videos,
and you know what,
I really enjoy constantly <a href="#desktop_console">resizing my windows</a>.
Seriously,
I get a kick out of it.
You just can&#39;t do that in the console!
Oh really?
Check out the links in the above paragraph...
If on the other hand,
you just want to go on the web,
keep reading :)
</p>

<h2 id="web">The Web</h2>

<h3 id="connect">Connecting to the Internet</h3>

<p>
Running <samp>ifconfig</samp> is a quick way to check your network settings,
pay particular attention to your network card names.
In Linux the wired network card is often called <samp>eth0</samp>,
and the wireless card <samp>wlan0</samp>,
but not always.
Other UNIX operating systems use different names.
Pinging a website
(eg. <samp>ping www.wikipedia.org</samp>)
is a quick way to check that your online,
but remember that this will usually not work from a virtual machine.
Connecting to the web over a wired network is often done with <samp>dhclient eth0</samp> or <samp>dhcpcd eth0</samp>.
</p>

<p>
You may be using a version of Linux that doesn&#39;t have <samp>ifconfig</samp>,
in that case you need to use the <samp>ip</samp> command instead.
Here is a quick ip to ifconfig cheat sheet:
</p>

<pre>ifconfig			ip a
ifconfig eth0 up		ip link set eth0 up
ifconfig eth0 down		ip link set eth0 down
ifconfig eth0 add 10.0.0.1/24	ip a add 10.0.0.1/24 dev eth0
ifconfig eth0 del 10.0.0.1/24	ip a del 10.0.0.1/24 dev eth0
</pre>


<p>
How about connecting to a wireless network?
On Linux the easiest way to do this is usually with <samp>nmcli</samp>,
a command line front-end to NetworkManager,
which should be available by default.
You can list available networks: <samp>nmcli dev wifi list</samp>,
connect to a network: <samp>nmcli dev wifi con mynetwork password mypassword</samp>.
</p>

<h4 id="wifi">Wifi without NetworkManager</h4>

<p>
If you aren&#39;t using Linux,
or your version of Linux doesn&#39;t have NetworkManager
(or you don&#39;t <i>want</i> to use it),
you can probably use <samp>wpa_supplicant</samp> to connect to your wifi.
First write a default configuration file in <samp>/etc/wpa_supplicant.conf</samp>:
</p>

<pre><samp>
network={
	ssid=&#34;my home network&#34;
	scan_ssid=1
	key_mgmt=WPA-PSK
	psk=&#34;mypassword&#34;
}
</samp>
</pre>


<p>
With this in place we can make our connection.
First make sure your wifi card is activated: <samp>sudo ifconfig wlan0 up</samp>.
Then start wpa_supplicant: <samp>sudo wpa_supplicant -B -c/etc/wpa_supplicant.conf -iwlan0</samp>
And finally request an ip address form the wireless router: <samp>dhclient wlan0</samp>.
You should now be connected!
</p>

<p>
If you only plan on ever connecting to a single wireless network,
then this is enough.
(actually in such a case you should probably invest in an ethernet cable...)
But if you need to connect to wireless networks arbitrarily,
manually editing the wpa_supplicant.conf file every time is tedious.
You can write the following <samp>wifi</samp> script to handle things automatically:
</p>

<pre><samp>
#!/bin/sh
# wifi - connect to a wifi network
# usage: wifi network password
wlan=${wlan:-wlan0}
sed -i -e &#34;s/ssid=.*/ssid=$1/&#34; -e &#34;s/psk=.*/psk=$2/&#34; /etc/wpa_supplicant.conf
ifconfig $wlan up
wpa_supplicant -B -c/etc/wpa_supplicant.conf -i$wlan
dhclient $wlan
</samp>
</pre>


<p>
You can now run the script: <samp>sudo wifi &#39;my home network&#39; password</samp>.
(or <samp>wlan=wlan1 sudo wifi &#39;my home network&#39; password</samp> if your device isn&#39;t <samp>wlan0</samp>)
There are a few problems with this script though:
The script does not check for errors,
such as badly written arguments.
Running <samp>sudo wifi my home network password</samp> would fail without giving you any obvious error messages 
(do you see why?).
It doesn&#39;t list available wifi networks,
for that you probably need <samp>iwlist</samp>.
And it stores your password as plain text,
you should probably use <samp>wpa_passphrase</samp> to encrypt it.
(you may also need to use <samp>dhcpcd</samp> instead of <samp>dhclient</samp>).
All of these issues can be addressed,
but I leave that as an exercise for the reader.
</p>

<p>
As a side note,
you should never configure your wireless router to accept connections without a password,
or to use WEP encryption,
which is more or less the same thing.
If you <i>do</i> need to connect to a WEP router,
use <samp>iwconfig</samp> not <samp>wpa_supplicant</samp>.
</p>
<p>
<b>Update:</b>
Actually it turn out that you shouldn&#39;t use 
<a href="https://www.theguardian.com/technology/2017/oct/16/wpa2-wifi-security-vulnerable-hacking-us-government-warns">wpa/wpa2</a> either... 
hm...
Maybe IP over 
<a href="https://en.wikipedia.org/wiki/IP_over_Avian_Carriers">carrier pigeons</a>
is the safe option?
Of course that method has security concerns as well,
such as cats...
</p>

<p>
You can use a password manager to store network passwords,
and use a simple script to automatically search this encrypted database and connect to your network,
as discussed in the
<a href="#password">password manager</a>
section below.
</p>

<h4 id="wifi_freebsd">FreeBSD and DragonFly BSD</h4>

<p>
With the exception of OpenBSD,
all the BSD&#39;s use wpa_supplicant to connect to wireless networks,
as described above.
Although the mechanism is basically the same,
some of the particulars vary.
The first issue in FreeBSD is simply enabling the wireless network card.
You can run <samp>sysctl net.wlan.devices</samp> to get the name of your card,
it might be something like <samp>iwm0</samp>.
You can get more information by analyzing the output of <samp>pciconf -lv</samp>,
or just by running <samp>dmesg | grep Wireless</samp>.
This last command might return something like this:
</p>

<pre><samp>
iwm0: <intel(r) dual="" band="" wireless="" ac="" 8265=""> mem 0xec000000-0xec001fff irq 18 at device 0.0 on pci5
</intel(r)></samp>
</pre>


<p>
Now that we know we are using an Intel iwm 8265 wireless network card,
we can go ahead and configure FreeBSD to load up the correct firmware and other necessities at boot time,
by adding these values to <samp>/boot/loader.conf</samp>:
</p>

<pre><samp>
if_iwm_load=&#34;YES&#34;
iwm8265fw_load=&#34;YES&#34;
legal.intel.ipw.license_ack=1
legal.intel.iwm.license_ack=1
legal.intel.iwi.license_ack=1
wlan_wep_load=&#34;YES&#34;
wlan_ccmp_load=&#34;YES&#34;
wlan_tkip_load=&#34;YES&#34;
</samp>
</pre>


<p>
Boy,
that was a lot of work!
From here though,
things get easier.
The next step is to write a <samp>/etc/wpa_supplicant.conf</samp> file for your wireless network,
it might look something like this:
</p>

<pre><samp>
network={
    ssid=&#34;mynetwork&#34;
    psk=&#34;mypassword&#34;
}
</samp>
</pre>


<p>
Finally,
we can configure the system to start wpa_supplicant at boot time:
</p>

<pre><samp>
# <i>echo wlans_iwm0=&#34;wlan0&#34; &gt;&gt; /etc/rc.conf</i>
# <i>echo ifconfig_wlan0=&#34;WPA DHCPSYNC&#34; &gt;&gt; /etc/rc.conf</i>
# <i>service netif restart</i>
</samp>
</pre>


<p>
You should now be connected to the wireless network!
You can switch to another wireless network manually by editing <samp>/etc/wpa_supplicant.conf</samp>,
and then run <samp>service netif restart</samp> again.
But we can also make a short script that automates this:
</p>

<pre><samp>
#!/bin/sh
# wifi - connect to a wifi network (FreeBSD edition)
# usage: wifi network password
sed -i &#39;&#39; -e &#34;s/ssid=.*/ssid=$1/&#34; -e &#34;s/psk=.*/psk=$2/&#34; /etc/wpa_supplicant.conf
service netif restart
</samp>
</pre>


<p>
PS: The process of connecting to a wireless network in DragonFly BSD is exactly the same,
with one exception:
The DragonFly kernel is preconfigured to use any wireless devices currently supported,
so just write your <samp>/etc/wpa_supplicant.conf</samp> and add a few values in /etc/rc.conf,
and you are good to go!
</p>

<h4 id="wifi_netbsd">NetBSD</h4>

<p>
Setting up a wireless network in NetBSD is easy peasy,
compared to FreeBSD at least ;)
First write a configuration file for your wireless network in <samp>/etc/wpa_supplicant.conf</samp>,
it might look something like this:
</p>

<pre><samp>
ctl_interface=/var/run/wpa_supplicant
ctl_interface_group=wheel
network={
	ssid=&#34;mynetwork&#34;
	psk=&#34;mypassword&#34;
}
</samp>
</pre>


<p>
Now add the following values to <samp>/etc/rc.conf</samp>
(this example assumes your network card is called &#34;iwn0&#34;,
it may be called something else):
</p>

<pre><samp>
wpa_supplicant_flags=&#34;-i iwn0 -c /etc/wpa_supplicant.conf&#34;
dhcpcd=YES
</samp>
</pre>


<p>
Now reload network settings with <samp>/etc/rc.d/wpa_supplicant reload</samp>,
and you should be connected.
To change to a different wireless network,
you can edit <samp>/etc/wpa_supplicant.conf</samp>,
and run <samp>/etc/rc.d/wpa_supplicant reload</samp> again.
Naturally you can automate this,
here is a NetBSD version of the above wifi script:
</p>

<pre><samp>
#!/bin/sh
# wifi - connect to a wifi network (NetBSD edition)
# usage: wifi network password
sed -i -e &#34;s/ssid=.*/ssid=$1/&#34; -e &#34;s/psk=.*/psk=$2/&#34; /etc/wpa_supplicant.conf
/etc/rc.d/wpa_supplicant reload
</samp>
</pre>


<h4 id="wifi_openbsd">OpenBSD</h4>

<p>
If you feel confused after reading the above sections,
you should be!
It is worth mentioning that <i>OpenBSD</i> is the only operating system in the UNIX world that connects to a wireless network in a sensible way:
<samp>ifconfig iwn0 nwid &#39;my home network&#39; wpakey mypassword</samp>
followed by
<samp>dhclient iwn0</samp>.
And how do you scan for wireless networks?
<samp>ifconfig iwn0 scan</samp>.
This last command also works for the other BSD&#39;s btw.
(<samp>iwn0</samp> is a typical wireless card name in OpenBSD,
and <samp>em0</samp> is a typical ethernet card name,
but your devices may have different names).
Other operating system developers could learn a <i>lot</i> from the OpenBSD weirdos :)
</p>

<h4 id="wifi_illumos">Solaris and Illumos</h4>

<p>
As for Illumos it has it&#39;s own &#34;NetworkManager&#34; called NWAM,
which if running will try to connect you to any known wifi or ethernet links automatically.
You can also scan for wireless networks with <samp>dladm scan-wifi</samp> and connect to one like so: <samp>dladm connect-wifi -e &#39;my home network&#39; wpi0</samp>
(<samp>wpi0</samp> is a typical wireless card name in Solaris,
and <samp>e1000g0</samp> is a typical ethernet card name,
but your devices may have different names).
</p>

<p>
It is possible to disable NWAM and use ifconfig manually.
For instance,
these commands will disable NWAM and manually request an ip address from your DHCP server
(to switch back to NWAM, disable &#34;default&#34; and enable &#34;nwam&#34;):
</p>

<pre><samp>
svcadm disable network/physical:nwam
svcadm enable  network/physical:default
ifconfig wpi0 dhcp
</samp>
</pre>

<h3 id="browsing">Browsing</h3>

<p>
The modern web browser is a beast,
and not in a good way...
In fact Firefox has about 25 million lines of code,
and is bigger then Linux kernel and the entire KDE4 suit of applications combined
(as of 2019, as time goes by these statistics will only grow worse)!
Expecting something like this to work in the text-based UNIX console is hopelessly unrealistic.
Sadly this is one area where the console does not,
and cannot,
impress.
</p>

<p>
Having that said there are a number of internet browsers available for the console.
The classic choice is <samp>lynx</samp>,
its a bit like <samp>vi</samp> in that you need to learn a whole set of key-bindings before it becomes useful.
But like <samp>vi</samp> it is very fast and efficient once learned.
You can check these key bindings by starting <samp>lynx</samp> and typing <kbd>?</kbd>.
A more user-friendly alternative is <samp>links</samp>.
It has a nice drop down menu accessible with <kbd>Esc</kbd>.
</p>

<p>
<i>PS:</i>
none of these browsers support anything like javascript or flash!
</p>

<p>
For a more graphical experience (Linux only) you can run <samp>links -g</samp>,
if the
<a href="#framebuffer">framebuffer</a>
has been configured.
<samp>w3m</samp>
is also capable of rendering images in the framebuffer
(in debian you want the <samp>links2</samp> and <samp>w3m-image</samp> packages).
</p>

<p>
Perhaps the most impressive framebuffer browser is <samp>NetSurf</samp>,
it even has some rudimentary javascript support
(in debian install <samp>netsurf-fb</samp>).
In many distros this package has a serious bug:
you can work around it by copying some font files:
<samp>cp /usr/share/fonts/truetype/dejavu/* /usr/share/netsurf</samp>
A graphical browser in a Linux console sure looks impressive,
but don&#39;t expect them to replace Firefox or Chrome anytime soon...
</p>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/web.png"></a>
</p>

<h3 id="webapps">Web Apps</h3>

<p>
Do not be too quick to dismiss <samp>lynx</samp> though, 
even if many sites will not work and you find the whole experience boring!
The big graphical browsers out there are buggy,
bloated and more often then not,
boneheaded!
<samp>lynx</samp> on the other hand is an invaluable tool for debugging your web server.
It often helps to see what your website looks like in pure HTML,
blind people using screen readers,
for instance,
will often see you site exactly as <samp>lynx</samp> presents it
(shame on the web developers who discriminate blind folk and UNIX nerds alike!).
This venerable old tool also does a supreme job of rendering sites as pure text.
So if you want to print out the Wikipedia article about Slackware for instance,
you could run the command:
<samp>lynx -dump https://en.wikipedia.org/wiki/Slackware | lpr</samp>.
</p>

<h4 id="weatherapp">Example 1: A Weather App - using Lynx</h4>

<p>
Still not convinced?
Here is a short demonstration of a simple web app printing todays weather:
</p>
<pre><samp>
$ <i>lynx -dump http://weather.yahoo.com/united-states/illinois/chicago-2379574/</i>
...
Current conditions as of 1:54 pm EDT
Mostly Cloudy

	Feels Like:
		32 ¬∞F


	Barometer:

		30.13 in and rising
...
$ <i>cat sedcond</i>
/IL, United States/{
n
p
}
$ <i>cat sedtemp</i>
/Feels Like/{
p
}
$ <i>cat weather</i>
#!/bin/bash
# weather - extract the current weather for Chicago, IL
# usage: weather

URL=&#34;http://weather.yahoo.com/united-states/illinois/chicago-2379574/&#34;
LYNX=$(which lynx)
TMPFILE=$(mktemp tmpXXXXXX)
$LYNX -dump $URL &gt; $TMPFILE
conditions=$(cat $TMPFILE | sed -n -f sedcond)
temp=$(cat $TMPFILE | sed -n -f sedtemp | awk &#39;{print $4}&#39;)
rm -f $TMPFILE
echo &#34;Current conditions: $conditions&#34;
echo The current temp outside is: $temp
$ <i>./weather</i>
Current conditions: Mostly Cloudy
The current temp outside is: 32 ¬∞F
</samp>
</pre>


<p>
Of course yahoo might change their website and break our script.
The point here is to understand the potential of <samp>lynx</samp>.
Once you convert a webpage to pure text,
you can feed it to the standard UNIX tools such as <samp>sed</samp>,
<samp>awk</samp>,
<samp>bc</samp>,
etc...
</p>

<h4 id="dailyapp">Example 2: Daily Motivational&#39;s - using wget</h4>

<p>
Let&#39;s explore another example.
This Web App prints daily quotations from 
<a href="http://www.quotationspage.com">quotationspage.com</a>.
It checks if the URL is valid or not,
and writes a download log in <samp>/tmp/quote.log</samp>.
You can run this script as a daily cron job,
and configure your shell to print the daily quote,
if you want:
</p>

<pre><samp>
#!/bin/sh
# dquote - download daily quote to /tmp/daily_quote.txt
# usage: dquote

quote_url=www.quotationspage.com/qotd.html
check_url=$(wget -nv --spider $quote_url 2&gt;1&amp;)

if (echo $check_url | grep -s &#39;*error404*&#39;); then
	echo &#34;Bad web address&#34;
	echo &#34;$quote_url invalid&#34;
	echo &#34;Exiting script...&#34;
	exit
fi

wget -o /tmp/quote.log -O /tmp/quote.html $quote_url

sed &#39;s/&lt;[^&gt;]*//g&#39; /tmp/quote.html |
grep &#34;$(date +%B&#39; &#39;%-d,&#39; &#39;%Y)&#34; -A2 |
sed &#39;s/&gt;//g&#39; |
sed &#39;/¬†/{n ; d}&#39; |
sed &#39;s/¬†//g&#39; |
tee /tmp/daily_quote.txt &gt; /dev/null
exit
</samp>
</pre>


<p>
Much of the details here has to do with cleaning up the HTML code,
and printing only the text we want.
If your having trouble following the logic here,
I suggest you do the steps manually,
one by one,
and analyze how it transforms the output.
</p>

<h4 id="smsapp">Example 3: Sending SMS - using curl</h4>

<p>
<samp>wget</samp> is great for retrieving data from the web,
but it&#39;s cousin <samp>curl</samp> can also <i>send</i> data.
In this example we use curl to send an SMS message to our phone
(PS: This will only work within the US)
</p>

<pre><samp>
#!/bin/sh
# sms - send an sms
# usage: sms number message...

phone=$1
shift
SMSrelay_url=http://textbelt.com/text

curl -s $SMSrelay_url -d \
number=$phone \
-d &#34;message=$@&#34; &gt; /dev/null
exit
</samp>
</pre>


<p>
If you happen to have a boring staff meeting in 30 minutes,
you can send this message to your phone in 35 minutes,
and thus get a convenient excuse to leave,
like so:
<samp>at -f &#39;sms 3173334444 Emergency - need you in the office now!&#39; Now + 35 minutes</samp>
</p>

<h4 id="chatapp">Example 4: A Chat Client - using netcat</h4>

<p>
As the name suggests,
netcat (or just nc),
is really a &#34;cat&#34; for networks.
It&#39;s an invariable tool for testing and debugging your servers.
In this example we are going to recreate the classic UNIX talk command,
a dead simple chat program,
using netcat on both machines.
On the first machine run <samp>nc -l 1234</samp>,
then on the second run <samp>nc <ip_address> 1234</ip_address></samp>.
That&#39;s it!
</p>

<p>
Just as the old talk command our chat program is crude beyond words,
it does not identify who is talking,
and the text is garbled if both users write at the same time.
The old UNIX talk convention was that the user who initiated the conversation starts typing and ends with &#34;(O)&#34; for over,
then the second user responds and ends with &#34;(O)&#34;,
and so on,
until someone finally ends the conversation with &#34;(OO)&#34; for over and out.
Of course it is possible to program a much more elaborate chat client using netcat,
that identifies the users and handles simultaneous input,
but that would kind of spoil the fun now wouldn&#39;t it ;)
</p>

<p>
There is a whole host of web tools available for the console that we haven&#39;t covered.
But I hope these examples have wet your appetite,
and perhaps demonstrated how useful the console tools can be on the modern web.
At least you don&#39;t have to learn some horrid javascript framework to use them.
</p>

<h3 id="downloads">Downloads</h3>

<p>
In Linux land you often use <samp>wget</samp> to download single files from the web,
and an ftp client like <samp>lftp</samp> to download files from an ftp server.
In BSD the included <samp>ftp</samp> program handles both.
Torrents can be downloaded with a number of programs,
such as the command line frontend for transmission:
<samp>transmission-cli torrent-file</samp> or <samp>transmission-cli magnet-url</samp>
(another good CLI torrent application is <samp>rtorrent</samp>).
</p>

<p>
<samp>wget</samp> can also be used to do quite complex downloads.
For instance this command continues a previous ripping of a website,
pretending to be Firefox and only downloading files at random intervals:
<samp>wget --continue --random-wait -r -p -e robots=off -U mozilla www.somesite.com</samp>
</p>

<h3 id="chatting">Chatting</h3>

<p>
The classic way to chat over the internet on a console is by IRC.
Many UNIX developers and powerusers still use this technology,
and it&#39;s a great way to get free support.
Two popular IRC clients for the console are <samp>irssi</samp> and <samp>weechat</samp>.
</p>

<p>
There are other clients that can handle other chat protocols.
For instance,
<samp>pidgin</samp> is a popular chat client on the desktop that can handle most chat protocols,
such as Google talk, Facebook Messenger, MSN and what not.
There are also Skype and Telegram plugins for it (text only though).
Pidgin has a command line front end called <samp>finch</samp>,
which uses the same libraries and configuration files,
so any account and contact information made on one will also appear in the other.
If you are in to Slack,
there is a terminal client for that chat service,
called <samp>slack-term</samp>.
And there are other clients besides,
too numerous to mention,
choose whatever trash can that fits your social garbage.
</p>

<h3 id="email">Email</h3>

<p>
The standard program for reading and sending email in UNIX is <samp>mail</samp>.
Like <samp>vi</samp> you need to learn a handful of keybindings to use it,
but these are quite mnemonic.
The mail commands can either be written in long format,
such as <samp>print</samp> or short as in <samp>p</samp>.
When you open <samp>mail</samp> it presents a numbered list of all your email.
You can <samp>print</samp> message 2 like this: <samp>print 2</samp>.
When you are done reading it you can:
<samp>delete</samp> it,
<samp>reply</samp> to it,
<samp>save /path/to/file</samp> it or move to the <samp>next</samp> email.
You can also list the email <samp>headers</samp> again,
that is,
print a list of your email inbox.
When you are done you can <samp>quit</samp>.
</p>

<p>
To type an email run <samp>mail -s subject person@email.adress</samp>,
you can then write your email and end it by hitting <kbd>Ctrl</kbd> + <kbd>d</kbd>
(which in UNIX means &#34;end of file&#34;),
or <samp>mail -s subject person@email.adress &lt; myemail</samp>.
You can do other thing as well such as attach files to email messages,
mark an email as junk,
delete all junk mail,
and so on...
Read the manpage for the specifics.
Of course this all assumes that you have configured your machine to function as an email server.
The method of doing so is depressingly complicated,
and highly dependent on what system you are using,
and what choices you make.
It is well beyond the scope of this article.
</p>

<p>
You can however use <samp>offlineimap</samp> to sync your external email,
such as Gmail,
to a local directory,
and then use <samp>mail</samp> or <samp>mutt</samp>
(or the newer fork <samp>neomutt</samp>)
to read them.
You can also use <samp>msmtp</samp> to send email via an external provider such as Gmail.
The exact configuration here depends on what kind of external email you are using,
and other details,
but its relatively straight forward.
You can find good examples out there on the net,
and the Arch Linux wiki,
as always,
have some really good tips on the subject.
The aforementioned <samp>mutt</samp> email client is also capable of using an external email provider all on its own.
The following example shows how you can configure <samp>mutt</samp> to use Gmail 
(<i>Ps</i>:
I do not recommend using Google services,
this is just an example).
Put the following in <samp>~/.muttrc</samp>:
</p>

<pre><samp>
# IMAP Settings
set imap_server = &#39;myuser&#39;
set realname = &#39;My Real Name&#39;
set from = &#39;myser@gmail.com&#39;
set imap_pass = &#39;mypassword&#39;

# Remote GMail Folders
set folder = &#39;imaps://imap.gmail.com:993&#39;
set spoolfile = &#39;+INBOX&#39;
set postponed = &#39;+[Gmail]/Utkast&#39;
set trash = &#39;+[Gmail]/Papirkurv&#39;
set record = &#39;+[Gmail]/Sendt e-post&#39;

# Local folders for cached headers and certificates
set header_cache = ~/.mutt/cache/headers
set message_cachedir = ~/.mutt/cache/bodies
set certificate_file = ~/.mutt/certificates

# SMTP Settings
set smtp_url = &#39;smtp://myuser@smtp.gmail.com:587/&#39;
set smtp_pass = &#39;mypassword&#39;

# Securing
set move = no
set imap_keepalive = 900

# Handle HTML emails with w3m
auto_view text/html
</samp>
</pre>


<p>
And we need to create a couple of directories and add a mailcap line for this to work:
</p>

<pre><samp>
$ <i>mkdir -p ~/.mutt/cache/bodies</i>
$ <i>echo &#39;text/html; w3m -I %{charset} -T text/html; copiousoutput;&#39; &gt;&gt; ~/.mailcap</i>
</samp>
</pre>


<p>
You can now read your GMail account from the console,
we have even configured <samp>mutt</samp> to use the <samp>w3m</samp> console web browser for reading HTML emails.
</p>

<h3 id="news">News</h3>

<p>
There are a few rss/atom news client&#39;s available for the console,
such as <samp>newsbeuter</samp> (or <samp>newsboat</samp>) and <samp>rssowl</samp>.
Some UNIX systems also have the ancient <samp>news</samp> command available,
this command reads any new text files added to <samp>/news</samp> or a similar place.
If your system doesn&#39;t have a <samp>news</samp> command, you can easily create one.
You can then either manually download news items and save them to the news directory,
or you can write a script that automatically syncs this directory with some online news service and add it to your crontab.
Here is the script:
</p>

<pre><samp>
#!/bin/sh
# news - read latest from /news
# usage: news

for i in $(ls -t /news/* $HOME/.news_time 2&gt;&amp;1); do
	case $i in
		*&#39; No such file&#39;) ;;
		*/.news_time) break ;;
		*) set X$(ls -l $i)
		   echo &#34;
$i: ($3) $6 $7 $8
&#34;
		   cat $i
	esac
done
touch $HOME/.news_time
</samp>
</pre>


<p>
This short script adapted from <i>The UNIX Programming Environment</i> on page 164,
can teach you a great deal about shell scripting and basic UNIX commands.
It has a bug though, you must have at least one file in <samp>/news</samp> for the script to work properly.
Naturally,
this script is only useful in the extremely rare situation where colleagues are working on a common server,
and actually <i>use</i> that server for communication and project management.
This is the only sensible way to work with computers of course,
but nobody outside of Bell Labs seems to be aware of it.
If you like this kind of workflow,
check out the
<a href="#hipster">Hipster Media</a>
section below. 
</p>



<p>
In Linux there are command line clients for Facebook, Google, Readit and Twitter: 
<samp>fbcmd</samp>, <samp>googlecl</samp>, <samp>rtv</samp>, <samp>ttytter</samp>
(and others).
Of course real hackers update their twitter account like this:
<samp>curl -u myuser:mypassword -d status=&#34;Twitting from my shell&#34; http://twitter.com/statuses/update.xml</samp>
Similar clients come and go,
and those that do exist are naturally susceptible to breakage whenever the upstream survice changes.
Some service providers are even so radical that regular HTML browsers,
such as <samp>links</samp> or <samp>w3m</samp>,
can use them.
But that is rare.
</p>

<h3 id="hipster">Hipsters Media</h3>

<p>
There are very good reasons why you shouldn&#39;t hand over your data to commercial companies that refuse to give you any control or insight into what they do with it.
If the postman snoops in your private mail,
you have valid grounds to call the police.
But calling the police on Google isn&#39;t quite so easy...
And besides sifting through the social garbage on Facebook,
Instagram, Imgur and what not, will likely cause brain damage.
Is there a way to create a local social network on the console,
where the users are fully in control?
</p>

<p>
Sure, 
in fact the technical aspect of sharing data and communicating with a group of people,
is remarkably easy.
That&#39;s what UNIX was <i>designed</i> to do!
Simply give your friends user accounts on your server with <samp>adduser</samp> and let them access it securely with <samp>ssh</samp>.
No one can snoop on them now!
(well, except big brother root of course...)
</p>

<p>
You can see who is presently online with <samp>who</samp>,
change and check your online profile with <samp>chfn</samp> and <samp>finger</samp>
(finger will also print the users <samp>~/.plan</samp> and <samp>~/.project</samp> files if they exists),
send them emails with <samp>mail</samp>.
Sending emails internally usually doesn&#39;t require any special configuration,
just make sure that a mail server,
like <samp>sendmail</samp> or <samp>exim</samp>,
is running in the background.
Share files with <samp>cp</samp> or <samp>mv</samp>,
control who has read and write access to what with <samp>chmod</samp>
(if your collaborating on a project make a group for it and <samp>chmod -R myuser:mygroup /path/to/project</samp>).
</p>

<p>
Run a centralized news service by putting plain text news items in <samp>/news</samp>.
You can even chat interactively with <samp>write</samp> or <samp>talk</samp>.
PS:
Users can enable or disable this service with <samp>mesg</samp>,
and control whether or not they should be notified about incoming email with <samp>biff</samp>.
<samp>talk</samp> may require some configuration,
and there are more advanced clients for this ancient chat protocol,
such as <samp>ytalk</samp> or <samp>xtalk</samp>.
Of course the <i>social</i> challenge of getting your friends to use these programs will be borderline impossible.
Don&#39;t expect to get many &#34;likes&#34; on your hipster network,
but then again that wouldn&#39;t be the point now would it :)
</p>



<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/audio.png"></a>
</p>

<h3 id="volume">Volume</h3>

<p>
In Linux you can adjust the volume with the <samp>alsamixer</samp> command.
On other systems you have to use other commands.
</p>

<h4 id="volume_freebsd">FreeBSD</h4>

<p>
FreeBSD uses the <samp>mixer</samp> command, which adjusts volume by percentage.
You can for instance do this: <samp>mixer vol 75</samp> or <samp>mixer speaker +10</samp>
</p>

<h4 id="volume_openbsd">OpenBSD</h4>

<p>
There is a nice alsamixer like package available in ports called <samp>cmixer</samp>.
Otherwise you can adjust volume and other sound settings with the <samp>mixerctl</samp> command.
For instance <samp>mixerctl outputs.master=255</samp> will set the speakers to maximum output.
This simple script will let you specify volume in percentage (eg. <samp>volume 75</samp>):
</p>

<pre><samp>
#/bin/sh
# volume - set audio volume
# usage: volume percent

output=$(echo &#34;(255 * $1)/100&#34; | bc)
mixerctl outputs.master=$output
</samp>
</pre>


<h4 id="volume_netbsd">NetBSD</h4>

<p>
NetBSD also has it&#39;s own alsamixer like command called <samp>aiomixer</samp>,
and like OpenBSD,
it too has a <samp>mixerctl</samp> command that works much the same way.
The command will not list the mixer settings if you run it without any flags though,
instead you must run <samp>mixerctl -a</samp>.
And to change settings you must use the <samp>-w</samp> flag: <samp>mixerctl -w outputs.master=195</samp>.
Similarly to OpenBSD the NetBSD mixerctl specifies volume from 0 to 255,
you can easily make the above mentioned OpenBSD volume command for NetBSD by tweaking the example a little.
</p>

<h4 id="volume_illumos">Solaris and Illumos</h4>

<p>
You can change audio configuration with the <samp>audioctl</samp> command.
For instance you should be able to set the volume to 50% by doing something like this: <samp>audioctl set-control volume 50</samp>.
Exactly what controls are available may depend on your hardware,
you can check with <samp>audioctl show-control</samp>.
(Read the full man page for further instructions)
</p>

<p>
As a side note:
I had some hardware problems on my test machine.
The first audio device <samp>/dev/sound/audiohd:0</samp> did not work,
but the second one <samp>/dev/sound/audiohd:1</samp> did.
Unfortunately the system choose the wrong card as the default!
Well, no problem, this quick fix solved it:
<samp>ln -sf /dev/dsp1 /dev/dsp</samp>.
You can test if your audio works with <samp>audiotest</samp>
</p>

<h3 id="video">Video</h3>

<p>
If you have configured your
<a href="#framebuffer">framebuffer</a>
correctly in Linux,
you can watch videos in the console with <samp>vlc -I ncurses movie.mpeg</samp>.
You might get a garbled screen when the movie is finished playing,
if so type <samp>reset</samp>.
Another fine alternative here is <samp>mplayer</samp>.
Like <samp>vi</samp> you need to learn a few key-bindings before you can truly appreciate this program.
You can play a movie in the framebuffer like so:
<samp>mplayer -vo fbdev2 -vf scale=1366:768 movie.mpeg</samp>.
The resolution must match exactly the resolution of your framebuffer,
this is usually the same as your maximum Xorg resolution.
(you can check this in X with the command <samp>xrandr</samp>)
</p>

<p>
Some key-bindings to help you get started with <samp>mplayer</samp>:
You can pause and unpause the movie with space,
change volume with <kbd>0</kbd> and <kbd>9</kbd>,
jump forward or backward with <kbd>arrow</kbd> keys or <kbd>pageup</kbd> or <kbd>pagedown</kbd>,
and quit with <kbd>q</kbd>.
</p>

<p>
In theory you should be able to play movies on the console with <samp>mpv</samp>,
but you probably need to recompile mpv with <samp>--enable-sdl</samp> and <samp>--enable-sdl2</samp>,
and you may need to recompile sdl2 with <samp>--enable-video-directfb</samp>.
I have not tested this myself.
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/video.png"></a>
</p>

<h3 id="youtube">Youtube</h3>

<p>
There are a couple of ways you can watch youtube movies in the Linux console.
One is to navigate to the video you want with a console browser,
such as <samp>lynx</samp>.
When you have found the right url,
hit <kbd>G</kbd>,
now left click and mark the url
(supposing you have configured <samp>gpm</samp>).
Hit <kbd>Ctrl</kbd> + <kbd>c</kbd> to quit <samp>lynx</samp>.
Now either type <samp>youtube-dl</samp> and middle click to paste the url,
to download the video,
or type <samp>vlc</samp> (or <samp>mplayer</samp>) and paste the url to watch the video directly
(you can copy paste the url with <samp>tmux</samp> also if you prefer).
</p>

<p>
Another program you could use is <samp>youtube-viewer</samp>.
You can either run <samp>youtube-viewer -d</samp> to download the movies instead of watching them,
and then later play them with <samp>vlc</samp> or <samp>mplayer</samp>.
Or you can edit <samp>~/.config/youtube-viewer/youtube-viewer.conf</samp> and set the appropriate <samp>mplayer</samp> or <samp>vlc</samp> args to play the movies directly in the framebuffer.
</p>

<h3 id="music">Music</h3>

<p>
Besides playing music with <samp>vlc</samp> or <samp>mplayer</samp>,
there is a ton of music players available for the console!
A very simple one witch I really like is <samp>mocp</samp>
(&#34;music on console player&#34;).
Adjust volume with <kbd>,</kbd> (comma) and <kbd>.</kbd> (dot),
display available key-bindings with <kbd>?</kbd>.
You can open a directory with <kbd>i</kbd>,
and start playing music files here by selecting it and hitting <kbd>enter</kbd>.
Or you can add the song to your playlist with <kbd>a</kbd>,
clear the playlist with <kbd>C</kbd>,
when the playlist is populated correctly switch to it by <kbd>tab</kbd>
and hit <kbd>enter</kbd>.
Shuffle with <kbd>S</kbd> or repeat with <kbd>R</kbd> if you want to.
Other popular alternatives are <samp>cmus</samp>,
<samp>mp3blaster</samp> and others.
There are also several more basic audio players available.
The <samp>sox</samp> package discussed below for instance,
includes the <samp>play</samp> command,
which is quite capable of playing any kind of audio file.
</p>

<h3 id="radio">Internet Radio</h3>

<p>
You can play internet streams with <samp>mplayer</samp> and other media players,
but this requires you to find the correct stream URL&#39;s.
This is more tricky then you might think since streaming websites will usually not display these URL&#39;s directly.
Often you need to snoop around in the website HTML code in order to find them.
Here is a somewhat Apple-centric example
(yes I know - <i>do</i> feel free to change it!) 
list to get you started:
(you can append it to your <samp>~/.profile</samp> or <samp>~/.bashrc</samp>)
</p>

<pre><samp>
alias news=&#34;mplayer -playlist http://minnesota.publicradio.org/tools/play/streams/news.pls&#34; # MPR News
alias current=&#34;mplayer -playlist http://minnesota.publicradio.org/tools/play/streams/the_current.pls&#34; # The Current 
alias classical=&#34;mplayer -playlist http://minnesota.publicradio.org/tools/play/streams/classical.pls&#34; # Classical MPR 
alias localcurrent=&#34;mplayer -playlist http://minnesota.publicradio.org/tools/play/streams/local.pls&#34; # Local Current 
alias heartland=&#34;mplayer -playlist http://minnesota.publicradio.org/tools/play/streams/radio_heartland.pls&#34; # MPR Radio Heartland 
alias wonderground=&#34;mplayer http://wondergroundstream2.publicradio.org/wonderground&#34; # MPR Wonderground Windows Media 
alias choral=&#34;mplayer -playlist http://choralstream1.publicradio.org/choral.m3u&#34; # Classical MPR Choral
alias wefunk=&#34;mplayer -playlist http://www.wefunkradio.com/play/shoutcast.pls&#34; # WEFUNK Radio MP3 64K
alias sleepbot=&#34;mplayer -playlist http://sleepbot.com/ambience/cgi/listen.cgi/listen.pls&#34; # Sleepbot Environmental Broadcast 56K MP3
alias groovesalad=&#34;mplayer -playlist http://somafm.com/groovesalad130.pls&#34; # Soma FM Groove Salad iTunes AAC 128K
alias dronezone=&#34;mplayer -playlist http://somafm.com/dronezone130.pls&#34; # Soma FM Drone Zone iTunes AAC 128K
alias lush=&#34;mplayer -playlist http://somafm.com/lush130.pls&#34; # Soma FM Lush iTunes AAC 128K
alias sonicuniverse=&#34;mplayer -playlist http://somafm.com/sonicuniverse.pls&#34; # Soma FM Sonic Universe iTunes AAC 128K
</samp>
</pre>


<p>
You can also set up your own radio stream with <samp>mpd</samp>,
and play it locally with <samp>mpc</samp>,
<samp>ncmpcpp</samp> or another MPD client.
</p>

<p>
Here is an example setup,
place it in <samp>/etc/mpd.conf</samp> for a system wide service,
or <samp>~/.config/mpd/mpd.conf</samp> if you plan to run it as a user process:
</p>

<pre><samp>
db_file             &#34;~/.config/mpd/database&#34;
log_file            &#34;syslog&#34;
music_directory     &#34;~/music&#34;
auto_update         &#34;yes&#34;
playlist_directory  &#34;~/.config/mpd/playlists&#34;
pid_file            &#34;~/.config/mpd/pid&#34;
state_file          &#34;~/.config/mpd/state&#34;
sticker_file        &#34;~/.config/mpd/sticker.sql&#34;
</samp>
</pre>


<p>
Run <samp>mkdir ~/.config/mpd/playlists</samp> if this directory does not exist.
Your now all set,
just run <samp>mpd</samp>,
and then you can launch an MPD client,
such as <samp>ncmpcpp</samp> to play your music.
</p>

<h3 id="spotify">Spotify, LastFM and Podcasts</h3>

<p>
There are command line clients for these online services:
<samp>despotify</samp>
was a good Spotify client,
but seems to have been abandoned,
<samp>ncspot</samp> is another alternative.
For LastFM and podcasts,
you can use <samp>shell-fm</samp> and <samp>bash-podder</samp>
(of course for podcasts you could just manually download them and use your favorite music player).
These commands are rare to see outside Linux repositories,
but you might be able to compile them yourself on your favorite OS all the same.
</p>

<p>
You can also install <samp>Mopidy</samp> (Linux only),
which can be configured to play music from Spotify and other streaming services as an MPD service,
you can then listen to Spotify with one of the many MPD clients.
For example,
after <samp>mopidy</samp> and <samp>mopidy-spotify</samp> is installed,
you can add this to <samp>/etc/mopidy/mopidy.conf</samp>
(or <samp>~/.config/mopidy/mopidy.conf</samp> if run as a user process):
</p>

<pre><samp>
[audio]
output = tee name=t ! queue ! autoaudiosink t. ! queue ! udpsink
port=5555

[spotify]
enabled = true
username = [username] # Must have Spotify Premium
password = [password]
bitrate = 320
</samp>
</pre>


<p>
You can then configure the MPD client <samp>ncmpcpp</samp> to use this,
by adding this to <samp>~/.ncmpcpp/config</samp>:
</p>

<pre><samp>
visualizer_fifo_path = &#34;/tmp/mpd.fifo&#34;
visualizer_output_name = &#34;my_fifo&#34;
visualizer_sync_interval = &#34;30&#34;
visualizer_in_stereo = &#34;yes&#34;
visualizer_type = &#34;spectrum&#34;
visualizer_look = &#34;+|&#34;
</samp>
</pre>


<p>
You can now launch the spotify client like so:
<samp>nohup mopidy &amp; ; mkfifo /tmp/mpd.fifo ; while :
do yes $&#39;\n&#39; | nc -lu 127.0.0.1 5555 &gt; /tmp/mpd.fifo
done &amp; ; ncmpcpp</samp>
If you don&#39;t care about visualization,
and <samp>mopidy</samp> is already running as a service,
it would suffice to just run <samp>ncmpcpp</samp>.
</p>

<h3 id="making_music">Making Music and Video</h3>

<p>
You will not find a massive studio software suit,
complete with pointy-clicky interface,
for the console,
but you can do a whole lot of productive audio/video work nonetheless.
</p>

<p>
To begin with,
you can record audio with <samp>rec</samp>,
which is included in the <samp>sox</samp> package,
or you can use a more native approach:
</p>

<ul>
  <lh>Linux</lh>
  <li><samp>arecord -f cd -d 600 -t raw | lame -x -r - out.mp3</samp>, record for 10 minutes and convert to mp3</li>
  <li><samp>arecord -f cd -t raw | oggenc - -r -o out.ogg</samp>, record and convert to ogg (hit Ctrl-D or -C when done)</li>
</ul>
<ul>
  <lh>UNIX (FreeBSD/Solaris)</lh>
  <li><samp>cat /dev/dsp &gt; bla</samp> record from device dsp, save raw output to <i>bla</i></li>
  <li><samp>cat bla &gt; /dev/dsp</samp> play (raw) audio file over the speakers</li>
  <li><samp>cat /dev/dsp &gt; /dev/dsp</samp> play from record device to speakers</li>
</ul>
(PS: You may want to use /dev/dspW in FreeBSD)
<ul>
  <lh>OpenBSD</lh>
  <li><samp>aucat -i file1.wav -i file2.wav -o file3.wav</samp> mix and play two audio files while recording a third (see also <i>mixerctl(1)</i>)</li>
</ul>


<p>
For recording video see the <a href="#screencapture">screen capturing</a> section.
</p>

<p>
The Jack Audio Connection Kit sound server is available on practically all modern UNIX&#39;es,
and can be used from the command line to organize and mangle your audio equipment.
<samp>ffmpeg</samp> and <samp>sox</samp> can be used to edit audio and video in various ways.
Here are some examples:
</p>

<ul>
  <li><samp>ffmpeg -i file.mpg -ss 120 -t 300 -c copy output.mpg</samp>, copy a 5 minute cut starting 2 minutes into the file, you can do the same for audio files</li>
  <li><samp>ffmpeg -i video.mpg -hide_banner</samp>, display information about video</li>
  <li><samp>ffmpeg -i video.mpg image%d.jpg</samp>, convert video to jpg images</li>
  <li><samp>ffmpeg -f image2 -i image%d.jpg output.mpg</samp>, convert a set of image*.jpg images into a video</li>
  <li><samp>ffmpeg -i video.mpg -vn -ar 44100 -ac 2 -ab 192 -f mp3 output.mp3</samp>, convert video to mp3 audio</li>
  <li><samp>ffmpeg -i video.mpg -i audio.mp3 output.mpg</samp>, merge video and audio</li>
  <li><samp>ffmpeg -loop 1 -i audio.mp3 -i picture.jpg -c:v libx264 -c:a aac -strict experimental -b:a 192k -shortest output.mp4</samp>, merge audio and image</li>
  <li><samp>ffmpeg -i video.flv output.mpg</samp>, convert flv to mpg</li>
  <li><samp>ffmpeg -i video.mpg output.gif.mpg</samp>, convert mpg to gif</li>
  <li><samp>ffmpeg -i video.mpg -ab 26k -f flv output.flv</samp>, convert mpg to flv</li>
  <li><samp>ffmpeg -i video.avi -target pal-dvd -ps 2000000000 -aspect 16:9 output.mpg</samp>, convert avi to mpg</li>
  <li><samp>ffmpeg -i video.mpg -target vcd output.mpg</samp>, convert video to DVD format</li>
  <li><samp>ffmpeg -i video.mpg -i subtitle.sub -map 0 -map 1 -c copy -c:v libx264 -crf 23 -preset veryfast output.mkv</samp>, merge video and subtitle</li>
  <li><samp>for file in *; do sox $file -r 8000 out/$file ; done</samp>, resample audio files and put them in the out directory</li>
</ul>


<p>
If you plan to do a lot of audio/video work in the command line,
you may find it useful to create some aliases for these commands.
(or whatever variations of them you may need)
</p>

<p>
Ripping audio CD&#39;s can be done with <samp>cdparanoia</samp>
(OpenBSD has it&#39;s own excellent cd tool, <samp>cdio</samp>),
and <samp>vobcopy</samp> is a good DVD ripper.
(see the
<a href="#dvd">cd&#39;s, dvd&#39;s and bluerays</a>
section for more information)
If you want to rip a radio stream,
<samp>streamripper</samp> is a good candidate.
Finally the <samp>mplayer</samp> package also includes <samp>mencoder</samp>,
which can rip any media that <samp>mplayer</samp> can play,
you can also use it to edit the video/audio stream in various ways.
</p>

<h2 id="graphics">Graphics</h2>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/graphics.png"></a>
</p>

<h3 id="pictures">Pictures</h3>

<p>
A few image viewers can be used in combination with the
<a href="#framebuffer">framebuffer</a> on Linux.
My favorite is <samp>fbi</samp>.
You can open a picture with <samp>fbi picture.jpeg</samp>,
or a directory of pictures with <samp>fbi pictures/*</samp>,
and navigate back and forth with <kbd>n</kbd> and <kbd>p</kbd>,
and zoom in or out with <kbd>-</kbd> and <kbd>+</kbd>.
</p>

<p>
Some people recommend <samp>zgv</samp> to view images in the console,
but I have never managed to get this program to work on my machine...
</p>

<h3>Making Pictures</h3>

<p>
There is no &#34;PhotoShop&#34; for the console,
but you can easily &#34;make&#34; pictures with a camera,
and work with these on a console.
Just use a memory card reader to retrieve the pictures,
and you can view them with <samp>fbi</samp>,
and organize them into whatever directories and naming scheme you like.
</p>

<p>
The process of mounting a memory card is similar to mounting a USB memory stick,
although the device names are different.
Stick your memory card in the reader and run <samp>dmesg | tail</samp>
to find out what the device is called.
On my Linux box this command gave me this output:
</p>

<pre>[   20.443125] mmc0: new ultra high speed SDR50 SDHC card at address e624
...
[   20.493617]  mmcblk0: p1
</pre>



<p>
Don&#39;t worry too much about all the details here,
the important thing to notice is that a new SD card was detected,
and that a new device called <samp>mmcblk0</samp>
(with partition <samp>p1</samp>)
was created.
We can now mount the device and copy over the images:
</p>

<pre><samp>
$ <i>sudo mount /dev/mmcblk0p1 /mnt/hd</i>
$ <i>cp /mnt/hd/DCIM/100NIKON/* Pictures/vacation_2018</i>
</samp>
</pre>


<p>
As you can see my camera organized its pictures in DCIM/100NIKON,
but yours may do things differently.
Once mounted just use <samp>ls</samp> and find out.
(PS: If you are having trouble you can always buy a cheap usb memory card reader on ebay,
you can then mount your memory card like an ordinary usb memory stick)
</p>

<p>
For scanners see the
<a href="#printer">printers and scanners</a>
section.
</p>

<p>
You can also edit photos from the console,
using the <samp>ImageMagick</samp> collection of tools
(a good alternative here is <samp>GraphicsMagick</samp>).
Here are some of its utilities:
</p>

<ul>
  <li>identify - print information about an image</li>
  <li>convert - convert image format, or resize, blur, crop, flip, join etc...</li>
  <li>mogrify - much the same as convert, but alter the image directly don&#39;t make a copy</li>
  <li>montage - create a composite image out of several others</li>
  <li>composite - overlap one image over another</li>
</ul>


<p>
These tools give you quite a lot of scripting power to manage your photos.
It is well worth learning,
even if you are only interested in using a desktop environment.
You can find many good tutorials for this software suit online
</p>

<h3 id="pdf">PDF and Postscript</h3>

<p>
The <samp>fbi</samp>
(or <samp>fbida</samp>)
package mentioned above usually include <samp>fbipdf</samp>.
(sometimes called <samp>fbpdf</samp>)
This program can be used to view PDF&#39;s on the framebuffer like so:
<samp>fbipdf document.pdf</samp>.
Also some old versions of <samp>fbi</samp> do not include <samp>fbipdf</samp>,
in such cases you can usually use the inferior <samp>fbgs</samp> program.
</p>

<p>
If you don&#39;t have a framebuffer available,
you can convert a PDF to HTML or plain text with <samp>pdftohtml</samp> and <samp>pdftotext</samp>,
both of witch are a part of the <samp>poppler</samp> (or <samp>poppler-utils</samp>) package.
You can also use <samp>pdfimages</samp> from the poppler tools to extract images in a PDF.
For instance you could to this:
</p>
<pre><samp>
$ <i>pdftohtml -s -i document.pdf</i>
$ <i>lynx document-html.html</i>
$ <i>pdftotext -layout document.pdf</i>
$ <i>less document.txt</i>
</samp>
</pre>


<p>
Exactly how well this works depends very much upon the PDF in question.
If you are lucky,
the conversion is merely bad,
if you are unlucky,
it&#39;s unreadable.
Some PDF&#39;s are simply a collection of JPEG&#39;s of text,
the poppler tools cannot convert such documents.
You can try with <samp>ocrmypdf</samp> or other OCR solutions
(see <a href="#ocr">discussion</a> below).
</p>

<p>
The poppler utils can do some basic editing as well,
such as extracting pages from a PDF or merging pages into a single PDF,
checking the metainfo and more.
An alternative PDF editing tool is <samp>pdftk</samp>.
Of course non of these tools are interactive,
so they are mostly useful for basic batch editing and scripting.
</p>

<h3 id="ocr">OCR</h3>

<p>
Sadly OCR support, that is scanning a document and converting the image to plain text,
is not well supported in the open source world.
The only widely available tool is tesseract, here is a short demonstration of its usage:
</p>

<pre><samp>
$ <i>scanimage --mode grey --resolution 300 &gt; scan.pnm</i>
$ <i>unpaper -b 0.5 -w 0.8 -l single scan.pnm scan1.pnm</i>
$ <i>convert scan1.pnm scan.tif</i>
$ <i>tesseract scan.tif scan.txt</i>
</samp>
</pre>


<p>
This example uses commands from the sane-backends, unpaper and ImageMagick packages.
The results of this OCR depends much upon the quality of the scan,
the higher the resolution the better,
and it also requires you to have installed the correct language packages for tesseract
(eg. tesseract-ocr-fra or similar if the document is French).
</p>

<h3 id="ascii">Asciiart</h3>

<p>
For the geeky console user,
asciiart can provide much fun.
Note however that non-Linux consoles that don&#39;t support video playback,
either don&#39;t have asciiart support at all,
or they don&#39;t have good enough font support to make it practical.
If you install the <samp>libcaca</samp>
(sometimes called <samp>caca-utils</samp>)
package,
you can view images with <samp>cacaview</samp> or convert them to text files with <samp>img2txt</samp>.
The related <samp>libaa</samp> is used for black and white asciiart,
it includes the fun <samp>bb</samp> demo.
You can even play videos in asciiart with something like this:
<samp>mplayer -vo caca myvideo.mkv</samp>,
or
<samp>vlc -V aa https://youtube.com/some_url...</samp>.
Speaking of video <samp>hasciicam</samp> will let you play video output from your webcam in ASCII!
PS:
The quality of your asciiart images depends on what fonts you use.
The smaller the font,
the greater the resolution
(see <a href="#configuration">console configuration section</a> on how to do this).
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/ascii.png"></a>
</p>

<p>
Although your artistic painting skills may be limited on the console,
you can freely draw asciiart.
There are a few programs designed specifically for this purpose,
such as <samp>cadubi</samp>,
but <i>real</i> pros do their ASCII painting in <samp>vi</samp>
(of course <samp>ed</samp> users scoff at such newbs...)!
</p>

<h2 id="peripherals">Peripherals</h2>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/printer.png"></a>
</p>

<h3 id="usb">USB Memory Sticks</h3>

<p>
See the <a href="#disk">disk management</a> section for more details about formatting USB memory sticks,
in this section we will only talk about mounting such devices.
The device name used in the examples are typical for these operating systems,
but yours may be different
(it may be <samp>sdb1</samp> not <samp>sdd1</samp> for example).
After attaching your memory stick you can run <samp>dmesg | tail</samp> to check what the system called the device,
or to see if there were any errors.
Finally,
depending on your security setup,
you may need to use <samp>sudo</samp> to run some of these commands.
</p>

<h4>Linux</h4>

<pre><samp>
$ <i>mkdir -p /mnt/usb</i>                 # make a directory to mount the usb device in
$ <i>mount /dev/sdd1 /mnt/usb</i>
$ <i>cp -r /mnt/usb $HOME/Downloads</i>    # use the usb device like a regular directory
$ <i>umount /mnt/usb</i>                   # safely unmount the device
</samp>
</pre>


<h4>FreeBSD/DragonFly BSD</h4>

<pre><samp>
$ <i>mount -t msdosfs /dev/da0s1 /mnt/usb</i>
$ <i>umount /mnt/usb</i>
</samp>
</pre>


<h4>OpenBSD/NetBSD</h4>

<pre><samp>
$ <i>disklabel sd0</i>                     # check the partition name
$ <i>mount /dev/sd0i /mnt/usb</i>
$ <i>umount /mnt/usb</i>
</samp>
</pre>


<h4>Solaris/Illumos</h4>

<pre><samp>
$ <i>rmformat</i>                         # check the partition name
$ <i>mount -F pcfs /dev/dsk/c0t0d0p0:c /mnt/usb</i>
$ <i>umount /mnt/usb  &amp;&amp; eject /dev/dsk/c0t0d0p0</i>
</samp>
</pre>


<h3 id="dvd">CD&#39;s, DVD&#39;s and BlueRays</h3>

<p>
Ripping CD&#39;s and DVD&#39;s can be done with <samp>cdparanoia</samp> and <samp>vobcopy</samp>.
Writing CD&#39;s and DVD&#39;s can be done with <samp>cdrecord</samp>
(or <samp>dvd+rw-format</samp>)
and <samp>growisofs</samp>,
and making iso files can be done with <samp>mkisofs</samp>.
OpenBSD has it&#39;s own program for ripping and writing CD&#39;s,
<samp>cdio</samp>.
As for playing music and video from such media see the
<a href="#media">Multimedia</a>
section.
</p>

<p>
The following examples show how to create and mount ISO files,
and how to burn such data to a CD/DVD:
(you may need <samp>sudo</samp> for some of these commands)
</p>

<h4>Linux</h4>

<pre><samp>
$ <i>mkisofs -o mydisk.iso /my/path</i>	# make an iso data file
$ <i>mkdir -p /mnt/cd</i>              	# make a directory to mount the iso in
$ <i>mount /dev/cdrom0 /mnt/cd</i>     	# mount cd
$ <i>mount /dev/dvd0 /mnt/cd</i>       	# mount dvd
$ <i>mount -o loop mydisk.iso /mnt/cd</i>	# mount iso
$ <i>umount /mnt/cd</i>                    	# unmount cd/dvd/iso
$ <i>cp -r /mnt/cd $HOME/Downloads</i>     	# use the iso like a regular directory (read only)
$ <i>cdrecord -scanbus</i>			# check the device name of the cd/dvd burner
$ <i>cdrecord mydisk.iso</i>
$ <i>cdrecord -dao -useinfo *.wav</i>		# write an audio cd/dvd
$ <i>mkisofs -R -J -udf -iso-level 3 -o mydvd.iso /my/path</i>    # make a dvd iso data file
$ <i>growisofs -dvd-compat -Z /dev/cd0=mydvd.iso</i>              # write a data dvd
</samp>
</pre>


<p>
Much the same can be done for other UNIX systems,
but the device names may be a little different.
And they might require you to create a virtual device for the iso file,
before you can mount it:
</p>

<h4>FreeBSD/DragonFly BSD</h4>

<pre><samp>
$ <i>mdconfig -a -t vnode -f mydisk.iso -u 0</i>
$ <i>mount -t cd9600 /dev/md0 /mnt/cd</i>
$ <i>mount /dev/cd0 /mnt/cd</i>
</samp>
</pre>


<h4>OpenBSD/NetBSD</h4>

<pre><samp>
$ <i>cdio play</i>                         # play audio cd (cdio is OpenBSD only)
$ <i>cdio tao mydisk.iso</i>               # write data cd
$ <i>cdio cdrip</i>                        # rip audio cd
$ <i>cdio tao -a *.wav</i>                 # write audio cd
$ <i>vnconfig vnd0 mydisk.iso</i>
$ <i>mount /dev/vnd9c /mnt/cd</i>
$ <i>mount /dev/cd0c /mnt/cd</i>
$ <i>growisofs -dvd-compat -Z /dev/rcd0c=mydvd.iso</i>            # write a data dvd
</samp>
</pre>


<h4>Solaris/Illumos</h4>

<p>
CD&#39;s should be auto mounted in <samp>/media</samp>,
you can double check with <samp>rmformat</samp>.
</p>

<pre><samp>
$ <i>mount -F hsfs mydisk.iso /mnt/cd</i>
</samp>
</pre>


<h3 id="printer">Printers and Scanners</h3>

<p>
Practically all modern UNIX&#39;es use CUPS and SANE to manage printers and scanners.
Installing a printer from the console is tricky if you don&#39;t know what you are doing.
So for this one task its probably better to use a graphical desktop and configure CUPS using a modern web browser,
such as Firefox.
Just go to <samp>localhost:631</samp> and enter your root password.
Many UNIX systems have large collections of printer drivers available by default,
but if you cant find your model,
head over to
<a href="https://openprinting.org/drivers">openprinting.org</a>
and search for a driver.
If you cannot find your exact model try to find a driver for a similar device.
For example,
I could not find a driver for my HL-2035 Brother printer,
but I did find one for the HL-2030 that worked just fine.
Once the printer is set up,
installing it on other UNIX machines using the console is easy.
Just copy the printer configuration file <samp>/etc/cups/printers.conf</samp>,
and optionally other configuration files that might be relevant,
such as the drivers in <samp>/etc/cups/ppd</samp>.
</p>

<p>
If you have configured your printer as the server default,
you can use the following commands to print documents:
</p>

<pre><samp>
$ <i>lpr document.pdf document.ps document.txt</i>
$ <i>enscript document.txt</i>		# print text as postscript (looks nicer)
$ <i>lpq</i>				# list printing jobs
$ <i>lprm</i>				# remove a print job0
</samp>
</pre>


<p>
PS: Some UNIX systems may already have a native <samp>lpr</samp> and related suite of applications.
In FreeBSD for example,
the native print command is <samp>/usr/bin/lpr</samp>,
while the CUPS print command is in <samp>/usr/local/bin/lpr</samp>.
In OpenBSD the CUPS command is called <samp>lpr-cups</samp>,
to distinguish it from the native <samp>lpr</samp> command.
Run <samp>which -a lpr</samp> to check if your system has more then one print command.
</p>

<p>
Scanners are also easy to use from the console,
using the <samp>sane</samp> collection of tools,
for instance:
<samp>scanimage &gt;image.pnm</samp>
</p>

<p>
Most scanners should be plug-and-play,
check the sane documentation or google if you are having problems.
</p>

<h2 id="game">Gaming</h2>

<p>
Don&#39;t expect the triple A games on your Steam account to work in the console!
The console is not a popular platform for gaming for obvious reasons,
but there are a few simple candidates to choose from.
Some of my favorites are <samp>myman</samp>,
<samp>sudoku</samp> and
<samp>vitetris</samp>
(or you can try <samp>basted</samp> if you *like* getting frustrated).
There is also <samp>cpat</samp> for all kinds of solitaire fun,
and the &#34;racing&#34; games <samp>moon-buggy</samp> and <samp>ztrack</samp>.
<samp>ASCIIpOrtal</samp> is an amazingly cool game,
even if it&#39;s quite obscure and unmaintained.
You can find a lot more suggestions,
and plenty of online tty games
<a href="https://github.com/ligurio/awesome-ttygames">here</a>.
The classic <samp>bsdgames</samp> and <samp>gnuchess</samp> might also provide you with some fun,
if you happen to be a meganerd...
</p>

<h3 id="strategy_games">Strategy Games</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/empire.png"></a>
</p>

<p>
There are precious few strategy games for the console,
but here are a couple of good ol&#39; classics:
<samp>starlanes</samp> is an economic conquest game,
and is great fun to play hotseat with a couple of friends
(you would have to have some pretty nerdy friends though...).
<samp>vms-empire</samp> (or just <samp>empire</samp>) is a lot more elaborate,
it&#39;s sort of basic Civilization for the terminal.
Its &#34;vi-like&#34; interface takes some getting used to though,
and you will have to skim through the manual a few times.
Here are some quick starting points:
After typing <kbd>a</kbd> to enter &#34;auto-mode&#34; at the beginning of the game,
and <kbd>a</kbd> again to produce armies in your city,
you want to command your new units to auto explore with <kbd>y</kbd>.
To change a units orders or change a cities production,
type <kbd>j</kbd> to enter &#34;edit-mode&#34;.
From here you can cancel a units orders with <kbd>k</kbd>,
and change what a city builds with <kbd>b</kbd>,
hit <kbd>o</kbd> to go out of &#34;edit-mode&#34;.
When you want to quit the game,
hit <kbd>o</kbd> to go out of &#34;auto-mode&#34;,
and into &#34;command-mode&#34;.
This will take effect once you have completed your round,
so move any remaining units until the game finally asks you for a command.
At this point you can type <kbd>s</kbd> to save,
and <kbd>q</kbd> to quit.
A final tip,
you want to start this game with <samp>vms-empire -d0</samp>!
Have Fun :)
</p>


<h3 id="framebuffer_games">Framebuffer Games</h3>

<p>
If your running Linux a few SDL games can actually run in the
<a href="#framebuffer">framebuffer</a>.
One example is <samp>dosbox</samp>,
this DOS emulator can run pretty much any old game from the early 90&#39;s.
If you&#39;re a retro gamer like me,
<samp>dosbox</samp> opens up a world of gaming for the console!
You need to tweak the <samp>~/.dosbox/dosbox-*.conf</samp> setting a bit for programs to work well.
These are the settings I use:
</p>
<pre><samp>
fullscreen=true
fulldouble=false
fullresolution=1680x1050
windowresolution=1680x1050
output=overlay
usescancodes=false
keyboardlayout=us
aspect=false
scaler=none
</samp>
</pre>

<p>
Note that the resolutions must match your framebuffer resolution,
witch is usually the maximum resolution in Xorg.
And output must be &#34;overlay&#34; with no fancy scaler,
otherwise fullscreen resolution will not work.
Also be sure to disable userscancodes and set a keyboard layout manually,
since userscancodes do not work in the framebuffer!
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/dosbox.png"></a>
</p>

<p>
<samp>scummvm</samp> might also works in the framebuffer
(it did not in debian),
but getting the resolution right is not easy.
You can try something like <samp>scummvm -g hq3x</samp>,
and hopefully this will work for you...
</p>

<h3 id="roguelikes">Roguelikes</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/cataclysm.png"></a>
</p>


<p>
The big gaming genre on the UNIX console is of course roguelikes.
Roguelikes are 2D dungeon exploration RPG games.
The name comes from the game <samp>rogue</samp>,
which was the first game in this genre,
created way back in the 80&#39;s
(in fact curses was originally developed <i>for</i> rogue).
Sometimes the ancient <samp>rogue</samp>,
<samp>hack</samp> or <samp>larn</samp> are included in the <samp>bsdgames</samp> package,
but players today usually prefer more modern alternatives.
</p>

<p>
The arch typical roguelike of all time is <samp>nethack</samp>,
which might very well be the
<a href="https://www.linuxvoice.com/nethack">greatest game</a>
ever created!
It has been in continuous development for over 30 years
(40 if you include the predecessors it is based on),
and has surprising depth.
You owe it to yourself to die at least once playing this murderously difficult dungeon crawler before you snuff it for good in RL.
Other popular alternatives is the action focused <samp>crawl</samp>,
the meta-world games of <samp>adom</samp> and <samp>angband</samp>,
and the full blown strategy/survival games <samp>dwarffortress</samp> (Linux and FreeBSD only) and <samp>cataclysm</samp>.
(ps: to play dwarffortress in the console,
set <samp>[PRINT_MODE:TEXT]</samp> in <samp>./df/data/init/init.txt</samp>)
</p>

<p>
There are a great,
great many alternative roguelikes out there.
Some of the more obscure ones are also the most interesting,
my own personal favorite for instance is an abandoned scify spin of nethack called <samp>zapm</samp>.
You can browse around in
<a href="http://www.roguebasin.com">roguebasin</a>
for more options if you are curious.
</p>

<h3 id="if">Interactive Fiction</h3>

<p>
Way back in the 70&#39;s the legendary game developer Infocom produces a host of interactive fiction games.
These games are all text,
like an interactive novel.
Now,
I know what you are thinking:
<i>&#34;What?!?
No graphics?
That cannot be fun!&#34;</i>
Well, that&#39;s a bit like saying that a book without pictures cannot be fun.
It&#39;s OK to say that if you&#39;re 4,
not if you&#39;re 40...
To quote one of the Infocom developers in the excellent <i>Get Lamp</i> (2010) documentary:
</p>

<blockquote>
<p>
¬´It&#39;s all good with high resolution graphics and surround sound,
but it is still far away from reality.
So what if you make a virtual reality game with 3D glasses?
That&#39;s a lot better,
but you don&#39;t feel anything.
So how about emerging your body into a sensory simulation capsule.
Now we are getting somewhere!
But it might not feel like the real thing.
So what if we make a direct neural connector to our brain,
feeding it our simulation directly?
Now we can really live out our fantasy!
Of course our imagination could have replaced this high tech solution all along...¬ª
</p>
</blockquote>

<p>
To paraphrase Sheldon Couper from The Big Bang Theory,
<em>interactive fiction games runs on the most powerful graphic chip known to man,
your imagination!</em>.
These old games can be played in the command line with <samp>frotz</samp>
(getting the Infocom games legally might be a problem though).
But interactive fiction games are still being created today,
surprising I know,
and most of the newer titles can be obtained for free.
There are even yearly 
<a href="http://ifcomp.org">IF competitions</a>!
</p>

<h3 id="mud">MUD&#39;S</h3>

<p>
As fun as interactive fiction is,
it&#39;s an introspective and solitary kind of joy,
much like enjoying a good novel.
Multi User Dungeons,
or <i>MUD&#39;s</i>,
on the other hand,
are multiplayer interactive fiction that has been around since the 80&#39;s.
Many of these MUD&#39;s are still around,
in fact some are huge virtual realms that will take years to explore,
with decades of political history - 
<i>in real time!</i>
Beware:
MUD&#39;s are insanely addictive!
</p>

<p>
One suggestion is 
<a href="http://discworld.starturtle.net"><i>Discworld MUD</i></a>,
this MUD recreates Terry Pratchets world in startling detail
(check out the 
<a href="http://dw.daftjunk.com/Ankh-Morpork.png">Ankh-Morpork</a>
city map - each dot here is a playable location!)
You can play the game from the command line with:
<samp>telnet discworld.starturtle.net</samp>.
If you want to have even more enjoyment out of this game,
you can buy any of the 41 discworld novels on Amazon.
Other MUDS are available on
<a href="http://mudconnect.com">mudconnect.com</a>
</p>

<h3 id="edu">Edutainment</h3>

<p>
There isn&#39;t much edutainment software for the console,
but there are some.
The bsdgames collection contains a few,
 such as <samp>arithmetic</samp> and <samp>hangman</samp>,
which are fairly self explanatory.
Although having a slightly rude name,
<samp>wtf</samp> is a fairly useful utility,
it explains abbreviations.
And then there is <samp>quiz</samp> which asks you questions and evaluates your responses.
</p>
<p>
By default <samp>quiz</samp> contains questions for various topics,
such as European capital or Presidential terms.
You can either run <samp>quiz European capital</samp> to get the European nations and guess their capitals,
or <samp>quiz capital European</samp> to get the capitals and guess their European nations.
All quizzes can be reversed in this way.
The default questions however are usually very dated,
even using geography names from the Cold-War era,
but you can easily supply your own quiz files,
and this radically increases the programs usefulness as a learning tool!
</p>

<p>
Say you wanted to write a quiz to memorize the console commands used in this howto,
you could add this line to <samp>/usr/share/games/quiz/index</samp>
(it might be located in a different place on your system - check with <samp>locate quiz</samp>):
</p>

<p>
<samp>
/usr/share/games/quiz/console:console_task:command
</samp>
</p>

<p>
Now in the <samp>/usr/share/games/quiz/console</samp> file add these entries:
</p>

<pre>Watch a video:vlc|mplayer
Play some music:play|mocp
Browse the web:lynx|w3m|links
Read your e-mail:mutt|mail
Read a PDF file:fbi?pdf
View some images:fbi
...
</pre>



<p>
You can now brush up on your console skills with <samp>quiz console_task command</samp>.
Notice that the quiz database allows regex,
so the answer to &#34;Browse the web&#34; is either lynx, w3m or links,
and the answer to &#34;Read a PDF file&#34; is either fbipdf or fbpdf.
You may of course write other more useful quizzes,
such as vocabulary trainers when learning another language,
or quizzes that help you prepare for an exam.
</p>

<p>
Beyond bsdgames,
edutainment software for the console is rare,
but one fine exception is <samp>typespeed</samp>,
which is kind of a touch typing game.
And i suppose the most useful kind of edutainment is simply reading,
a great source of free online books can be found at <samp>gutenberg.org</samp>.
You can read these online with <samp>lynx</samp> or download them and read them in <samp>less</samp>.
Of course if you really want to challenge your brain muscles,
learn to program,
and write edutainment software yourself to fill this void :)
</p>

<h3 id="misc">Misc Fun</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/asciiquarium.png"></a>
</p>

<p>
You can have much geeky fun in the console beyond pure gaming.
<samp>fortune</samp> is a classic command from the bsdgames collection that produces random quotations and humorous snippets.
It&#39;s quite popular to add this program to <samp>/etc/motd</samp> or your shell configuration file,
so that you are always greeted with a random welcome message when you log in.
You can also pipe this output (or other text) to various fun filters such as:
</p>
<ul>
  <li><samp>cowsay</samp> - draws an ascii cartoon around the text</li>
  <li><samp>figlet</samp> (or <samp>toilet</samp>), or banner from the bsdgames collection - converts the text to asciiart banners
  </li><li><samp>lolcat</samp> - adds spectacular colors to the text
  </li><li>one of the filter from <samp>textfilters</samp> (or <samp>filters</samp>) such as <samp>pirate</samp> - that converts the text to pirate slang</li>
  <li><samp>rot13</samp> or <samp>pig</samp> from the bsdgames collection - obfuscate the text</li>
</ul>


<p>
If you want to produce a random quote with a random cow
(<samp>cowsay</samp> has many different &#34;cows&#34; to choose from),
you can do so with this script:
</p>

<pre><samp>
#!/bin/sh
# cowfortune - fortune with random cow
# usage: cowfortune
COWDIR=/usr/share/cowsay/cows
COWFILE=$(ls -1 $COWDIR | shuf | head -n 1)
fortune | cowsay -f $COWFILE
</samp>
</pre>


<p>
PS: Beware that some systems include offensive asciiart with sexual content,
whereas others have censored out these cows from the collection.
So printing a random &#34;cow&#34; may not be what you want.
You can always manually delete any of the cow files that offends you though.
</p>

<p>
You could also do something like this:
<samp>fortune | pirate | cowsay -f $(ls -l /usr/share/cowsay/cows | shuf | head -n 1) | lolcat</samp>
Have fun :^)
</p>

<p>
If you&#39;re into asciiart you will probably enjoy the &#34;screensavers&#34; <samp>cmatrix</samp> and <samp>asciiquarium</samp>.
The bsdgames collection also has a few that you can try out,
such as <samp>worms -t -d 50</samp> or <samp>rain -d 150</samp>.
</p>

<p>
Another fun command is <samp>sl</samp>,
which animates a steam locomotive in ascii traveling across your screen.
The joke is that <samp>ls</samp> is probably the command you type the most,
it&#39;s easy to mistype it as <samp>sl</samp>,
and when you do the steam locomotive will grieve you for several seconds...
</p>

<p>
FreeBSD has a nice program in its repo called <samp>coffeebreak</samp>.
It&#39;s just a shell script that runs a bunch of important looking sysadmin commands that does nothing.
The idea is to run <samp>coffeebreak</samp> at work whenever you need a break,
it looks like you are just waiting for something important to finish.
Other operating systems do not have this program,
but seasoned sysadmins can easily create such a script themselves.
Here is one simple way to do it:
Install and run <samp>ttyrec</samp>.
Now compile a bunch of stuff,
and type <samp>exit</samp> when you are done.
You can then,
<samp>mv ttyrecord ~/.coffeebreak</samp>,
and add this to <samp>~/.profile</samp> (or <samp>~/.bashrc</samp>):
<samp>alias coffeebreak=&#39;while true; do ttyplay ~/.coffeebreak&#39;; done</samp>
You now have your very own <samp>coffeebreak</samp> script!
To quit the playback,
hit <kbd>Ctrl</kbd> + <kbd>c</kbd>.
</p>

<p>
There are also various easter eggs in Linux land.
A popular example is to add <samp>Defaults Insults</samp> in <samp>/etc/sudoers</samp>,
which will make sudo rather obnoxious if you mistype your password.
Naturally you can make your own internal dad jokes too,
I often have the following in my <samp>~/.bashrc</samp>:
</p>

<pre># quirky humor
alias playdead=halt
alias lazarus=reboot
alias woman=man
alias dog=cat
...
</pre>



<p>
Judging from various terminal screenshots on the web,
many people seem to like <samp>linux_logo</samp> (or <samp>neofetch</samp>)
and <samp>tty_clock</samp>
(OpenBSD has its own version of this called <samp>grdc</samp>).
It is easy enough to write scripts with similar functionality yourself though.
You could for instance just create an ASCII art logo,
possibly with the aid of the aforementioned <samp>figlet</samp>.
You can then colorize it with <samp>lolcat</samp>.
As for the digital clock you can add the command <samp>cliclock</samp>,
which does much the same as tty_clock,
and <samp>topclock</samp>,
which will add a digital clock to the upper right corner for your terminal
(and you can still use your terminal normally),
by adding the following aliases to your shell configuration (eg. <samp>~/.bashrc</samp>):
</p>

<pre><samp>
alias cliclock=&#39;while sleep 1; do clear; date &#34;+%H:%M:%S&#34; | figlet -f smslant; done&#39;
alias topclock=&#39;while sleep 1; do tput sc; tput cup 0 $(($tput cols)-8)); date &#34;+%H:%M:%S&#34;; tput rc; done &amp;&#39;
</samp>
</pre>


<p>
You can do a whole lot of fun with <samp>telnet</samp>,
even in 2018!
Here are some suggestions:
</p><ul>
  <li><samp>telnet towel.blinkenlights.nl</samp>: watch StarWars IV in Ascii</li>
  <li><samp>telnet telehack.com</samp>, then <samp>eliza</samp>: talk with a psychotherapist</li>
  <li><samp>telnet freechess.org</samp>: play chess</li>
  <li><samp>telnet rainmaker.wunderground.com</samp>: display weather forecast</li>
  <li><samp>ssh sshtron.zachlatter.com</samp>: multiplayer racing game</li>
</ul>


<h2 id="office">Office</h2>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/office.png"></a>
</p>

<h3 id="documents">Reading Documents</h3>

<p>
The arch typical program for reading documents on the command line is <samp>less</samp>,
and for many UNIX users it is a well known tool for text reading.
What may come as a surprise though is that less can read a lot more than plain text files.
This is due to the fact that less allow a user to specify a preprocessor with the <samp>LESSOPEN</samp> environment variable.
Thus, 
any file that can be converted to text by some other program,
can be viewed automatically in less with the right configuration in place.
On most UNIX systems this preprocessor is set to <samp>/usr/local/bin/lesspipe.sh</samp> or a similar script,
which allows less to do a few fancy things like read the contents of a tar archive.
You can manually expand the <samp>lesspipe.sh</samp> script,
or even wholesale replace it,
to suit your viewing needs.
</p>

<p>
A nice github project that exploits this is 
<a href="https://github.com/wofr06/lesspipe">here</a>.
When you run the provided <samp>./configure</samp> script,
it checks to see if you have tools such as:
<samp>antiword</samp> to read Microsoft Word documents.
<samp>xlhtml</samp> to read MS Excel documents.
<samp>pdftotext</samp>, (from <samp>poppler-utils</samp>) which can read PDF documents.
And more.
When it has figured out what tools you have available,
it builds a corresponding <samp>lesspipe.sh</samp> script and a few helper scripts.
You can then install them simply by running <samp>sudo cp lesspipe.sh sxw2txt code2color tarcolor /usr/local/bin</samp>,
or other suitable location.
(make sure your <samp>LESSOPEN</samp> variable points to the correct script. eg. add <samp>export LESSOPEN=&#34;|/usr/local/bin/lesspipe.sh %s&#34;</samp> to your <samp>~/.profile</samp> or <samp>~/.bashrc</samp>)
</p>

<p>
With this in place you should be able to read quite a few documents with less.
But be aware that the quality of document to text rendering varies.
There is excellent support for old Microsoft office documents for instance,
but not for new ones.
The rendering of PDF&#39;s will vary depending on the file in question,
but it&#39;s usually not very good.
If you have a framebuffer device available,
your best bet is probably to convert your office documents to PDF and read them directly with a PDF reader such as <samp>fbipdf</samp>.
And HTML is easy enough to read in a browser such as <samp>lynx</samp>.
</p>

<h4 id="libreoffice">LibreOffice</h4>

<p>
The above script has one flaw, it is rather dated.
Worse, the tools needed to convert Microsoft Office documents are even less maintained.
Luckily LibreOffice has excellent support for converting different document formats,
and you can use it without the pesky GUI.
Here are some examples:
</p>

<pre><samp>
$ <i>soffice --headless --convert-to pdf mydoc.docx ; fbipdf mydoc.pdf</i>
$ <i>soffice --headless --convert-to html mydoc.docx ; lynx mydoc.html</i>
$ <i>soffice --headless --convert-to odt mydoc.docx ; odt2txt mydoc.odt</i>
</samp>
</pre>


<h4 id="epub">E-Books</h4>

<p>
Epubs are actually just zipped html files,
so in theory you can unzip the file and read the results with <samp>lynx</samp> or another browser.
In practice though it can be quite a mess to figure out which files correspond to the chapters you want.
<a href="http://devio.us/~dan/scripts/unix/sources/bin/eread">Here</a> is a script I made that tries to sort this out automatically.
It&#39;s crude, but works quite well in many cases.
You are welcome to try it (and improve it...).
</p>

<p>
Other ebook formats may not be that easy to read manually.
If you have installed <samp>calibre</samp>,
it comes with the <samp>ebook-convert</samp> command line tool,
which you can use to convert the ebook file into another format.
Some examples:
</p>

<pre><samp>
$ <i>ebook-convert mydoc.mobi mydoc.pdf ; fbipdf mydoc.pdf</i>
$ <i>ebook-convert mydoc.mobi mydoc.html ; lynx mydoc.html</i>
$ <i>ebook-convert mydoc.mobi mydoc.txt ; cat mydoc.txt</i>
</samp>
</pre>


<h4 id="cbr">CBR Comic Books</h4>

<p>
CBR comic books are just images archived with rar,
you can read them in the console by <samp>unrar</samp>&#39;ing the file and then view the images with <samp>fbi</samp> if you have a framebuffer device available
(cbz files are zipped images, so use <samp>unzip</samp> on them).
</p>

<h3 id="spelling">Writing Text and Spell Checking</h3>

<p>
There is a ridiculous amount of text editors available for UNIX.
A popular editor for beginners is <samp>nano</samp>
(or <samp>ee</samp> in the BSD world),
you can freely move about with the cursor keys and type in your text.
When you are done hit <kbd>Ctrl</kbd> + <kbd>x</kbd> to quit,
the editor will ask if you want to save your work,
hit <kbd>y</kbd> for yes if you do.
You can see a quick menu of the most common file operation commands at the bottom,
<samp>^X Exit</samp> for instance means hit <kbd>Ctrl</kbd> + <kbd>x</kbd> to exit.
</p>

<p>
You can spell check your files interactively with <samp>aspell -c myfile</samp>,
or <samp>aspell -l lang -c myfile</samp>,
if you need to specify the language.
</p>

<p>
Not all UNIX&#39;es come with <samp>aspell</samp> (or <samp>ispell</samp>/<samp>hunspell</samp>/etc...) by default,
but virtually all come with the classic spell checker <i>spell</i>.
<samp>Spell</samp> is a very simple program.
It checks if your words are found in the systems plain text dictionary
(usually in <samp>/usr/share/dict/words</samp>),
if not it just prints the presumably misspelled word.
By the way you can manually check for words in this dictionary with the
<samp>look</samp>
command.
Using <samp>spell</samp> may at first seem to be very inefficient,
since it just hands you a long list of words that you need to manually check and correct yourself.
But for precisely that reason it is actually very efficient at teaching you correct spelling...
</p>

<p>
The classic text editors on UNIX are <samp>emacs</samp> 
(see <samp>mg</samp> for OpenBSD),
and <samp>vi</samp>.
Emacs is notorious for being over engineered,
it can read your email and browse the web,
not to mention play games,
it can even edit text files!
Vi on the other hand is notorious for being overly complex to use.
You need to learn quite a few keyboard commands in order to use it,
and you need to navigate back and forth between different modes.
Both of these editors will require some effort to learn,
but they are extremely useful when mastered.
If you want to become a productive UNIX user,
learn one of them!
</p>

<p>

</p>

<p>
By the way both <samp>vim</samp>
(<samp>vi</samp> improved)
and <samp>Emacs</samp> have internal spell checkers you can use,
<samp>:set spell</samp> for <samp>vim</samp>, and <kbd>Alt</kbd> + <kbd>x</kbd> <samp>ispell-buffer</samp> for <samp>Emacs</samp>.
But it&#39;s just as easy to use <samp>aspell</samp> from within <samp>vi</samp>/<samp>vim</samp> by running
<samp>:!aspell -c myfile</samp>
(the <samp>Emacs</samp> <samp>ispell</samp> command actually uses <samp>aspell</samp> as its backend).
</p>

<h3 id="dictionary">Dictionaries</h3>

<p>
<i>WordNet</i> is a very good English dictionary,
you can lookup a word from the command line like so:
<samp>wn flabbergasted -over</samp> 
(over means &#34;overview&#34;).
Sadly there arn&#39;t many such alternatives for languages other then English,
but you may be able to find a free online dictionary,
and if you are lucky it might even work in <samp>lynx</samp>.
</p>

<p>
Way back in the 70&#39;s UNIX came with the Writer&#39;s Workbench suit of tools.
Today much of this functionality has been continued with the GNU tools 
<samp>diction</samp> and <samp>style</samp>.
These tools do basic sanity checks of your documents,
such as checking if two identical words are written right next to each other.
And <samp>style</samp> does a basic analysis of your prose.
Of course the tools cannot actually make you a good writer,
but they are handy utilities nonetheless
(they only support English and German).
And like all the classic UNIX tools,
it pays great dividends to split your work into many small files
(eg. <samp>cat chap* &gt; book</samp>),
otherwise the output from these commands will be overwhelming.
</p>

<h3 id="writing">Writing Documents</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/word.png"></a>
</p>


<p>
The closest console equivalent to a typical &#34;word processor&#34; is <samp>wordgrinder</samp>.
It is basically Word Pad for the terminal,
so it lets you add a few basic extras to your text documents,
such as underlined text,
chapter headers or bullet points.
Just hit Esc to bring up the main menu.
It uses it&#39;s own fileformat by default,
but you can export this to other formats,
such as ODT, LaTeX or HTML.
A slightly more professional way to write your documents though,
would be to type them directly in a markup language in a text editor,
and then converting the source files to document format,
such as a PDF.
Beyond amateur HTML (and *ahem* Markdown),
there are several candidates available to you.
Here are three examples:
</p>

<h4 id="troff">Troff</h4>

<p>
<samp>troff</samp> is the markup language used to write man pages in UNIX,
and as such it isn&#39;t very impressive.
The man pages are just plain text with little formatting finesse.
This however is not because troff is primitive,
but rather that the terminal <i>is</i>.
By default troff writes postscript files as its output,
intended for printers.
If you write a man page in this output,
you will see that the humble man page actually looks very much like a professional document:
</p>

<pre><samp>
$ <i>cp /usr/man/man1/ls.1.gz /tmp &amp;&amp; cd /tmp</i>
$ <i>gunzip ls.1.gz</i>
$ <i>groff -m man -T pdf ls.1 &gt; ls.pdf</i>
$ <i>fbipdf ls.pdf</i>
</samp>
</pre>


<p>
Of course it still looks like a man page,
as it should since its written with the <samp>man</samp> macro package
(pure troff markup is very low level,
you usually write documents with higher level macro commands).
But troff is capable of producing other document types as well.
Several computer text books have been written in troff.
Naturally this includes the UNIX classics such as 
<i>The C Programming Language</i> and <i>The UNIX Programming Environment</i>,
but also some modern works such as 
<i>The Design and Implementation of the FreeBSD Operating System</i>.
These books contain indexes, footnotes, graphs, diagrams, pictures,
tables and most confections you would expect to find in professional literature
(troff&#39;s complete lack of comic sans and clip-arts reinforces the professional vibe).
</p>

<p>
A popular troff macro package for general purpose documents is <samp>ms</samp>.
Here is an example letter written in ms:
</p>

<pre><samp>
.LP
.DS L
To: Archduke Poggle of Geonosis
23 Insectoid Str.
Hive
103133
GEONOSIS
.DE
.DS L
From: Emperor Palpatine
Imperial Palace
PO 000001
Senate District
CORUSCANT
.DE
.SH
Dear Archduke
.PP
The so called
.I 
undefeatable
.R
Death Star was blown to bits by a bunch of teenagers yesterday.
I must say I am disappointed!
We need to construct a new planet killer ASAP,
and this time lets try to avoid an
.B
Achilles heel
.R
in our design shall we?
.PP
I have some other ideas for further improvements.
First of all we need a 
.I
menacing 
.R
throne room with a view...
</samp>
</pre>


<p>
The syntax here is fairly simple.
You first write an <samp>ms</samp> command,
which all begin with a dot, 
such as <samp>.SH</samp> (a section header).
This command is then applied to the following text,
until you encounter another <samp>ms</samp> command.
You will find troff included by default on virtually every UNIX system,
and it is a simple document system that is indispensable for system administrators,
and surprisingly useful for casual use.
Another advantage of troff is that its syntax fits very well with the line based UNIX tools,
for instance to convert a troff file to plain text you would only need to do this:
<samp>cat mydoc.ms | sed &#39;/\..*/d&#39; | fmt</samp>
</p>

<p>
You can convert the above ms source file to various document formats,
such as a PDF:
<samp>groff -m ms -T pdf mydoc.ms &gt; mydoc.pdf</samp>
It will look like this:
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/troff.png"></a>
</p>

<p>
Some important <samp>ms</samp> macros:
</p>

<p>
Ironically the markup language used to write UNIX manuals,
troff,
is not well documented.
This has mainly to do with the fact that it did not catch on as a general purpose documentation tool outside of Bell Labs.
Still,
the old Bell Labs papers on these tools are very useful references,
even for modern versions of these programs.
<i>PS</i>:
Linux systems today use <samp>groff</samp> and BSD systems use <samp>mandoc</samp>,
but both are essentially backwards compatible with the original UNIX <samp>troff</samp>.
Mandoc however can only render manpages,
so install <samp>groff</samp> as well on BSD systems if you plan to write generic troff documents.
If you need to write an actual man page,
check man 7 man.
There are also a number of troff preprocessors that can add specific functionality,
most of them have fairly decent man pages.
In the list below you will also find links to the old Bell Labs papers on these tools:
</p>

<p>
<samp><a href="https://pspodcasting.net/dan/blog/2018/docs/troffref.pdf">troff</a></samp> - Reference manual
</p>

<h4 id="tex">Tex</h4>

<p>
Perhaps the most widely used document system on UNIX is <samp>Tex</samp>
(<samp>latex</samp> is a dialect of Tex).
It was originally written because it&#39;s author was annoyed by the limitations of troff.
Tex has become quite popular in the scientific community,
and it is not unusual for universities to require students to send in their papers in this format.
Of course you can also use Tex to write your personal letters and todo lists.
Although Tex is not normally included by default in UNIX systems,
you can usually install a Tex distribution, 
like the <samp>texlive-base</samp> or a similar package,
with the systems package manager
(<i>PS</i>:
Unlike troff,
Tex is a <i>large</i> package,
it can take more than a gigabyte of diskspace!
(that&#39;s like a <i>thousand</i> floppy disks!!!)).
The above example letter in Tex would be written like this:
</p>

<pre><samp>
\documentclass{article}
\begin{document}

\begin{verbatim}
To: Archduke Poggle of Geonosis
23 Insectoid Str.
Hive
103133
GEONOSIS
\end{verbatim}

\begin{verbatim}
From: Emperor Palpatine
Imperial Palace
PO 000001
Senate District
CORUSCANT
\end{verbatim}

\section*{Dear Archduke}

The so called \emph{undefeatable} Death Star was blown to bits by a bunch of teenagers yesterday.
I must say I am disappointed!
We need to construct a new planet killer ASAP,
and this time lets try to avoid an \textbf{Achilles heel} in our design shall we?

I have some other ideas for further improvements.
First of all we need a \emph{menacing} throne room with a view..

\end{document}
</samp>
</pre>


<p>
As you can see the Tex syntax is more free form,
where you can intersperse normal text with formatting commands.
You can convert the Tex source file to more useful document types,
such as a PDF:
</p><pre><samp>
$ <i>latex mydoc.tex </i>
$ <i>dvipdf mydoc.dvi</i>
</samp>
</pre>
(<i>PS</i>:
Tex is very particular about its syntax,
latex will fail to compile the document for instance if you leave out
the <samp>\end{document}</samp> line at the end).
It will look like this:


<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/tex.png"></a>
</p>

<p>
The Tex equivalents to the above mentioned ms macros:
</p>

<p>
You can probably find a useful Tex tutorial with a quick Google search
(although <samp>latex</samp> might give you some unwarranted results),
and there are several useful books on the subject available on Amazon.
</p>

<h4 id="docbook">Docbook</h4>

<p>
The other serious competitor to Tex (in terms of popularity at least), 
is Docbook.
It is basically HTML for books.
Which may or may not be a good thing,
depending on your background
(ei. if you are a script kiddie or not).
Here is an example of how you could write the above letter:
</p>

<pre><samp>
&lt;!DOCTYPE article PUBLIC &#34;-//OASIS/DTD DocBook XML V4.5//EN&#34; &#34;/usr/share/xml/docbook/xml-dtd-4.5/docbookx.dtd&#34;&gt;
&lt;article&gt;
  &lt;section&gt;
    &lt;para&gt;
      &lt;literallayout&gt;
        To: Archduke Poggle of Geonosis
        23 Insectoid Str.
        Hive
        103133
        GEONOSIS
      &lt;/literallayout&gt;
    &lt;/para&gt;
  &lt;/section&gt;

  &lt;section&gt;
    &lt;para&gt;
      &lt;literallayout&gt;
        From: Emperor Palpatine
        Imperial Palace
        P0 000001
        Senate District
        CORUSCANT
      &lt;/literallayout&gt;
    &lt;/para&gt;
  &lt;/section&gt;

  &lt;section&gt;
    &lt;title&gt;Dear Archduke/title&gt;
    &lt;para&gt;
      The so called &lt;emphasis&gt;undefeatable&lt;/emphasis&gt; Death Star was
      blown to bits by a bunch of teenagers yesterday. I must say I am
      disappointed! We need to construct a new planet killer ASAP, and
      this time lets try to avoid an &lt;emphasis role=&#34;bold&#34;&gt;Achilles
      heel&lt;/emphasis&gt; in our design shall we? I have some other ideas
      for further improvements. First of all we need a menacing throne
      room with a view...
    &lt;/para&gt;
  &lt;/section&gt;
&lt;/article&gt;
</samp>
</pre>


<p>
We can now convert this source document into html or other formats,
for example assuming you saved this letter as <i>letter.xml</i> you can:
</p>

<pre><samp>
$ <i>STYLEST=/usr/share/xml/docbook/xsl-stylesheets-1.78.1/html/docbook.xsl</i>
$ <i>xsltproc -o letter.html $STYLEST letter.xml</i>
</samp>
</pre>


<p>
The result will look similar (browser dependent) to this:
</p>

<p>
<a href="https://pspodcasting.net/images/dan/blog/2018/docbook.png"></a>
</p>

<p>
There is a bewildering plethora of different docbook tools available,
and the method used to produce docbook documents can vary greatly.
This is just an example.
Also note that the <i>docbookx.dtd</i> and <i>docbook.xsl</i> files used here can be located in different places on different systems, 
check with <samp>locate docbookx.dtd docbook.xsl</samp>
(You might need to install a package or two to get them).
</p>

<p>
The Docbook equivalents to the above mentioned Tex commands:
</p>

<p>
Writing left-aligned paragraphs, numbered paragraphs, footnotes or linebreaks,
can be done with various clever hacks, that is anything but intuitive.
Buy a book an Amazon or search the web for tutorials to get the gory details,
or better yet,
choose a different markup language to write your documents in.
</p>

<h3 id="spreadsheets">Spreadsheets and Databases</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/sheet.png"></a>
</p>

<p>
<samp>sc</samp> is quite a decent spreadsheet for the console.
It has its own way of doing things though,
so initially you will want to hit <samp>?</samp> and spend some time learning the ropes.
Sc uses its own file format by default,
but it can export to LaTex or tbl (ei. troff) too.
Of course <samp>sc</samp> is a poor substitute for Excel,
but then again,
Excel is a poor substitute for a database.
And there are many professional databases available for UNIX,
such as <samp>MariaDB</samp> and <samp>PostgreSQL</samp>.
For private use though <samp>Sqlite</samp> is probably sufficient:
</p>

<h4 id="sqlite">Sqlite</h4>

<p>
Let&#39;s apply a popular spreadsheet pass time to our SQL database,
making a budget and doing our accounting:
</p>

<pre><samp>
$ <i>sqlite3 account.db</i>
sqlite&gt; <i>CREATE TABLE account ( id INTEGER PRIMARY KEY, date TEXT DEFAULT CURRENT_DATE,</i>
   ...&gt; <i>category TEXT DEFAULT &#39;food&#39;, price INTEGER NOT NULL, desc TEXT );</i>
sqlite&gt; <i>INSERT INTO account ( category, price, desc ) VALUES ( &#39;sweets&#39;, 1.25, &#39;coca cola&#39; );</i>
sqlite&gt; <i>INSERT INTO account ( category, price, desc ) VALUES ( &#39;sweets&#39;, 2.95, &#39;candy bar&#39; );</i>
sqlite&gt; <i>INSERT INTO account ( date, price ) VALUES ( &#39;2018-04-25&#39;, 20.65 );</i>
sqlite&gt; <i>.headers on</i>
sqlite&gt; <i>.mode column</i>
sqlite&gt; <i>SELECT * FROM account ORDER BY date;</i>
</samp>
</pre>


<p>
This will produce an output similar to this:
</p>

<table>
<tbody><tr>
<td>id</td>
<td>date</td>
<td>category</td>
<td>price</td>
<td>desc</td>
</tr>
<tr>
<td>----------------</td>
<td>----------------</td>
<td>----------------</td>
<td>----------------</td>
<td>----------------</td>
</tr>
<tr>
<td>3</td>
<td>2018-04-25</td>
<td>food</td>
<td>0.65</td>
<td>chewing gum</td>
</tr>
<tr>
<td>1</td>
<td>2018-04-26</td>
<td>sweets</td>
<td>1.25</td>
<td>coca cola</td>
</tr>
<tr>
<td>2</td>
<td>2018-04-26</td>
<td>sweets</td>
<td>2.95</td>
<td>candy bar</td>
</tr>
</tbody></table>



<p>
With this database in place you can list particular types of expenses:
<samp>SELECT * FROM account WHERE category = &#39;sweets&#39;;</samp>,
or summarize them:
<samp>SELECT sum(price) AS total FROM account WHERE category = &#39;sweets&#39;;</samp>.
Type <samp>.help</samp> for more instructions,
and <samp>.quit</samp> to exit SQLite.
Using SQL databases from a shell script is also quite trivial.
Here is a simple example:
</p>

<pre><samp>
#!/bin/sh
# sqlaccount - manage an sql account
# usage: sqlaccount [-d date] [-c category] [-s category] [amount comments...]

database=$HOME/account.db
if [ ! -f $database ]; then
	echo &#34;CREATE TABLE account ( id INTEGER PRIMARY KEY, date TEXT DEFAULT CURRENT_DATE, category TEXT DEFAULT &#39;food&#39;, price INTEGER NOT NULL, desc TEXT );&#34; | sqlite3 $database
fi

if [ $# = 0 ]; then
	echo &#34;SELECT * FROM account ORDER BY date;&#34; | sqlite3 -column $database
	exit
fi

date=$(date &#34;+%Y-%m-%d&#34;)
category=food
for args in &#34;$@&#34;; do
	case &#34;$args&#34; in
		-d) date=$2 ; shift 2 ;;
		-c) category=$2 ; shift 2 ;;
		-s)
			if [ $# = 1 ]; then
				echo &#34;SELECT sum(price) AS total FROM account;&#34; | sqlite3 -column $database
			else
				echo &#34;SELECT sum(price) AS total FROM account WHERE category = &#39;$2&#39;;&#34; | sqlite3 -column $database
			fi
			exit ;;
	esac
done
price=$1
shift

echo &#34;INSERT INTO account ( date, category, price, desc ) VALUES ( &#39;$date&#39;, &#39;$category&#39;, $price, &#39;$@&#39;);&#34; | sqlite3 $database
</samp>
</pre>


<p>
You can now do something like this:
</p>

<pre><samp>
$ <i>sqlaccount -c sweets 1.25 coca cola</i>
$ <i>sqlaccount -c sweets 2.95 candy bar</i>
$ <i>sqlaccount -d 2018-04-25 20.65</i>
$ <i>sqlaccount</i>
3 2018-04-25 food   20.65
1 2018-04-26 sweets 1.25  coca cola
2 2018-04-26 sweets 2.95  candy bar
$ <i>sqlaccount -s</i>
24.85
$ <i>sqlaccount -s sweets</i>
4.2
</samp>
</pre>


<p>
There is a whole heck of a lot you can do with an SQL database,
we have only scratched at the very surface here.
There are many fine books on this subject on Amazon,
and I am sure you can find a useful tutorial if you Google for it.
It does require some effort to learn SQL,
but once you have done so,
you will never need a spreadsheet again!
</p>

<h4 id="awk">AWK</h4>

<p>
You may feel that the above example was far too complicated,
you are absolutely right.
In fact if you ever see anyone doing their personal accounting in an SQL database,
slap them
(one exaggeration deserves another)!
It is in fact quite simple to just type in your account information in a plain text editor,
and summarize them or query the accounts with sed or awk.
Consider this example:
</p>

<pre><samp>
2018-04-25 food 20.65
2018-04-26 sweets 1.25 coca cola
2018-04-26 sweets 2.95 candy bar
</samp>
</pre>


<p>
You can list all account records for April 2018 by:
<samp>sed -n &#39;/^2018-04/p&#39; account.txt</samp>,
or summarize the march expenses by:
<samp>awk &#39;/^2018-04/ { sum+=$3 } END { print sum }&#39; account.txt</samp>.
Or if you only want to summarize your candy expenditures for April:
<samp>awk &#39;/^2018-04.* sweets/ { sum+=$3 } END { print sum }&#39; account.txt</samp>.
A more elaborate example of an accounting shell script can be found in the
<a href="#accounting">Accounting section</a>.
</p>

<p>
Do not be quick to dismiss <samp>awk</samp>,
it can do much more then you think.
In section 4.3 of the classic book <i>The AWK Programming Language</i>,
for example
(if you don&#39;t have this in your bookshelf - <i>get it!</i>),
the authors demonstrate how a ~50 line awk script enables you to create a relational database spread across multiple files,
using column name tags instead of numbers.
Awk is also <i>fast</i>,
unless you are planning to develop a website with hundreds of requests per second,
industry grade databases will not give you any significant speed improvements.
Best of all,
when you have mastered awk,
you will find a million other uses for this versatile utility!
</p>

<h3 id="presentation">Presentations</h3>

<p>
<a href="https://pspodcasting.net/dan/blog/2018/images/tpp.png"></a>
</p>

<p>
It is odd that businessmen place so much emphasis on presentations,
when they are really just a slideshow of pictures,
lightly sprinkled with semi-relevant text.
There are presentation specific software for the console,
such as <samp>tpp</samp>,
you can also create slides with <samp>tex</samp> or even <samp>troff</samp>.
Another approach is to create a bunch of images with sequential names (eg 001.jpg, 002.jpg, etc...),
and view them with an image viewer like <samp>fbi</samp>
(you can add text to the pictures with ImageMagick if you like).
</p>

<p>
If you want to give tpp a go,
read the instructions in <samp>/usr/share/doc/tpp/README</samp>
(it might be located somewhere else on your system).
It&#39;s fairly straight forwards.
TPP uses its own file format,
ut it can also export to LaTex.
The above tpp screenshot was created with this tpp file:
</p>

<pre><samp>
--bgcolor white
--fgcolor magenta

--newpage
--heading A Short Demo of TPP

--withborder
--center Presentations are written as plain text,
--center but you can manipulate the text in various ways.
--center For example, you can change
--boldon 
--color  red
--center font style and color
--boldoff
--## ulon means &#34;underline on&#34;, this is a comment btw
--ulon
--color  blue
--center in various ways
--uloff
--color  magenta
--center and you can play around with
--huge   ----Figlet----

--center Thats about it
--center Use the arrow keys or space to move around in the slide show.
--newpage
</samp>
</pre>


<h3 id="math">Math and Graphs</h3>

<p>
For mathematical tasks,
<samp>bc</samp> is the goto tool.
You can use it interactively or within your scripts.
Just be aware that this calculator doesn&#39;t do floating point arithmetic by default,
you can either use the <samp>-l</samp> flag to set the scale to 20 and also enable some advanced mathematical functions 
(sine, cosine, arctangent, logarithms etc...),
or you could just set the scale to the accuracy you need.
To demonstrate:
</p>

<pre><samp>
$ <i>bc -q</i>
<i>20.2 / 10</i>
2
<i>scale=2</i>
<i>20.2 / 10</i>
2.02
<i>quit</i>
$ <i>echo pi = $(echo &#34;4*a(1)&#34; | bc -l)</i>
pi = 3.14159265358979323844
</samp>
</pre>


<p>
Of course there are other mathematical tools available.
For instance, <samp>dc</samp> is a reverse-polish desk calculator,
if you happen to be a 100 years old and like that sort of thing...
</p>

<p>
As for graphs,
the goto program is <samp>gnuplot</samp>.
This program can do any imaginable thing relating to graphs,
and then some.
But just to get you started,
let take a very simple example:
</p>

<p>
Suppose you have used the above mentioned <samp>sqlaccount</samp> script to check how much expenses you had from January to December in 2017,
and you added these numbers to a text file like so:
</p>

<pre><samp>
01 2104
02 2260
03 1987
04 2053
05 2242
06 2321
07 2107
08 2134
09 2032
10 1934
11 2143
12 2355
</samp>
</pre>


<p>
You can then use gnuplot to make a graph out of this:
</p>

<pre><samp>
$ <i>gnuplot</i>
gnuplot&gt; <i>set term pngcairo</i> # you may need to use pdfcairo
gnuplot&gt; <i>set title &#39;Expenditures 2017&#39;</i>
gnuplot&gt; <i>set out &#39;expenditures.png&#39;</i>
gnuplot&gt; <i>unset key</i>
gnuplot&gt; <i>set grid</i>
gnuplot&gt; <i>plot [1:12] &#39;months.txt&#39; with line</i>
gnuplot&gt; <i>quit</i>
</samp>
</pre>


</div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 04:52:03 +0000</pubDate>
      <source>https://pspodcasting.net/dan/blog/2018/console_desktop.html</source>
    </item>
    <item>
      <title>Australia is becoming a surveillance state</title>
      <link>https://ia.acs.org.au/article/2021/australia-is-becoming-a-surveillance-state.html</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___ia_acs_org_au_article_2021_australia-is-becoming-a-surveillance-state_html/image.jpg" /> 
<div id="readability-page-1" class="page"><div>
	    <p></p><p>The government should modernise and consolidate its surveillance powers. Image: Shutterstock</p>
	</div><div>
	    <p>The government‚Äôs approach to technological surveillance is leading us down a dark path, experts warn, as it prepares to give law enforcement agencies new hacking powers.</p>
<p>Currently before parliament‚Äôs Intelligence and Security Committee, the <a href="https://www.homeaffairs.gov.au/about-us/our-portfolios/national-security/lawful-access-telecommunications/surveillance-legislation-amendment-identify-and-disrupt-bill-2020">Surveillance Legislation Amendment (Identify and Disrupt) Bill 2020</a> is the government‚Äôs latest attempt to gain a watchful eye over cyber space.</p>
<p>Once the bill passes, it will dish out extra power to the Australian Federal Police (AFP) and the Australian Criminal Intelligence Commission (ACIC), giving the agencies access to new warrants that will let them modify and delete data, collect intelligence from online communities, and even take over the online accounts of supposed criminals.</p>
<p>Speaking at a webinar hosted by <a href="https://www.efa.org.au/">Electronic Frontiers Australia</a> last week, senior lecturer in criminology at Deakin University, Dr Monique Mann, said the laws are just the latest in what she called a ‚Äúhyper-legislative‚Äù approach to electronic surveillance.</p>
<p>‚Äú[These laws] represent, in my view, significant expansions of the existing powers of law enforcement agencies away from a traditional focus on investigation and the collection of admissible evidence of specific offenses to disruption, to attack, to take-over, to take-down,‚Äù Dr Mann said.</p>
<p>‚ÄúThese typically are powers that are reserved for the Australian Signals Directorate (ASD).</p>
<p>‚ÄúHere the distinction between intelligence and evidence, and the activities of law enforcement and signals agencies is being eroded.</p>
<p>‚ÄúThis comes with democratic costs ‚Äì impacts on liberties such as freedom of expression and freedom of the press.‚Äù</p>
<p><strong>Expanding powers</strong></p>
<p>Since 2015, when the government passed its <a href="https://www.smh.com.au/politics/federal/senate-passes-controversial-metadata-laws-20150326-1m8q3v.html">controversial metadata retention laws</a>, law enforcement agencies have gained greater oversight into the digital domain of everyday Australians by rushing through the <a href="https://ia.acs.org.au/article/2018/it-happened--encryption-bill-gets-through.html">Encryption Bill</a> late in the last parliamentary sitting day of 2018.</p>
<p>Both sets of legislation have continued to cause controversy with the <a href="https://ia.acs.org.au/article/2020/atlassian--australia-s-reputation--significantly-degraded-.html">tech industry warning</a> that the encryption laws ‚Äúsignificantly degraded the global reputation of the Australian tech sector‚Äù while reviews have found <a href="https://ia.acs.org.au/article/2019/police-illegally-access-metadata.html">law enforcement</a> misusing their <a href="https://ia.acs.org.au/article/2021/afp-misused-metadata-powers.html">metadata powers</a>.</p>
<p>Lawyer and chair of the EFA‚Äôs policy team, Angus Murray, said the current ‚Äúmess‚Äù of surveillance legislation ‚Äì which is being added to with the Identify and Disrupt Bill ‚Äì is broad, vague, and not fit for purpose.</p>
<p>‚ÄúLegislation has to adhere to a parliamentary intention,‚Äù he said.</p>
<p>‚ÄúAn intention to introduce legislation that deals with child exploitation material or to combat terrorism that has a scope that is extremely widely defined ‚Äì and, by the assistance and access legislation, amends the definition of ‚Äòcomputer‚Äô to effectively mean ‚Äòthe internet‚Äô ‚Äì puts us in a situation where firstly the scope and the full power of law is not actually understood.</p>
<p>‚ÄúSecondly, the courts are left to guide the community in terms of how the law is ultimately applied.</p>
<p>‚ÄúAnd thirdly, it‚Äôs unlikely this legislation will be repealed once it‚Äôs passed.‚Äù</p>
<p><strong>The Richardson Review</strong></p>
<p>The complexity of Australia‚Äôs existing surveillance legislation was firmly pointed out in the Comprehensive Review of the Legal Framework of the National Intelligence Community which was published in a de-classified format <a href="https://www.ag.gov.au/national-security/publications/report-comprehensive-review-legal-framework-national-intelligence-community">late last year</a> after going through a year‚Äôs-long redaction process.</p>
<p>Commonly known as the Richardson Review, the lengthy four-volume, 1,300-page document outlines a much-needed overhaul of existing legislation and the creation of a new, modernised, Electronic Surveillance Act.</p>
<p>Dr Mann said to enact the full recommendations of the Richardson Review would in effect require the repeal and re-writing of ‚Äúabout 1,000 pages of existing telecommunications surveillance law‚Äù.</p>
<p>‚ÄúThe whole point leading to this review is because the Telecommunications Interception and Access Act, developed in 1979, has not kept up with the scale and pace of technological change, it needs to be updated, it‚Äôs no longer fit-for-purpose.</p>
<p>‚ÄúI think moving forward, this landscape, in the Australian context, is going to be changing. It‚Äôs going to take time ‚Äì a long time ‚Äì to do a lot of that repealing and re-writing.‚Äù</p>
<p>Murray doesn‚Äôt share Dr Mann‚Äôs optimism, however, that the government will work to enact a consolidated Electronic Surveillance Act.</p>
<p>‚ÄúIn my view and experience, it isn‚Äôt ordinary for government to attempt to make things easier,‚Äù he said.</p>
<p>‚ÄúThe reason why it‚Äôs scattered out at the moment I think is to give power across a variety of bases.</p>
<p>‚ÄúAnd law that‚Äôs confusing is law that can be applied without people appreciating its consequences.‚Äù</p>

	    
	</div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 07:19:37 +0000</pubDate>
      <source>https://ia.acs.org.au/article/2021/australia-is-becoming-a-surveillance-state.html</source>
    </item>
    <item>
      <title>Interactive introduction to game theory and trust</title>
      <link>https://ncase.me/trust/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___ncase_me_trust_/image.jpg" /> 
<div id="readability-page-1" class="page">
	<p>loading...</p> <!-- TRANSLATE THIS -->
	
	
















<!-- Core Engine -->













<!-- Simulations -->






<!-- Slides -->











<!-- Main Code -->

</div>]]></content:encoded>
      <pubDate>Mon, 09 Aug 2021 09:32:19 +0000</pubDate>
      <source>https://ncase.me/trust/</source>
    </item>
    <item>
      <title>A novel approach to entity resolution using serverless technology</title>
      <link>https://tilodb.com/tilodb</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___tilodb_com_tilodb/image.jpg" /> 
<div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <div>
              
              
              <p>
                  The API is provided using GraphQL via AWS API Gateway and
                  Lambda. Adding data into the database works by calling the
                  <code>submit</code> mutation, which in a very simplified way
                  looks like:
                </p>
              <div>
                <pre><code>{
  submit(
    new: {
      firstName: &#34;John&#34;
      surName: &#34;Smith&#34;
      address: {
        street: &#34;Augustinerstr.&#34;
        houseNumber: &#34;1&#34;
        city: &#34;M√ºnchen&#34;
      }
    }
    old: {
      firstName: &#34;John&#34;
      surName: &#34;Smith&#34;
      address: {
        street: &#34;Jungfernstieg&#34;
        houseNumber: &#34;7&#34;
        city: &#34;Hamburg&#34;
      }
    }
  )
}
</code></pre>
              </div>
              <div>
                <p>
                  The example represents the submission of the current address
                  for John as well as one of his previous addresses. A
                  submission might only include the current known address and
                  include no previous addresses. TiloDB makes the connections
                  with existing data in the database using the pre-configured
                  rules, regardless of how much data is submitted.</p>
                <ul>
                  <li>matching</li>
                  <li>deduplication</li>
                  <li>updating</li>
                  <li>indexing</li>
                </ul>
              </div>
              
              
              <div>
                <p>
                  An entity resolution technology must compare different data
                  sets with other potential matches in order to identify the
                  right candidates that belong to one particular entity.
                  Additionally, comparison of different data sets is also
                  relevant when performing the search as well as when
                  identifying possible duplicates. The goal is always to have as
                  few comparisons between data sets as possible. Ideally, each
                  resulting data ‚Äúblock‚Äù contains only the correct results.
                  However, for fuzzy matching, e.g. when using the Levenshtein
                  distance, this is not possible.</p>
                <ul>
                  <li>
                    <code>R1</code>: matching if: first name, surname and city
                    are lowercase equal, OR
                  </li>
                  <li>
                    <code>R2</code>: matching if: city and street are lowercase
                    equal and the name parts have the same metaphone value and a
                    maximum Levenshtein distance of 1</li>
                  <li><code>R1:john:smith:m√ºnchen</code></li>
                  <li><code>R1:john:smith:hamburg</code></li>
                </ul>
                <p>
                  Resulting in any data having the same index key to be matching
                  without any further comparison.</p>
                <ul>
                  <li><code>R2:m√ºnchen:augustinerstr.:JN:SM0</code></li>
                  <li><code>R2:hamburg:jungfernstieg:JN:SM0</code></li>
                </ul>
                
                <p>
                  Where JN is the metaphone value for John and SM0 for Smith.
                  Everything with the same index key would result in being a
                  potential match.</p>
              </div>
              <div>
                <table>
                  <thead>
                    <tr>
                      <th>
                        index_key
                      </th>
                      <th>data</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>
                        R1:john:smith:m√ºnchen
                      </td>
                      <td>{&#34;aaa&#34;}</td>
                    </tr>
                    <tr>
                      <td>
                        R1:john:smith:hamburg
                      </td>
                      <td>{&#34;bbb&#34;}</td>
                    </tr>
                    <tr>
                      <td>
                        R2:m√ºnchen:augustinerstr.:JN:SM0
                      </td>
                      <td>
                        {&#34;aaa:john:smith&#34;}
                      </td>
                    </tr>
                    <tr>
                      <td>
                        R2:hamburg:jungfernstieg:JN:SM0
                      </td>
                      <td>
                        {&#34;bbb:john:smith&#34;}
                      </td>
                    </tr>
                  </tbody>
                </table>
              </div>
              <div>
                <p>
                  The <code>data</code> column is a string set that contains at
                  least the ID of the corresponding data set(s). For
                  <code>R2</code> it also contains the first and surname, which
                  will be used when doing the final comparison. This has the
                  advantage of not needing to load the actual data from
                  somewhere else.
                </p>
                <p>
                  Furthermore, this table structure has the advantage that data
                  can be added very easily. This is valid in case of a complete
                  new index key as well as for adding data to an already
                  existing index key. Both cases can be handled with the same
                  DynamoDB update query:
                </p>
                <ul>
                  <li>
                    Key:
                    <code>{&#34;index_key&#34;: {S: &#34;R1:john:smith:m√ºnchen&#34;}}</code>
                  </li>
                  <li>UpdateExpression: <code>&#34;ADD data :data&#34;</code></li>
                  <li>
                    ExpressionAttributes: <code>{&#34;:data&#34;: {SS: [&#34;aaa&#34;]}}</code>
                  </li>
                </ul>
                <p>
                  If the item already exists, then <code>aaa</code> will be
                  added to the string set, otherwise a new index entry will be
                  created under the provided key. However, to understand the
                  other steps, it is important to first understand how indexing
                  works.
                </p>
              </div>
              
              
              <p>
                  Assuming the two previous data sets have already been indexed
                  and now the following data set <code>ccc</code> needs to be
                  added:
                </p>
              <div>
                <pre><code>{
  submit(
    new: {
      firstName: &#34;John&#34;
      surName: &#34;Smith&#34;
      address: {
        street: &#34;Hofgraben&#34;
        houseNumber: &#34;3a&#34;
        city: &#34;M√ºnchen&#34;
      }
    }
  )
}</code></pre>
              </div>
              <div>
                
                <p>
                  When searching for possible matches, the index keys according
                  to <code>R1</code> and <code>R2</code> would be:
                </p>
                <ul>
                  <li><code>R1:john:smith:m√ºnchen</code></li>
                  <li><code>R2:m√ºnchen:hofgraben:JN:SM0</code></li>
                </ul>
                <p>
                  Searching with this data in the index table, results in
                  exactly one entry: <code>{&#34;aaa&#34;}</code> with currently only
                  one data set <code>aaa</code>. Because the used rule
                  <code>R1</code> does not require any further checks, the
                  matching is done here already. In that case the new data set
                  needs to be added to the existing entity.</p>
              </div>
              <div>
                <pre><code>{
  submit(
    new: {
      firstName: &#34;Johnn&#34;
      surName: &#34;Smith&#34;
      address: {
        street: &#34;Augustinerstr.&#34;
        houseNumber: &#34;11&#34;
        city: &#34;M√ºnchen&#34;
      }
    }
  )
}</code></pre>
              </div>
              <div>
                <p>the resulting index keys would be</p>
                <ul>
                  <li><code>R1:johnn:smith:m√ºnchen</code></li>
                  <li><code>R2:m√ºnchen:augustinerstr.:JN:SM0</code></li>
                </ul>
                <p>
                  resulting in a possible match for <code>R2</code> on
                  <code>{&#34;bbb:john:smith&#34;}</code>. Since everything required for
                  the additional Levenshtein check is now present, no further
                  data needs to be loaded. The Levenshtein distance between
                  <code>John</code> and <code>Johnn</code> is 1 and 0 for
                  <code>Smith</code> and <code>Smith</code>, therefore the data
                  set should also be added to the existing entity.</p>
                <ul>
                  <li><code>aaa:bbb:RELOCATION</code></li>
                  <li><code>aaa:ccc:R1</code></li>
                  <li><code>bbb:ddd:R2</code></li>
                </ul>
                
              </div>
              
              
              <p>Let&#39;s look at data set <code>eee</code></p>
              <div>
                <pre><code>{
  submit(
    new: {
      firstName: &#34;John&#34;
      surName: &#34;Smith&#34;
      address: {
        street: &#34;Hofgraben&#34;
        houseNumber: &#34;3&#34;
        city: &#34;M√ºnchen&#34;
      }
    }
  )
}</code></pre>
              </div>
              <div>
                <p>
                  which is similar, but not identical (see house number), to
                  <code>ccc</code> - a non-identical duplicate. This is quite
                  typical, e.g. a different order transaction, a different date
                  or anything else, that prevents one from simply ignoring the
                  data set.</p>
                <ul>
                  <li><code>aaa:eee:R1</code></li>
                  <li><code>ccc:eee:R1</code></li>
                  <li><code>ccc:eee:R2</code></li>
                </ul>
                <p>
                  This may look fine at first, but what if there would be only
                  four non-identical duplicates?
                </p>
              </div>
              <p>
              </p>
              <div>
                <p>
                  These are already twelve edges, or <code>n*(n-1)/2</code> for
                  each rule. Consider a frequent online shopper, with only 100
                  orders, this would be 9.900 edges!
                </p>
                
                <p>
                  To prevent the exponential growth of the edges, a new rule can
                  be added:
                </p>
                
                <p>
                  <code>D1</code>: matching if: first name, surname, city and
                  street are lowercase equal
                </p>
                
                <p>
                  The deduplication rule must cover all the matching relevant
                  fields from <code>R1</code> and <code>R2</code>. The
                  assumption here is, that all these fields do not change as
                  frequently as e.g. an order number among different data sets.
                </p>
                <p>
                  Finding duplicates using <code>D1</code> works in the same way
                  as finding matches: generate the index key, search with index
                  key and if needed filter the candidates when fuzzy matching is
                  required.
                </p>
                <p>
                  Data set <code>eee</code> would then be recognized as a
                  duplicate of <code>ccc</code>. It might simply be stored as a
                  single edge in the form <code>ccc:eee:D1</code> or slightly
                  optimized as in:
                </p>
              </div>
              
              <p>
                  The important part is, that duplicates do not create edges and
                  will not be indexed, because they are not providing new
                  relevant data for matching or searching.</p>
              
              
              <div>
                <p>
                  When adding a new data set, there are three potential
                  scenarios, that can occur:
                </p>
                
                <ul>
                  <li>
                    no matching data sets were found -&gt; a new entity must be
                    created
                  </li>
                  <li>
                    one or more matching data sets for the same entity were
                    found -&gt; the entity needs to be updated
                  </li>
                  <li>
                    matching data sets from multiple entities were found -&gt;
                    the entities must be merged into one entity
                  </li>
                </ul>
                
                <p>
                  For this use case, each entity is stored in a single AWS S3
                  object. Each object uses JSON lines (jsonl). The first line
                  contains a header and all other lines contain one data set
                  each.</p>
                
              </div>
              <div>
                <pre><code>{&#34;entityID&#34;:&#34;157009fd-65f3-4ec6-ac29-7f9f81cafa72&#34;,&#34;edges&#34;:[&#34;aaa:bbb:RELOCATION&#34;,&#34;aaa:ccc:R1&#34;,&#34;bbb:ddd:R2&#34;],&#34;duplicates&#34;:{&#34;ccc&#34;:[&#34;eee&#34;]}}
{&#34;id&#34;:&#34;aaa&#34;,&#34;firstName&#34;:&#34;John&#34;,&#34;surName&#34;:&#34;Smith&#34;,&#34;address&#34;:{&#34;street&#34;:&#34;Augustinerstr.&#34;,&#34;houseNumber&#34;:&#34;1&#34;,&#34;city&#34;:&#34;M√ºnchen&#34;}}
{&#34;id&#34;:&#34;bbb&#34;,&#34;firstName&#34;:&#34;John&#34;,&#34;surName&#34;:&#34;Smith&#34;,&#34;address&#34;:{&#34;street&#34;:&#34;Jungfernstieg&#34;,&#34;houseNumber&#34;:&#34;7&#34;,&#34;city&#34;:&#34;Hamburg&#34;}}
{&#34;id&#34;:&#34;ccc&#34;,&#34;firstName&#34;:&#34;John&#34;,&#34;surName&#34;:&#34;Smith&#34;,&#34;address&#34;:{&#34;street&#34;:&#34;Hofgraben&#34;,&#34;houseNumber&#34;:&#34;3a&#34;,&#34;city&#34;:&#34;M√ºnchen&#34;}}
{&#34;id&#34;:&#34;ddd&#34;,&#34;firstName&#34;:&#34;Johnn&#34;,&#34;surName&#34;:&#34;Smith&#34;,&#34;address&#34;:{&#34;street&#34;:&#34;Augustinerstr.&#34;,&#34;houseNumber&#34;:&#34;11&#34;,&#34;city&#34;:&#34;M√ºnchen&#34;}}
{&#34;id&#34;:&#34;eee&#34;,&#34;firstName&#34;:&#34;John&#34;,&#34;surName&#34;:&#34;Smith&#34;,&#34;address&#34;:{&#34;street&#34;:&#34;Hofgraben&#34;,&#34;houseNumber&#34;:&#34;3&#34;,&#34;city&#34;:&#34;M√ºnchen&#34;}}</code></pre>
              </div>
              <div>
                <p>
                  In addition to to this file, two AWS DynamoDB tables are
                  populated.
                </p>
                
              </div>
              <div>
                <table>
                  <thead>
                    <tr>
                      <th>
                        entity_id
                      </th>
                      <th>
                        s3_location
                      </th>
                      <th>...</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>
                        157009fd-65f3-4ec6-ac29-7f9f81cafa72
                      </td>
                      <td>
                        1570/157009fd-65f3-4ec6-ac29-7f9f81cafa72_10ff295f-8f4a-41d3-b35f-2d556b7cb2d1
                      </td>
                      <td>...</td>
                    </tr>
                  </tbody>
                </table>
              </div>
              <div>
                <p>
                  This table holds the path to the S3 location and other meta
                  data.</p>
                
              </div>
              <div>
                <table>
                  <thead>
                    <tr>
                      <th>
                        data_set_id
                      </th>
                      <th>
                        entity_id
                      </th>
                      <th>...</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>aaa</td>
                      <td>
                        157009fd-65f3-4ec6-ac29-7f9f81cafa72
                      </td>
                      <td>...</td>
                    </tr>
                    <tr>
                      <td>bbb</td>
                      <td>
                        157009fd-65f3-4ec6-ac29-7f9f81cafa72
                      </td>
                      <td>...</td>
                    </tr>
                    <tr>
                      <td>ccc</td>
                      <td>
                        157009fd-65f3-4ec6-ac29-7f9f81cafa72
                      </td>
                      <td>...</td>
                    </tr>
                    <tr>
                      <td>ddd</td>
                      <td>
                        157009fd-65f3-4ec6-ac29-7f9f81cafa72
                      </td>
                      <td>...</td>
                    </tr>
                    <tr>
                      <td>eee</td>
                      <td>
                        157009fd-65f3-4ec6-ac29-7f9f81cafa72
                      </td>
                      <td>...</td>
                    </tr>
                  </tbody>
                </table>
              </div>
              <p>
                  When adding a new data set for a new entity, then the S3
                  object will be created and the entity as well as the data set
                  table populated.</p>
              
              
              <div>
                <p>Searching works similar to finding matches or duplicates:</p>
                <ul>
                  <li>create index keys for the provided search</li>
                  <li>find possible candidates and filter them</li>
                  <li>
                    find the entries in the data set table for these candidates
                  </li>
                  <li>find the S3 location(s) from the entity table</li>
                  <li>load the S3 object(s)</li>
                  <li>
                    perform any kind of data selection or aggregation on the
                    entity data sets
                  </li>
                </ul>
                <p>
                  It‚Äôs worth mentioning the advantage of this approach: the
                  linear time complexity, which is already better than the
                  exponential complexity used by standard blocking techniques,
                  is, in reality, very close to a constant response time no
                  matter how complex the entities are. I.e. using our example
                  from the beginning, searching with A brings the result Z as
                  fast as it would return the result B. </p>
                
              </div>
              
              
              <p>
                  Some parts were not yet covered, but they are important for
                  the overall process.
                </p>
              <div>
                <h3>
                  <span><p>Parallelization and Locking</p> </span>
                </h3>
              </div>
              <div>
                <p>
                  Data may be added in parallel. Each entity must therefore be
                  locked to prevent conflicting writes on the same entity
                  (entity table or S3 object). This is done using an
                  <code>UpdateItem</code> request instead of an
                  <code>GetItem</code> request when loading the data from the
                  entity table:
                </p>
                <ul>
                  <li>
                    ConditionExpression:
                    <code>&#34;attribute_not_exists(#lockConstraint) OR
                      #lockConstraint=:lockConstraint&#34;</code>
                  </li>
                  <li>
                    UpdateExpression:
                    <code>&#34;SET #lockConstraint=:lockConstraint&#34;</code>
                  </li>
                  <li>ReturnValues: <code>&#34;ALL_NEW&#34;</code></li>
                </ul>
                
                <p>
                  However, if multiple entities are involved in an update
                  process, it must be ensured, that all locks have been
                  sucessfully acquired. If that is not the case, then all locks
                  must be released again to prevent dead-locks.
                </p>
                
              </div>
              <div>
                <h3>
                  <span><p>Failure Handling and Execution Plan</p> </span>
                </h3>
              </div>
              <p>
                  Any kind of error, including failing to acquire locks, should
                  simply result in letting the lambda fail (after a reasonable
                  amount/time of retries). Once the Lambda invocation has
                  failed, the Lambda service will, due to using Kinesis,
                  automatically retry to invoke it with the same data.</p>
              <div>
                <h3>
                  <span><p>Matching and Search Rules</p> </span>
                </h3>
              </div>
              <div>
                <p>
                  To keep things (relatively) simple in this description only
                  two rules were used for both matching and searching. However,
                  things start to get interesting when the rules for matching
                  and the rules for searching are different.</p>
                
              </div>
              
              
              <div>
                <p>
                  As a credit bureau, our job was to sell data, not build new
                  types of databases. Nevertheless, we were forced into creating
                  TiloDB because the alternatives for entity resolution provided
                  entirely unsatisfactory performance. (N.B. for an interesting
                  review of the state of entity resolution technology, see
                  <a href="https://blog.acolyer.org/2020/12/14/entity-resolution/" target="_blank">this blog post</a>
                  by Adrian Colyer, Venture Partner at Accel.)
                </p>
                
              </div>
              
              <p>
                  The traditional approach to entity matching would be to
                  precalculate all matches up-front. For small amounts of data
                  sets, this works quite well. Larger amounts of data sets
                  require some kind of blocking approach similar to the used
                  index key. However, even the slightest change would require a
                  complete recalculation of all matches.
                </p>
              
              <div>
                <p>
                  Using a recursive search in a relational database would also
                  be possible. But there is no optimization for non-identical
                  duplicates and jumping from one data set to the next to the
                  next to the next ... takes a very long time. Nothing real-time
                  about that!
                </p>
                
              </div>
              
              <p>
                  Graph databases are great - but not for this use case. They
                  are great at answering questions such as &#34;who are the friends
                  of my friends&#34; or &#34;how is A connected with B&#34;. But they fail
                  when asking the question &#34;what are all nodes and edges that
                  belong to a certain sub-graph&#34;. The reason is the same as with
                  relational databases: they need to jump from node to node.
                  Beside, the handling for the non-identitcal duplicates must
                  happen outside of a graph database.
                </p>
              
              
              <p>
                  If you have made it this far, then congratulations! Your
                  reward is a photo of the eponymous Tilo, who is currently aged
                  3 and lives in Brandenburg, Germany.¬†
                </p>
              <p>
              </p>
              
              <p>
                  Again, if you want to be notified when we release TiloDB as
                  OSS, please enter your email address below.¬†
                </p>
              
              
              <p>
                  <em>*less fun fact: we just discovered that there is in fact
                    already a database company (albeit a completely different
                    type of technology) with a name that differs from TiloDB by
                    only one letter(!), so I guess we will be changing our name
                    soon.
                  </em>
                </p>
              
            </div>
          </div>
        </div>
      </div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 11:48:59 +0000</pubDate>
      <source>https://tilodb.com/tilodb</source>
    </item>
    <item>
      <title>Culdesac Tempe: The first car-free neighborhood built from scratch in the US</title>
      <link>https://culdesac.com/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___culdesac_com_/image.jpg" /> 
<div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><nav></nav> <p><span>Coming to Tempe, Arizona in 2022.</span></p><section id="welcome" data-component="WelcomeSection" data-source-file="WelcomeSection.tsx"><div data-component="WelcomeSection" data-source-file="WelcomeSection.tsx"><p>The first car-free neighborhood built from scratch in the US!</p><div><p></p><p>Located at 2025 E Apache Blvd, Tempe, AZ 85281</p></div></div></section><div data-component="CardSection" data-source-file="CardSection.tsx"><div data-component="Card" data-source-file="CardSection.tsx"><p></p><p>Life at your front door</p><p>Stay home and skip the trip because we&#39;re bringing local restaurants, grocery, coworking spaces, and community to you.</p></div><div data-component="Card" data-source-file="CardSection.tsx"><p></p><p>Wide open spaces</p><p>Enjoy vibrant courtyards, wide tree-lined walkways, active plazas, and a beautiful central park.</p></div><div data-component="Card" data-source-file="CardSection.tsx"><p></p><p>Modern mobility</p><p> From e-bikes to e-scooters, light rail to rideshare, we make accessing Tempe&#39;s many transportation options easier than ever.</p></div></div><p></p><p></p><section id="courtyard" data-component="CourtyardSection" data-source-file="CourtyardSection.tsx"><div data-component="SlideDetails" data-source-file="SlideDetails.tsx"><h6 data-component="SlideDetails" data-source-file="SlideDetails.tsx">Your courtyard</h6><h2 data-component="SectionTitle" data-source-file="SectionTitle.tsx">The heart of the community<br/></h2><p>Culdesac Tempe is a car-free rental apartment community in Tempe, AZ. Units are situated around vibrant courtyards that become the outdoor living rooms and center of community for Culdesac.</p><ul><li>BBQ grills</li><li>Water features</li><li>Fire pits</li><li>Hammocks</li><li>Desert landscaping</li></ul></div></section><p></p><p></p><section id="your-life" data-component="YourLifeSection" data-source-file="YourLifeSection.tsx"><div id="container" data-component="YourLifeSection" data-source-file="YourLifeSection.tsx"><h6 data-component="YourLifeSection" data-source-file="YourLifeSection.tsx">Your Life</h6><h2 data-component="SectionTitle" data-source-file="SectionTitle.tsx">Living at Culdesac Tempe<br/></h2><p>Culdesac Tempe means life at your front door. Removing parking creates ample open space for a large dog park and pool. Our¬†<a href="https://culdesac.com/blog/post/bookable-spaces-and-familiar-faces" rel="noopener noreferrer" target="_blank">&#34;Extend Your Home On-Demand&#34;</a>¬†program allows you to expand and contract your home as you need to. Book a Guest Suite or day in the Makerspace through the Culdesac app and we&#39;ll handle the rest.</p></div></section><p></p><p></p><section id="your-home" data-component="YourHomeSection" data-source-file="YourHomeSection.tsx"><div data-component="SlideDetails" data-source-file="SlideDetails.tsx"><h6 data-component="SlideDetails" data-source-file="SlideDetails.tsx">Your home</h6><h2 data-component="SectionTitle" data-source-file="SectionTitle.tsx">Relax in comfort<br/></h2><p>Your home at Culdesac Tempe is a desert retreat, with ample natural light and luxury finishes. Studios start at $1,090/mo, and 1-bedrooms start at $1,250/mo. All units include:</p><ul><li>Private outdoor entrance</li><li>In-unit washer / dryer</li><li>Granite countertops &amp; kitchen island</li><li>Luxury plank hardwood flooring</li><li>Spacious walk-in closets</li><li>Energy Star Whirlpool appliances</li></ul></div></section><p></p><p></p><section id="shops-and-restaurants" data-component="ShopsSection" data-source-file="ShopsSection.tsx"><div id="container" data-component="ShopsSection" data-source-file="ShopsSection.tsx"><h6 data-component="ShopsSection" data-source-file="ShopsSection.tsx">Shops and Restaurants</h6><h2 data-component="SectionTitle" data-source-file="SectionTitle.tsx">Live in a 5-minute city<br/></h2><p>At Culdesac Tempe, you&#39;re always just 5 minutes away from a diverse range of high-quality retailers: Firecreek Coffee Co, Cocina Chiwas, and Street Corner Urban Market, to name a few.<!-- --> </p><p>Our retailers are award-winners, community leaders, and visionaries. Read more about them<!-- --> <a href="https://culdesac.com/blog/post/meet-our-retailers" target="__blank">here</a>.<!-- --> </p></div></section><p></p><p></p><section id="transportation" data-component="TransportationSection" data-source-file="TransportationSection.tsx"><div data-component="SlideDetails" data-source-file="SlideDetails.tsx"><h6 data-component="SlideDetails" data-source-file="SlideDetails.tsx">Transportation and mobility</h6><h2 data-component="SectionTitle" data-source-file="SectionTitle.tsx">How you move defines how you live<br/></h2><p>Culdesac Tempe is designed to make car-free living seamless. From ordering takeout for a night in, to jumping on a scooter just outside your door, we&#39;re bringing the best of mobility and delivery services so that zero private cars means zero hassle.</p><ul><li>Ample bike parking</li><li>On-site light rail</li><li>Rideshare</li><li>Scooters</li><li>On-site car share</li></ul></div></section><p></p><p></p><section id="waitlist" data-component="WaitlistSection" data-source-file="WaitlistSection.tsx"><div><p></p></div><div><h2 data-component="SectionTitle" data-source-file="SectionTitle.tsx">Join our waitlist today!<br/></h2><p>Claim your spot in the first car-free neighborhood built from scratch with a fully-refundable $100 reservation fee.</p><p><a href="https://culdesac.com/joinus" rel="noreferrer noopener" target="_blank">Want to live here?<span> (opens in a new window)</span></a></p></div><div><p></p></div></section><section id="press" data-component="PressSection" data-source-file="PressSection.tsx"><article data-component="PressCard" data-source-file="PressSection.tsx"><div data-component="PressCard" data-source-file="PressSection.tsx"><p></p><p></p><p>The Capital of Sprawl Gets a Radically Car-Free Neighborhood</p><h6>By Connor Dougherty</h6></div></article><article data-component="PressCard" data-source-file="PressSection.tsx"><div data-component="PressCard" data-source-file="PressSection.tsx"><p></p><p></p><p>New Arizona Development Bans Residents From Bringing Cars</p><h6>By Laura Kusisto</h6></div></article><article data-component="PressCard" data-source-file="PressSection.tsx"><div data-component="PressCard" data-source-file="PressSection.tsx"><p></p><p></p><p>Introducing Culdesac: Building car-free neighborhoods from scratch</p><h6>By Ryan Johnson and Jeff Berens</h6></div></article></section><section data-component="PropertyOwnerSection" data-source-file="PropertyOwnerSection.tsx"><p data-component="PropertyOwnerSection" data-source-file="PropertyOwnerSection.tsx">Interested in helping build the next car-free city? Email us at<!-- --> <a href="mailto:nextcity@culdesac.com" data-component="PropertyOwnerSection" data-source-file="PropertyOwnerSection.tsx">nextcity@culdesac.com</a>.</p></section><section id="contact-form" data-component="ContactForm" data-source-file="ContactForm.tsx"></section></div></div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 20:03:27 +0000</pubDate>
      <source>https://culdesac.com/</source>
    </item>
    <item>
      <title>A dubious writing style emerging in science</title>
      <link>https://arxiv.org/abs/2107.06751</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___arxiv_org_abs_2107_06751/image.jpg" /> 
<div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2107.06751">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Probabilistic text generators have been used to produce fake scientific
papers for more than a decade. Such nonsensical papers are easily detected by
both human and machine. Now more complex AI-powered generation techniques
produce texts indistinguishable from that of humans and the generation of
scientific texts from a few keywords has been documented. Our study introduces
the concept of tortured phrases: unexpected weird phrases in lieu of
established ones, such as &#39;counterfeit consciousness&#39; instead of &#39;artificial
intelligence.&#39; We combed the literature for tortured phrases and study one
reputable journal where these concentrated en masse. Hypothesising the use of
advanced language models we ran a detector on the abstracts of recent articles
of this journal and on several control sets. The pairwise comparisons reveal a
concentration of abstracts flagged as &#39;synthetic&#39; in the journal. We also
highlight irregularities in its operation, such as abrupt changes in editorial
timelines. We substantiate our call for investigation by analysing several
individual dubious articles, stressing questionable features: tortured writing
style, citation of non-existent literature, and unacknowledged image reuse.
Surprisingly, some websites offer to rewrite texts for free, generating
gobbledegook full of tortured phrases. We believe some authors used rewritten
texts to pad their manuscripts. We wish to raise the awareness on publications
containing such questionable AI-generated or rewritten texts that passed (poor)
peer review. Deception with synthetic texts threatens the integrity of the
scientific literature.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Guillaume Cabanac [<a href="https://arxiv.org/show-email/5ef25b51/2107.06751">view email</a>]
      </p></div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 04:19:18 +0000</pubDate>
      <source>https://arxiv.org/abs/2107.06751</source>
    </item>
    <item>
      <title>OpenAI Codex</title>
      <link>https://openai.com/blog/openai-codex/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___openai_com_blog_openai-codex_/image.jpg" /> 
<div id="readability-page-1" class="page"><article id="post-openai-codex">
  

  <section>
  <div>
    <section>
      
            
      
      <!--kg-card-begin: markdown--><p>We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today. Codex is the model that powers <a href="https://copilot.github.com/">GitHub Copilot</a>, which we built and launched in partnership with GitHub a month ago. Proficient in more than a dozen programming languages, Codex can now interpret simple commands in natural language and execute them on the user‚Äôs behalf‚Äîmaking it possible to build a natural language interface to existing applications. We are now inviting businesses and developers to build on top of OpenAI Codex through our API.</p>

<section>
<a href="https://challenge.openai.com">Enter the Codex Challenge (Aug 12, 10am PT)</a>
<hr/>
<a href="https://youtu.be/SGUCcjHTmGY">Rewatch Live Demo</a>
<hr/>
<a href="https://arxiv.org/abs/2107.03374">Read Paper</a>
</section>

<p>OpenAI Codex is a descendant of GPT-3; its training data contains both natural language and billions of lines of source code from publicly available sources, including code in public GitHub repositories. OpenAI Codex is most capable in Python, but it is also proficient in over a dozen languages including JavaScript, Go, Perl, PHP, Ruby, Swift and TypeScript, and even Shell. It has a memory of 14KB for Python code, compared to GPT-3 which has only 4KB‚Äîso it can take into account over 3x as much contextual information while performing any task.</p>
<p>GPT-3‚Äôs main skill is generating natural language in response to a natural language prompt, meaning the only way it affects the world is through the mind of the reader. OpenAI Codex has much of the natural language understanding of GPT-3, but it produces working code‚Äîmeaning you can issue commands in English to any piece of software with an API. OpenAI Codex empowers computers to better understand people‚Äôs intent, which can empower everyone to do more with computers.</p>
<p>Once a programmer knows what to build, the act of writing code can be thought of as (1) breaking a problem down into simpler problems, and (2) mapping those simple problems to existing code (libraries, APIs, or functions) that already exist. The latter activity is probably the least fun part of programming (and the highest barrier to entry), and it‚Äôs where OpenAI Codex excels most.</p>
<p>OpenAI Codex is a general-purpose programming model, meaning that it can be applied to essentially any programming task (though results may vary). We‚Äôve successfully used it for transpilation, explaining code, and refactoring code. But we know we‚Äôve only scratched the surface of what can be done.</p>
<p>We‚Äôre now making OpenAI Codex available in private beta via our API, and we are aiming to scale up as quickly as we can safely. During the initial period, OpenAI Codex will be offered for free. OpenAI will continue building on the safety groundwork we laid with GPT-3‚Äîreviewing applications and incrementally scaling them up while working closely with developers to understand the effect of our technologies in the world.</p>


</section></div>





<!--kg-card-end: markdown-->
    </section>
  

  





</article></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 17:33:50 +0000</pubDate>
      <source>https://openai.com/blog/openai-codex/</source>
    </item>
    <item>
      <title>Sony&#39;s new curved image sensors could shake up the whole camera industry</title>
      <link>https://www.digitalcameraworld.com/news/sonys-new-curved-image-sensors-could-shake-up-the-whole-camera-industry</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___www_digitalcameraworld_com_news_sonys-new-curved-image-sensors-could-shake-up-the-whole-camera-industry/image.jpg" /> 
<div id="readability-page-1" class="page"><article data-id="ne8isCMAFrZLCjaMZHDHnT">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li><a href="https://www.digitalcameraworld.com/">Home</a></li>
<li><a href="https://www.digitalcameraworld.com/news">News</a></li>
</ol>
</nav>


</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<div>
<div>
<picture><source type="image/webp" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-1024-80.jpg.webp 1024w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f.jpg"/><source type="image/jpeg" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f-1024-80.jpg 1024w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f.jpg"/></picture>
</div>
</div>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/inkSZsLvHkxvHa9aBN3t5f.jpg"/>
<meta itemprop="height" content="600"/>
<meta itemprop="width" content="338"/>
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Sony)</span>
</figcaption>
</div>

<div id="article-body">
<p>It‚Äôs happened to us all. You spot something big, beautiful and visually impressive. It might be a building, a landscape or a giant piece of street art. Then you go to photograph it, but suddenly one thing becomes shockingly clear: however expensive your camera is, it can never quite compete with the human eye.¬†</p><p>Shaped by millions of years of evolution, our eyes are quite frankly incredible. And the history of camera development has essentially been all about trying to mimic that level of perfection.¬†</p><p><strong>‚Ä¢ Read more: </strong><a href="https://www.digitalcameraworld.com/buying-guides/best-360-cameras" target="_blank"><strong>Best 360 cameras</strong></a></p><p>You can see it in the emergence of stereoscopic photography, for example, or the more recent development of 360-degree VR. There is, however, another way that manufacturers are trying to replicate the human eye, which doesn‚Äôt get as much press but promises to be quite revolutionary: curved sensors.¬†</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf-970-80.jpg.webp 970w" data-original-mos="https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf.jpg"/><source type="image/jpeg" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf-970-80.jpg 970w" data-original-mos="https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/RcpKL3UW9krpyd84jCvYCf.jpg"/></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Sony)</span></figcaption></figure><p>Rather than follow the curve of our eyes, the sensors in conventional digital cameras are flat. This results in an unnatural curvature in the image, and so the accompanying lenses have to be made in a way that corrects this distortion. This makes camera optics larger and heavier than they otherwise need to be.¬†</p><p>Swapping a flat sensor for a curved one, consequently, should allow for lenses with a shorter and smaller diameter, with greater aperture and reduced light fall-off at the edge of the photo.¬†</p><p>We say ‚Äòshould‚Äô because while <a href="https://www.digitalcameraworld.com/news/is-sonys-medium-format-camera-with-a-curved-sensor-almost-ready" target="_blank">Sony has been developing this tech</a> for some time, as have other manufacturers <a href="https://www.digitalcameraworld.com/news/canon-has-just-patented-its-first-lenses-for-a-curved-sensor" target="_blank">such as Canon</a>, neither is bringing new cameras based on curved sensors to market just yet.¬†</p><p>However, the big news is that Sony has just filed a new patent for the production of a curved sensor ‚Äì one that looks like it has smartphone users in mind.¬†</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf-970-80.jpg.webp 970w" data-original-mos="https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf.jpg"/><source type="image/jpeg" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf-970-80.jpg 970w" data-original-mos="https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/8XrEfxsGFGqx8mHkxkdzLf.jpg"/></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Sony)</span></figcaption></figure><p>You can see the patent in full <a href="https://www.j-platpat.inpit.go.jp/c1800/PU/JP-2021-108427/1D0D737B2A79C124B9DF0B3F0B72667F4CEDCEDB6369633E895CF467339C5D2D/11/ja" target="_blank" data-url="https://www.j-platpat.inpit.go.jp/c1800/PU/JP-2021-108427/1D0D737B2A79C124B9DF0B3F0B72667F4CEDCEDB6369633E895CF467339C5D2D/11/ja"><u>here</u></a>, although you‚Äôll need a good knowledge of Japanese (not to mention camera technology) to understand it. Suffice to say that following its 2020 patent in this area, Sony is clearly serious about developing this new tech and getting it into the hands of consumers, before rivals can steal a march on it.¬†</p><p>And Sony&#39;s interest is far from academic; there is a real commercial need at play here. Smartphones are increasingly at the cutting edge of photography tech and, with multi-lens cameras and 108MP sensors becoming increasingly common, brands are desperate for new ways to stand out from the crowd.¬†</p><p>Curved sensors will potentially enable makers of both digital cameras and smartphones to leave their competitors in the dust, so there&#39;s an awful lot to play for here.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf-970-80.jpg.webp 970w" data-original-mos="https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf.jpg"/><source type="image/jpeg" alt="Diagram showing curved lens technology" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf-970-80.jpg 970w" data-original-mos="https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/yKchNsgdCUo4oMkW4NytUf.jpg"/></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Sony)</span></figcaption></figure><p>We&#39;ve been saying for some time that curved sensors represent the next big leap forward in imaging technology, and this new patent from Sony makes us even surer of that. We imagine that rival manufacturers are quaking in their boots right now ‚Äì unless, that is, they&#39;ve got their own curved sensors in the works.¬†</p><p>Either way, we&#39;ll bring you all the news in the development of this game-changing tech the moment we learn of it, so keep watching.</p><p><strong>Read more:¬†</strong></p><p><a href="https://www.digitalcameraworld.com/buying-guides/best-camera-phone" target="_blank">Best camera phones</a></p>

</div>
<div>
<div>
<picture><source type="image/webp" alt="Tom May" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="99vw" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/9gGAGRPzJeEG2f5kxRw4SM-300-80.jpg.webp 300w" data-original-mos="https://cdn.mos.cms.futurecdn.net/9gGAGRPzJeEG2f5kxRw4SM.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/9gGAGRPzJeEG2f5kxRw4SM.jpg" data-pin-nopin="true"/><source type="image/jpeg" alt="Tom May" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" sizes="99vw" data-normal="https://vanilla.futurecdn.net/digitalcameraworld/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/9gGAGRPzJeEG2f5kxRw4SM-300-80.jpg 300w" data-original-mos="https://cdn.mos.cms.futurecdn.net/9gGAGRPzJeEG2f5kxRw4SM.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/9gGAGRPzJeEG2f5kxRw4SM.jpg" data-pin-nopin="true"/></picture>
</div>

<p><span><p>Tom May is a freelance writer and editor specializing in art, photography, design and travel. He has been editor of Professional Photography magazine, associate editor at <a href="https://www.creativebloq.com" target="_blank">Creative Bloq</a>, and deputy editor at net magazine. He has also worked for a wide range of mainstream titles including The Sun, Radio Times, NME, T3, Heat, Company and Bella.</p></span>
</p></div>

<!-- No tag-links -->

</section>









<!-- No tag-links -->

</article></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 02:49:21 +0000</pubDate>
      <source>https://www.digitalcameraworld.com/news/sonys-new-curved-image-sensors-could-shake-up-the-whole-camera-industry</source>
    </item>
    <item>
      <title>The emergence of heat and humidity too severe for human tolerance</title>
      <link>https://advances.sciencemag.org/content/6/19/eaaw1838</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___advances_sciencemag_org_content_6_19_eaaw1838/image.jpg" /> 
<div id="readability-page-1" class="page"><div><div id="abstract-2"><h2>Abstract</h2><p id="p-3">Humans‚Äô ability to efficiently shed heat has enabled us to range over every continent, but a wet-bulb temperature (TW) of 35¬∞C marks our upper physiological limit, and much lower values have serious health and productivity impacts. Climate models project the first 35¬∞C TW occurrences by the mid-21st century. However, a comprehensive evaluation of weather station data shows that some coastal subtropical locations have already reported a TW of 35¬∞C and that extreme humid heat overall has more than doubled in frequency since 1979. Recent exceedances of 35¬∞C in global maximum sea surface temperature provide further support for the validity of these dangerously high TW values. We find the most extreme humid heat is highly localized in both space and time and is correspondingly substantially underestimated in reanalysis products. Our findings thus underscore the serious challenge posed by humid heat that is more intense than previously reported and increasingly severe.</p></div><div id="sec-1"><h2>INTRODUCTION</h2><p id="p-4">Humans‚Äô bipedal locomotion, naked skin, and sweat glands are constituents of a sophisticated cooling system (<a id="xref-ref-1-1" href="#ref-1"><em>1</em></a>). Despite these thermoregulatory adaptations, extreme heat remains one of the most dangerous natural hazards (<a id="xref-ref-2-1" href="#ref-2"><em>2</em></a>), with tens of thousands of fatalities in the deadliest events so far this century (<a id="xref-ref-3-1" href="#ref-3"><em>3</em></a>, <a id="xref-ref-4-1" href="#ref-4"><em>4</em></a>). The additive impacts of heat and humidity extend beyond direct health outcomes to include reduced individual performance across a range of activities, as well as large-scale economic impacts (<a id="xref-ref-5-1" href="#ref-5"><em>5</em></a>‚Äì<a id="xref-ref-7-1" href="#ref-7"><em>7</em></a>). Heat-humidity effects have prompted decades of study in military, athletic, and occupational contexts (<a id="xref-ref-8-1" href="#ref-8"><em>8</em></a>, <a id="xref-ref-9-1" href="#ref-9"><em>9</em></a>). However, consideration of wet-bulb temperature (TW) from the perspectives of climatology and meteorology began more recently (<a id="xref-ref-10-1" href="#ref-10"><em>10</em></a>, <a id="xref-ref-11-1" href="#ref-11"><em>11</em></a>).</p><p id="p-5">While some heat-humidity impacts can be avoided through acclimation and behavioral adaptation (<a id="xref-ref-12-1" href="#ref-12"><em>12</em></a>), there exists an upper limit for survivability under sustained exposure, even with idealized conditions of perfect health, total inactivity, full shade, absence of clothing, and unlimited drinking water (<a id="xref-ref-9-2" href="#ref-9"><em>9</em></a>, <a id="xref-ref-10-2" href="#ref-10"><em>10</em></a>). A normal internal human body temperature of 36.8¬∞ ¬± 0.5¬∞C requires skin temperatures of around 35¬∞C to maintain a gradient directing heat outward from the core (<a id="xref-ref-10-3" href="#ref-10"><em>10</em></a>, <a id="xref-ref-13-1" href="#ref-13"><em>13</em></a>). Once the air (dry-bulb) temperature (T) rises above this threshold, metabolic heat can only be shed via sweat-based latent cooling, and at TW exceeding about 35¬∞C, this cooling mechanism loses its effectiveness altogether. Because the ideal physiological and behavioral assumptions are almost never met, severe mortality and morbidity impacts typically occur at much lower values‚Äîfor example, regions affected by the deadly 2003 European and 2010 Russian heat waves experienced TW values no greater than 28¬∞C (fig. S1). In the literature to date, there have been no observational reports of TW exceeding 35¬∞C and few reports exceeding 33¬∞C (<a id="xref-ref-9-3" href="#ref-9"><em>9</em></a>, <a id="xref-ref-11-2" href="#ref-11"><em>11</em></a>, <a id="xref-ref-14-1" href="#ref-14"><em>14</em></a>, <a id="xref-ref-15-1" href="#ref-15"><em>15</em></a>). The awareness of a physiological limit has prompted modeling studies to ask how soon it may be crossed. Results suggest that, under the business-as-usual RCP8.5 emissions scenario, TW could regularly exceed 35¬∞C in parts of South Asia and the Middle East by the third quarter of the 21st century (<a id="xref-ref-14-2" href="#ref-14"><em>14</em></a>‚Äì<a id="xref-ref-16-1" href="#ref-16"><em>16</em></a>).</p><p id="p-6">Here, we use quality-assured station observations from HadISD (<a id="xref-ref-17-1" href="#ref-17"><em>17</em></a>, <a id="xref-ref-18-1" href="#ref-18"><em>18</em></a>) and high-resolution reanalysis data from ERA-Interim (<a id="xref-ref-19-1" href="#ref-19"><em>19</em></a>, <a id="xref-ref-20-1" href="#ref-20"><em>20</em></a>), verified against radiosondes and marine observations (see the Supplementary Materials) (<a id="xref-ref-21-1" href="#ref-21"><em>21</em></a>, <a id="xref-ref-22-1" href="#ref-22"><em>22</em></a>), to compute TW baseline values, geographic patterns, and recent trends. Uncertainties in TW from station data due to instrumentation and procedures are on the order of 0.5¬∞ to 1.0¬∞C in all regions considered, an important consideration for proper interpretation of the results. Our approach of using TW and sea surface temperature (SST) observations as guidance for future TW projections offers a different line of evidence from previous research that used coupled or regional models without explicitly including historical station data.</p></div><div id="sec-2"><h2>RESULTS</h2><p id="p-7">Our survey of the climate record from station data reveals many global TW exceedances of 31¬∞ and 33¬∞C and two stations that have already reported multiple daily maximum TW values above 35¬∞C. These conditions, nearing or beyond prolonged human physiological tolerance, have mostly occurred only for 1- to 2-hours‚Äô duration (fig. S2). They are concentrated in South Asia, the coastal Middle East, and coastal southwest North America, in close proximity to extraordinarily high SSTs and intense continental heat that together favor the occurrence of extreme humid heat (<a id="xref-ref-2-2" href="#ref-2"><em>2</em></a>, <a id="xref-ref-14-3" href="#ref-14"><em>14</em></a>). Along coastlines, the marine influence is manifest via anomalous onshore low-level winds during midday and afternoon hours, and these wind shifts can cause rapid dew point temperature (Td) increases in arid and semiarid coastal areas (figs. S3 to S9). Regionally coherent observational evidence supports these intense values: Of the stations along the Persian Gulf coastline with at least 50% data availability over 1979 to 2017, all have a historical 99.9th percentile of TW (the value exceeded roughly 14 times in 39 years) above 31¬∞C (<a id="xref-fig-1-1" href="#F1">Fig. 1</a>; see fig. S1 for the all-time maximum). In the ERA-Interim reanalysis, the highest values are similarly located over the Persian Gulf and immediately adjacent land areas, as well as parts of the Indus River Valley (fig. S10). The spatiotemporal averaging inherent in reanalysis products causes ERA-Interim to be unable to represent the short durations and small areas of critical heat stress, causing its extreme TW values to be substantially lower than those of weather stations across the tropics and subtropics (fig. S11). In the Persian Gulf and adjacent Gulf of Oman, these differences are consistently in the range of ‚àí2¬∞ to ‚àí4¬∞C (fig. S12). Larger bias but similar consistency is present along the eastern shore of the Red Sea, presenting a basis for future studies examining the reasons for this behavior, as well as further comparisons between station and reanalysis data.</p><figure id="F1">
  <div>
    <p><a href="https://advances.sciencemag.org/content/advances/6/19/eaaw1838/F1.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Observed global extreme humid heat. Color symbols represent the 99.9th percentile of observed daily maximum TW for 1979‚Äì2017 for HadISD stations with at least 50% data availability over this period. Marker size is inversely proportional to station density." rel="gallery-fragment-images-110081336" data-figure-caption="&lt;div class=&#34;highwire-markup&#34;&gt;&lt;span class=&#34;fig-label&#34;&gt;Fig. 1&lt;/span&gt; &lt;span class=&#34;caption-title&#34;&gt;Observed global extreme humid heat.&lt;/span&gt;&lt;p id=&#34;p-8&#34; class=&#34;first-child&#34;&gt;Color symbols represent the 99.9th percentile of observed daily maximum TW for 1979‚Äì2017 for HadISD stations with at least 50% data availability over this period. Marker size is inversely proportional to station density.&lt;/p&gt;&lt;div class=&#34;sb-div caption-clear&#34;/&gt;&lt;/div&gt;" data-icon-position="" data-hide-link-title="0"><span></span></a></p>        
      </div>
    <figcaption id="F1-caption">
    <span>Fig. 1</span> <span>Observed global extreme humid heat.</span><p id="p-8">Color symbols represent the 99.9th percentile of observed daily maximum TW for 1979‚Äì2017 for HadISD stations with at least 50% data availability over this period. Marker size is inversely proportional to station density.</p>  </figcaption>
  </figure><p id="p-9">Other &gt;31¬∞C hotspots in the weather station record emerge through surveying the globally highest 99.9th TW percentiles: eastern coastal India, Pakistan and northwestern India, and the shores of the Red Sea, Gulf of California, and southern Gulf of Mexico (<a id="xref-fig-1-2" href="#F1">Fig. 1</a>). All are situated in the subtropics, along coastlines (typically of a semienclosed gulf or bay of shallow depth, limiting ocean circulation and promoting high SSTs), and in proximity to sources of continental heat, which together with the maritime air comprise the necessary combination for the most exceptional TW (<a id="xref-ref-11-3" href="#ref-11"><em>11</em></a>). That subtropical coastlines are hotspots for heat stress has been noted previously (<a id="xref-ref-23-1" href="#ref-23"><em>23</em></a>, <a id="xref-ref-24-1" href="#ref-24"><em>24</em></a>); our analysis makes clear the broad geographic scope but also the large intraregional variations (<a id="xref-fig-1-3" href="#F1">Fig. 1</a>). Western South Asia stands as the main exception to this coastline rule, likely due to the efficient inland transport of humid air by the summer monsoon together with large-scale irrigation (<a id="xref-ref-15-2" href="#ref-15"><em>15</em></a>, <a id="xref-ref-25-1" href="#ref-25"><em>25</em></a>). Tropical forest and oceanic areas generally experience TW no higher than 31¬∞ to 32¬∞C, perhaps a consequence of the high evapotranspiration potential and cloud cover, along with the greater instability of the tropical atmosphere. However, more research is needed on the thermodynamic mechanisms that prevent these areas from attaining higher values.</p><p id="p-10">Steep and statistically significant upward trends in extreme TW frequency (exceedances of 27¬∞, 29¬∞, 31¬∞, and 33¬∞C) and magnitude are present across weather stations globally (<a id="xref-fig-2-1" href="#F2">Fig. 2</a>). Each frequency trend represents more than a doubling of occurrences of the corresponding threshold between 1979 and 2017. Trends in ERA-Interim are strongly correlated with those of HadISD but are smaller for the highest values (<a id="xref-fig-2-2" href="#F2">Fig. 2</a>), consistent with ERA-Interim‚Äôs underestimation of extreme TW that is largest for the most extreme conditions (fig. S11). We also find a sharp peak in the number of global TW = 27¬∞C and TW = 29¬∞C extremes during the strong El Ni√±o events of 1998 and 2016. Linearly detrending this global-TW-extremes time series reveals that the El Ni√±o‚ÄìSouthern Oscillation (ENSO) correlation is largest for TW values that are high but not unusual (~27¬∞ to 28¬∞C) across the tropics and subtropics (fig. S13). Further work is necessary to test to what extent this relationship may be related to the effect of ENSO on hydrological extremes at the global scale, on tropospheric-mean temperatures, or on SSTs in particular basins, and the implications of these effects for TW predictability (<a id="xref-ref-26-1" href="#ref-26"><em>26</em></a>, <a id="xref-ref-27-1" href="#ref-27"><em>27</em></a>). Overall, TW extremes in the tropics largely correspond on an interannual basis to mean TW (fig. S14), indicating that climate forcings and modes of internal variability resulting in mean temperature shifts can be expected to modulate tropical TW extremes. This is the case in the subtropics as well, although to a somewhat lesser extent.</p><figure id="F2">
  <div>
    <p><a href="https://advances.sciencemag.org/content/advances/6/19/eaaw1838/F2.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Global trends in extreme humid heat. (A to D) Annual global counts of TW exceedances above the thresholds labeled on the respective panel, from HadISD (black, right axes, with units of station days) and ERA-Interim grid points (gray, left axes, with units of grid-point days). We consider only HadISD stations with at least 50% data availability over 1979‚Äì2017. Correlations between the series are annotated in the top left of each panel, and dotted lines highlight linear trends. (E) Annual global maximum TW in ERA-Interim. (F) The line plot shows global mean annual temperature anomalies (relative to 1850‚Äì1879) according to HadCRUT4 (40), which we use to approximate each year‚Äôs observed warming since preindustrial; circles indicate HadISD station occurrences of TW exceeding 35¬∞C, with radius linearly proportional to global annual count, measured in station days." rel="gallery-fragment-images-110081336" data-figure-caption="&lt;div class=&#34;highwire-markup&#34;&gt;&lt;span class=&#34;fig-label&#34;&gt;Fig. 2&lt;/span&gt; &lt;span class=&#34;caption-title&#34;&gt;Global trends in extreme humid heat.&lt;/span&gt;&lt;p id=&#34;p-11&#34; class=&#34;first-child&#34;&gt;(&lt;strong&gt;A&lt;/strong&gt; to &lt;strong&gt;D&lt;/strong&gt;) Annual global counts of TW exceedances above the thresholds labeled on the respective panel, from HadISD (black, right axes, with units of station days) and ERA-Interim grid points (gray, left axes, with units of grid-point days). We consider only HadISD stations with at least 50% data availability over 1979‚Äì2017. Correlations between the series are annotated in the top left of each panel, and dotted lines highlight linear trends. (&lt;strong&gt;E&lt;/strong&gt;) Annual global maximum TW in ERA-Interim. (&lt;strong&gt;F&lt;/strong&gt;) The line plot shows global mean annual temperature anomalies (relative to 1850‚Äì1879) according to HadCRUT4 (&lt;a id=&#34;xref-ref-40-1&#34; class=&#34;xref-bibr&#34; href=&#34;#ref-40&#34;&gt;&lt;em&gt;40&lt;/em&gt;&lt;/a&gt;), which we use to approximate each year‚Äôs observed warming since preindustrial; circles indicate HadISD station occurrences of TW exceeding 35¬∞C, with radius linearly proportional to global annual count, measured in station days.&lt;/p&gt;&lt;div class=&#34;sb-div caption-clear&#34;/&gt;&lt;/div&gt;" data-icon-position="" data-hide-link-title="0"><span></span></a></p>        
      </div>
    <figcaption id="F2-caption">
    <span>Fig. 2</span> <span>Global trends in extreme humid heat.</span><p id="p-11">(<strong>A</strong> to <strong>D</strong>) Annual global counts of TW exceedances above the thresholds labeled on the respective panel, from HadISD (black, right axes, with units of station days) and ERA-Interim grid points (gray, left axes, with units of grid-point days). We consider only HadISD stations with at least 50% data availability over 1979‚Äì2017. Correlations between the series are annotated in the top left of each panel, and dotted lines highlight linear trends. (<strong>E</strong>) Annual global maximum TW in ERA-Interim. (<strong>F</strong>) The line plot shows global mean annual temperature anomalies (relative to 1850‚Äì1879) according to HadCRUT4 (<a id="xref-ref-40-1" href="#ref-40"><em>40</em></a>), which we use to approximate each year‚Äôs observed warming since preindustrial; circles indicate HadISD station occurrences of TW exceeding 35¬∞C, with radius linearly proportional to global annual count, measured in station days.</p>  </figcaption>
  </figure><p id="p-12">We also observe modulation on a seasonal scale, by considering as an illustrative example the South Asian monsoon region. There, the timing of peak TW varies with the advance of the summer monsoon (<a id="xref-ref-15-3" href="#ref-15"><em>15</em></a>). Splitting South Asia into ‚Äúearly monsoon‚Äù and ‚Äúlate monsoon‚Äù subregions, we find that the number of TW extremes is largest around the time of the local climatological monsoon onset date (<a id="xref-fig-3-1" href="#F3">Fig. 3</a>). Although equivalent extreme values of TW are possible before, during, and after the monsoon rains in any given year, they are of a different character; especially in the northern and western parts of the subcontinent, they become continually moister and have lower dry-bulb temperatures as summer progresses. Across the globe, such temperature and humidity variations occur within a well-defined bivariate space (fig. S15). That these variations are systematically associated with the summer monsoon in South Asia emphasizes the important role of moisture, and of weather systems on synoptic to subseasonal time scales, in controlling extreme TW (<a id="xref-ref-15-4" href="#ref-15"><em>15</em></a>, <a id="xref-ref-28-1" href="#ref-28"><em>28</em></a>). Our findings underscore the diversity of conditions that can lead to extreme humid heat in the same location at different times, suggesting that impacts adaptation strategies may benefit from taking this recognition into account. Such intraseasonal variability in TW also matters for physiological acclimation, which requires several-day time scales to develop (<a id="xref-ref-29-1" href="#ref-29"><em>29</em></a>); TW character is especially relevant when considering effects on human systems that vary in their sensitivity to humidity and temperature‚Äîfor example, thermoregulation and energy demand for artificial cooling are strongly affected by TW, whereas the materials that make up the built environment are principally affected by temperature alone (<a id="xref-ref-13-2" href="#ref-13"><em>13</em></a>, <a id="xref-ref-30-1" href="#ref-30"><em>30</em></a>).</p><figure id="F3">
  <div>
    <p><a href="https://advances.sciencemag.org/content/advances/6/19/eaaw1838/F3.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Monsoon-modulated seasonality of extreme humid heat. (A) Early monsoon areas (light orange shading; " rel="gallery-fragment-images-110081336" data-figure-caption="&lt;div class=&#34;highwire-markup&#34;&gt;&lt;span class=&#34;fig-label&#34;&gt;Fig. 3&lt;/span&gt; &lt;span class=&#34;caption-title&#34;&gt;Monsoon-modulated seasonality of extreme humid heat.&lt;/span&gt;&lt;p id=&#34;p-13&#34; class=&#34;first-child&#34;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Early monsoon areas (light orange shading; &lt;June 15 average onset date) and late monsoon areas (green shading; ‚â•June 15 average onset date) in South Asia. (&lt;strong&gt;B&lt;/strong&gt;) (Solid line) Mean annual number of TW exceedances of 31¬∞C per station, by pentad, in the early monsoon areas. (Dashed line) Mean relative humidity associated with these exceedances. The division between the brown- and blue-shaded sections represents the station-weighted-average climatological monsoon onset date. (&lt;strong&gt;C&lt;/strong&gt;) Same as in (B), but for the late monsoon areas.&lt;/p&gt;&lt;div class=&#34;sb-div caption-clear&#34;/&gt;&lt;/div&gt;" data-icon-position="" data-hide-link-title="0"><span></span></a></p>        
      </div>
    <figcaption id="F3-caption">
    <span>Fig. 3</span> <span>Monsoon-modulated seasonality of extreme humid heat.</span><p id="p-13">(<strong>A</strong>) Early monsoon areas (light orange shading; &lt;June 15 average onset date) and late monsoon areas (green shading; ‚â•June 15 average onset date) in South Asia. (<strong>B</strong>) (Solid line) Mean annual number of TW exceedances of 31¬∞C per station, by pentad, in the early monsoon areas. (Dashed line) Mean relative humidity associated with these exceedances. The division between the brown- and blue-shaded sections represents the station-weighted-average climatological monsoon onset date. (<strong>C</strong>) Same as in (B), but for the late monsoon areas.</p>  </figcaption>
  </figure><p id="p-14">While our analysis of weather stations indicates that TW has already been reported as having exceeded 35¬∞C in limited areas for short periods, this has not yet occurred at the regional scale represented by reanalysis data, which is also the approximate scale of model projections of future TW extremes considered in previous studies (<a id="xref-ref-14-4" href="#ref-14"><em>14</em></a>, <a id="xref-ref-15-5" href="#ref-15"><em>15</em></a>). To increase the comparability of our station findings with these model projections, we implement a generalized extreme value (GEV) analysis to estimate the amount of global warming from the preindustrial period until TW will regularly exceed 35¬∞C at the global hottest ERA-Interim grid cells, currently all located in the Persian Gulf area (<a id="xref-fig-4-1" href="#F4">Fig. 4</a>). Complete details of this procedure are in Materials and Methods. In brief, we fit a nonstationary GEV model to the grid cells experiencing the highest TW values, with the GEV location parameter a function of the annual global-mean air-temperature anomaly. This enables us to quantify how much global warming is required for annual maximum TW ‚â• 35¬∞C to become at most a 1-in-30-year event at any grid cell. We conduct this analysis solely for grid cells where the nonstationary GEV model is a significantly (<em>P</em> &lt; 0.05) better fit to the annual maximum time series (1979‚Äì2017) than a stationary alternative. We then define the temperature of emergence (ToE) as the amount of global warming required until TW ‚â•35¬∞C is at most a 1-in-30-year event at the ERA-Interim spatiotemporal scale, such that the lowest ToE at any grid cell approximates the first occurrences of TW = 35¬∞C that are widespread and sustained enough to cause serious or fatal health impacts, as estimated from physiological studies (<a id="xref-ref-6-1" href="#ref-6"><em>6</em></a>, <a id="xref-ref-10-4" href="#ref-10"><em>10</em></a>, <a id="xref-ref-31-1" href="#ref-31"><em>31</em></a>).</p><figure id="F4">
  <div>
    <p><a href="https://advances.sciencemag.org/content/advances/6/19/eaaw1838/F4.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Projections of extreme humid heat exceeding the physiological survivability limit. (A) Shading shows the amount of global warming (since preindustrial) until TW = 35¬∞C is projected to become at least a 1-in-30-year event at each grid cell according to a nonstationary GEV model. In blank areas, more than 4¬∞C of warming is necessary. Black dots indicate ERA-Interim grid cells with a maximum TW (1979‚Äì2017) in the hottest 0.1% of grid cells worldwide. (B) Total area with TW of at least 35¬∞C, as a function of mean annual temperature change „ÄàT„Äâ from the preindustrial period. Red (green) vertical lines highlight the lowest „ÄàT„Äâ for which there are nonzero areas over land (sea)‚Äîthe respective ToE. (C) Bootstrap estimates of the ToE. See text for details of this definition and calculation." rel="gallery-fragment-images-110081336" data-figure-caption="&lt;div class=&#34;highwire-markup&#34;&gt;&lt;span class=&#34;fig-label&#34;&gt;Fig. 4&lt;/span&gt; &lt;span class=&#34;caption-title&#34;&gt;Projections of extreme humid heat exceeding the physiological survivability limit.&lt;/span&gt;&lt;p id=&#34;p-15&#34; class=&#34;first-child&#34;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Shading shows the amount of global warming (since preindustrial) until TW = 35¬∞C is projected to become at least a 1-in-30-year event at each grid cell according to a nonstationary GEV model. In blank areas, more than 4¬∞C of warming is necessary. Black dots indicate ERA-Interim grid cells with a maximum TW (1979‚Äì2017) in the hottest 0.1% of grid cells worldwide. (&lt;strong&gt;B&lt;/strong&gt;) Total area with TW of at least 35¬∞C, as a function of mean annual temperature change „Äà&lt;em&gt;T&lt;/em&gt;„Äâ from the preindustrial period. Red (green) vertical lines highlight the lowest „Äà&lt;em&gt;T&lt;/em&gt;„Äâ for which there are nonzero areas over land (sea)‚Äîthe respective ToE. (&lt;strong&gt;C&lt;/strong&gt;) Bootstrap estimates of the ToE. See text for details of this definition and calculation.&lt;/p&gt;&lt;div class=&#34;sb-div caption-clear&#34;/&gt;&lt;/div&gt;" data-icon-position="" data-hide-link-title="0"><span></span></a></p>        
      </div>
    <figcaption id="F4-caption">
    <span>Fig. 4</span> <span>Projections of extreme humid heat exceeding the physiological survivability limit.</span><p id="p-15">(<strong>A</strong>) Shading shows the amount of global warming (since preindustrial) until TW = 35¬∞C is projected to become at least a 1-in-30-year event at each grid cell according to a nonstationary GEV model. In blank areas, more than 4¬∞C of warming is necessary. Black dots indicate ERA-Interim grid cells with a maximum TW (1979‚Äì2017) in the hottest 0.1% of grid cells worldwide. (<strong>B</strong>) Total area with TW of at least 35¬∞C, as a function of mean annual temperature change „Äà<em>T</em>„Äâ from the preindustrial period. Red (green) vertical lines highlight the lowest „Äà<em>T</em>„Äâ for which there are nonzero areas over land (sea)‚Äîthe respective ToE. (<strong>C</strong>) Bootstrap estimates of the ToE. See text for details of this definition and calculation.</p>  </figcaption>
  </figure><p id="p-16">Our method yields a ToE of 1.3¬∞C over the waters of the Persian Gulf (90% confidence interval, 0.81¬∞ to 1.73¬∞C) and of 2.3¬∞C for nearby land grid cells (1.4¬∞ to 3.3¬∞C) (<a id="xref-fig-4-2" href="#F4">Fig. 4</a>). Adjusting these numbers for ERA-Interim‚Äôs robust Persian Gulf differences of approximately ‚àí3¬∞C for extreme TW (fig. S12) supports the conclusion from the station observations that recent warming has increased exceedances of TW = 35¬∞C, but that this threshold has most likely been achieved on occasion throughout the observational record (<a id="xref-fig-2-3" href="#F2">Fig. 2</a>). The strong marine influence on these values is also apparent in <a id="xref-fig-1-4" href="#F1">Fig. 1</a>.</p><p id="p-17">To further assess the physical realism of our GEV extrapolation, we additionally examine observed annual maximum (monthly mean) SSTs. An atmospheric boundary layer fully equilibrated with the ocean surface would be at saturation and have the same temperature as the underlying SSTs, meaning that, in principle, 35¬∞C is the lowest SST that could sustain the critical 35¬∞C value of TW in the air above. In reality, equilibrium will not be achieved if air-mass residence times over extreme SSTs are too short, which is more likely if the vertical profile of the atmosphere allows strong surface heating to trigger deep convection (<a id="xref-ref-10-5" href="#ref-10"><em>10</em></a>). Current large-scale SSTs and their trends may therefore provide some guidance as to whether our projections of extreme TW are physically plausible. It is in this context that we note monthly mean SSTs exceeding the 35¬∞C threshold for the first time, reaching 35.2¬∞C in the Persian Gulf in 2017 (<a id="xref-fig-5-1" href="#F5">Fig. 5</a>). As a result, our GEV projection of large-scale maritime TW ‚â• 35¬∞C, for less than 1.5¬∞C warming, appears physically consistent with SST observations at the same scale. Analogous corroboration of station-based TW ‚â• 35¬∞C events is provided by point scale, hourly SST and TW across the Persian Gulf from an independent database of marine observations (see the Supplementary Materials) (<a id="xref-ref-21-2" href="#ref-21"><em>21</em></a>), in which we find SSTs have exceeded 35¬∞C in every year since 1979, with ~33% of July to September 2017 observations above this threshold. During the summer of 2017, reports of Persian Gulf over-water TW ‚â• 35¬∞C also peaked at ~6% of all TW measurements there.</p><figure id="F5">
  <div>
    <p><a href="https://advances.sciencemag.org/content/advances/6/19/eaaw1838/F5.large.jpg?width=800&amp;height=600&amp;carousel=1" title="Trends and maxima of observed SST. (A) Annual maximum of monthly SST across all grid cells in the HadISST dataset; orange dashed line is a running 30-year average, and red line marks 35¬∞C. (B) All-time maximum SST around the Persian Gulf and Arabian Sea. The blue points mark locations where monthly mean SST rose above 35¬∞C in 2017." rel="gallery-fragment-images-110081336" data-figure-caption="&lt;div class=&#34;highwire-markup&#34;&gt;&lt;span class=&#34;fig-label&#34;&gt;Fig. 5&lt;/span&gt; &lt;span class=&#34;caption-title&#34;&gt;Trends and maxima of observed SST.&lt;/span&gt;&lt;p id=&#34;p-18&#34; class=&#34;first-child&#34;&gt;(&lt;strong&gt;A&lt;/strong&gt;) Annual maximum of monthly SST across all grid cells in the HadISST dataset; orange dashed line is a running 30-year average, and red line marks 35¬∞C. (&lt;strong&gt;B&lt;/strong&gt;) All-time maximum SST around the Persian Gulf and Arabian Sea. The blue points mark locations where monthly mean SST rose above 35¬∞C in 2017.&lt;/p&gt;&lt;div class=&#34;sb-div caption-clear&#34;/&gt;&lt;/div&gt;" data-icon-position="" data-hide-link-title="0"><span></span></a></p>        
      </div>
    <figcaption id="F5-caption">
    <span>Fig. 5</span> <span>Trends and maxima of observed SST.</span><p id="p-18">(<strong>A</strong>) Annual maximum of monthly SST across all grid cells in the HadISST dataset; orange dashed line is a running 30-year average, and red line marks 35¬∞C. (<strong>B</strong>) All-time maximum SST around the Persian Gulf and Arabian Sea. The blue points mark locations where monthly mean SST rose above 35¬∞C in 2017.</p>  </figcaption>
  </figure></div><div id="sec-3"><h2>DISCUSSION</h2><p id="p-19">The station-based approach that we take here and the model-based approach taken in previous studies (<a id="xref-ref-14-5" href="#ref-14"><em>14</em></a>‚Äì<a id="xref-ref-16-2" href="#ref-16"><em>16</em></a>) represent different methods for obtaining valuable perspective on the genesis and characteristics of global TW extremes. The primary strength of station data is its ability to precisely capture local conditions, but even the best-available station data have limitations, uncertainties, and potential unobserved humidity biases (for example, due to observational procedures, instrumentation type, or siting), as well as highly incomplete spatial coverage (see discussion in the Supplementary Materials) (<a id="xref-ref-32-1" href="#ref-32"><em>32</em></a>, <a id="xref-ref-33-1" href="#ref-33"><em>33</em></a>). In contrast, reanalysis products and high-resolution regional models satisfy the need for spatiotemporal continuity and consistency and allow analysis of additional variables, but often underestimate extremes (<a id="xref-ref-34-1" href="#ref-34"><em>34</em></a>).</p><p id="p-20">In this study, we demonstrate that efforts to better understand extreme TW would benefit from further close examination, and improved standardization and integration, of station data to alleviate model shortcomings‚Äîespecially along coasts where TW can vary markedly over small distances and where high-quality humidity data are therefore essential‚Äîbut that station-based and physical modeling‚Äìbased approaches are fundamentally complementary. Further research into the origins of extreme-TW biases in gridded products and continued advances in data assimilation would also help enable the development of a more unified approach drawing on all available sources of knowledge. For instance, it is important to understand the treatment of extreme values in reanalyses, and whether false-positive or false-negative rejections might be taking place, particularly as temperature and humidity distributions shift toward ever-higher values. Key multiscale TW processes necessitating closer comparison between observations and models include coastal upwelling, atmospheric convection, land-atmosphere interactions, and atmospheric variability linked to SSTs (<a id="xref-ref-28-2" href="#ref-28"><em>28</em></a>)‚Äîfor instance, at the hourly, 1- to 10-km scale. Detailed analyses of individual events could help illuminate the unfolding interactions of processes and provide additional investigative power, such as in tracing and forecasting the rapid increases in humidity, which tend to accompany TW extremes (fig. S5), and in assessing the role of topography and land use/land cover in creating apparent TW hotspots (fig. S4). Studies comparing biases and trends in TW and SSTs among reanalyses, models, and regions would be especially beneficial, as would investigation of the sensitivity of extreme-TW projections to historical variability, changes in forcing patterns, and statistical methodologies.</p><p id="p-21">Imminent severe humid heat provides incentive for a broad interdisciplinary research initiative to better characterize health impacts. Increased collection of high-resolution health data, international collaborations with public health experts and social scientists, and dedicated modeling projects would aid in answering questions about how vulnerable populations (such as the elderly, outdoor laborers, and those with preexisting health conditions) will be adversely affected as peak TW advances further into the extreme ranges we consider here. Of particular salience is the need to ascertain how acclimation to high-heat-stress conditions is diminished as the physiological survivability limit is approached. Such efforts may also help resolve the reasons for the paucity of reported mortality and morbidity impacts associated with observed near 35¬∞C conditions (<a id="xref-ref-11-4" href="#ref-11"><em>11</em></a>, <a id="xref-ref-14-6" href="#ref-14"><em>14</em></a>).</p><p id="p-22">Our findings indicate that reported occurrences of extreme TW have increased rapidly at weather stations and in reanalysis data over the last four decades and that parts of the subtropics are very close to the 35¬∞C survivability limit, which has likely already been reached over both sea and land. These trends highlight the magnitude of the changes that have taken place as a result of the global warming to date. At the spatial scale of reanalysis, we project that TW will regularly exceed 35¬∞C at land grid points with less than 2.5¬∞C of warming since preindustrial‚Äîa level that may be reached in the next several decades (<a id="xref-ref-35-1" href="#ref-35"><em>35</em></a>). According to our weather station analysis, emphasizing land grid points underplays the true risks of extreme TW along coastlines, which tends to occur when marine air masses are advected even slightly onshore (<a id="xref-ref-14-7" href="#ref-14"><em>14</em></a>). The southern Persian Gulf shoreline and northern South Asia are home to millions of people, situating them on the front lines of exposure to TW extremes at the edge of and outside the range of natural variability in which our physiology evolved (<a id="xref-ref-36-1" href="#ref-36"><em>36</em></a>). The deadly heat events already experienced in recent decades are indicative of the continuing trend toward increasingly extreme humid heat, and our findings underline that their diverse, consequential, and growing impacts represent a major societal challenge for the coming decades.</p></div><div id="sec-4"><h2>MATERIALS AND METHODS</h2><div id="sec-5"><h3>Weather station observations</h3><p id="p-23">We use HadISD, version 2.0.1.2017f, which is produced by the Met Office Hadley Centre as a more rigorously quality-controlled version of the National Climatic Data Center Integrated Surface Database (ISD) (<a id="xref-ref-17-2" href="#ref-17"><em>17</em></a>, <a id="xref-ref-18-2" href="#ref-18"><em>18</em></a>). HadISD results from the implementation of additional data availability and quality control procedures to ISD, including checks on both temperature and Td, the two variables required for computing TW. Because of a lack of good-quality data in the tropics, our conclusions are most reliable in the subtropics and midlatitudes, especially where multiple nearby stations are in agreement. TW uncertainties range from ~0.5¬∞C for the most recent data from North America and Europe to ~1.2¬∞C for the oldest data and that from South Asia, Africa, and Latin America. Data validation is considered in depth in the Supplemental Materials.</p><p id="p-24">We use a MATLAB implementation (<a id="xref-ref-37-1" href="#ref-37"><em>37</em></a>) of the formula of (<a id="xref-ref-38-1" href="#ref-38"><em>38</em></a>) for computing TW. We compute TW daily maxima irrespective of stations‚Äô temporal resolutions, which vary from 1 to 6 hours. TW values are for 2 m above ground level, with station surface pressure calculated from its elevation using a standard atmosphere and an assumed sea-level pressure of 1013 mb. A sensitivity analysis reveals the error in TW owing to this assumption to be on the order of 0.1¬∞C.</p><p id="p-25">We additionally eliminate HadISD station data that fail any one of the following meteorological and climatological tests. Tests are listed in the order implemented, with the fraction of HadISD 31+¬∞C readings removed at each successive step shown in parentheses:</p><p id="p-26">1. A TW extreme occurs in conjunction with a dew point depression of ‚â§0.5¬∞C (65/10,492).</p><p id="p-27">2. The Td associated with a TW extreme is more than 10¬∞C different from the elevation-adjusted value at the closest grid cell and time step in the ERA-Interim reanalysis (289/10,427).</p><p id="p-28">3. A TW extreme occurring in 1979‚Äì1993 is greater than the maximum in 2003‚Äì2017 (67/10,138).</p><p id="p-29">4. A TW extreme is followed at any point by at least 1000 consecutive days of missing Td data (365/10,071).</p><p id="p-30">5. A TW extreme occurs on a day when the daily maximum and daily minimum T or Td are identical (53/9706).</p><p id="p-31">6. A TW extreme is more than 7.5¬∞C higher than any other TW value co-occurring in a 7.5¬∞ √ó 7.5¬∞ box centered on the station (405/9653).</p><p id="p-32">7. A TW extreme is associated with a Td change of more than 8¬∞C in 1 hour or 12¬∞C in 3 hours (77/9248).</p><p id="p-33">8. A TW extreme is associated with a Td greater than the previously reported, although unofficial, global maximum value of 35¬∞C recorded at Dhahran, Saudi Arabia, on 8 July 2003 (18/9171).</p><p id="p-34">9. A TW extreme occurs during a period with two or more consecutive identical daily maximum TW and Td values (289/9153).</p><p id="p-35">10. A TW extreme before 2001 is higher than any value recorded since 2001 (270/8864).</p><p id="p-36">11. The top five TW extremes at a station all occur within a 365-day period (60/8594).</p><p id="p-37">12. The Td associated with a TW extreme is higher than the 99.5th percentile of the first 5000 days, only at stations where this value is more than 1¬∞C larger than the 99.9th percentile of the last 5000 days (55/8534).</p><p id="p-38">13. The Td associated with a TW extreme is higher than the 99.5th percentile of the last 5000 days, only at stations where this value is more than 6¬∞C larger than the 99.9th percentile of the first 5000 days (362/8479).</p><p id="p-39">14. A TW extreme is associated with a relative humidity of ‚â•95% (29/8117).</p><p id="p-40">15. A TW extreme occurs on a day when the daily maximum TW takes place before 11:00 a.m. or after 8:00 p.m. local standard time (26/8088).</p><p id="p-41">16. A TW extreme is the all-time maximum at a station and is more than 2¬∞C higher than the next largest value (6/8062).</p><p id="p-42">17. A remaining ‚â•33¬∞C TW extreme is manually ascertained to be associated with a significant changepoint or not fully supported by gridded humidity and temperature data (508/8056).</p><p id="p-43">Remaining TW = 35¬∞C readings are also closely examined on a subdaily basis so as to ensure validity to the extent possible. We deem valid all other values that pass the above additional quality control measures, beyond the original quality control and homogenization (<a id="xref-ref-17-3" href="#ref-17"><em>17</em></a>, <a id="xref-ref-18-3" href="#ref-18"><em>18</em></a>). Summaries of the TW = 33¬∞C and 35¬∞C values in the final dataset are given in tables S1 and S2.</p><p id="p-44">Interannual trends are calculated using an ordinary least squares regression, with significance evaluated using a <em>t</em> test on the slope coefficient. Our assessment of extreme TW frequency considers threshold exceedances in 2¬∞C increments from 35¬∞ to 27¬∞C, so as to strike a balance between values that are sufficiently distinct from one another while being high enough to remain relevant from an impact perspective.</p></div><div id="sec-6"><h3>Marine observations</h3><p id="p-45">We use monthly SSTs from the 1¬∞ HadISST version 1.1 dataset (<a id="xref-ref-20-2" href="#ref-20"><em>20</em></a>) to assess the physical realism of our GEV extrapolations and use in situ point observations of SST and TW from International Comprehensive Ocean-Atmosphere Data Set (ICOADS) (<a id="xref-ref-21-3" href="#ref-21"><em>21</em></a>) as an independent (versus HadISD) check on the extreme TW values reported at nearby land-based weather stations. Details of these comparisons are provided in the Supplementary Materials.</p></div><div id="sec-7"><h3>Marine and vertical profile data</h3><p id="p-46">The ICOADS integrated dataset (<a id="xref-ref-21-4" href="#ref-21"><em>21</em></a>) is used as validation of near-surface conditions over water. Radiosondes are from the Integrated Global Radiosonde Archive (<a id="xref-ref-22-2" href="#ref-22"><em>22</em></a>, <a id="xref-ref-39-1" href="#ref-39"><em>39</em></a>).</p></div><div id="sec-8"><h3>GEV modeling of TW extremes in reanalysis data</h3><p id="p-47">We fit a GEV distribution to the time series of annual maximum TW from selected grid cells in ERA-Interim, a reanalysis dataset that optimally blends observations with a numerical hindcast and, thus, provides an estimate of the atmospheric state less sensitive to observation error and microclimatic variability (<a id="xref-ref-19-2" href="#ref-19"><em>19</em></a>). While well suited to identifying and extrapolating global trends, it is inevitable in such an approach that decadal temperature trends and other large-scale variability may affect our results modestly.</p><p id="p-48">The cumulative distribution function of the GEV is given by<span id="disp-formula-1"><span><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:semantics definitionurl="" encoding=""><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:msup><mml:mrow><mml:mo>‚àí</mml:mo><mml:mo stretchy="true">[</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">–∫</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>‚àí</mml:mo><mml:mi mathvariant="normal">Œ∂</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Œ≤</mml:mi></mml:mfrac><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mrow><mml:mo>‚àí</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">–∫</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:msup></mml:mrow><mml:annotation encoding=""></mml:annotation></mml:semantics></mml:math></span><span>(1)</span></span></p><p id="p-49">The TW quantile for an <em>n</em>-year return period can be evaluated by inverting <a id="xref-disp-formula-1-1" href="#disp-formula-1">Eq. 1</a><span id="disp-formula-2"><span><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:semantics definitionurl="" encoding=""><mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>‚àí</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Œ∂</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mi mathvariant="normal">Œ≤</mml:mi><mml:mi mathvariant="normal">–∫</mml:mi></mml:mfrac><mml:mo stretchy="false">{</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>‚àí</mml:mo><mml:mtext>ln</mml:mtext><mml:mo>¬†</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mo>‚àí</mml:mo><mml:mi mathvariant="normal">–∫</mml:mi></mml:mrow></mml:msup><mml:mo>‚àí</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:annotation encoding=""></mml:annotation></mml:semantics></mml:math></span><span>(2)</span></span>where the location, scale, and shape parameters are denoted Œ∂, Œ≤, and –∫, respectively. Note that, in our analysis, we use <em>n</em> = 30 (and hence <em>P</em> = 0.967), although we expect different choices of <em>n</em> would not qualitatively affect the results. We estimate these parameters using the method of maximum likelihood, only fitting distributions to series from grid cells whose maximum value over 1979 to 2017 was in the highest 0.1% worldwide (top 119 grid cells), corresponding to a TW threshold of 30.6¬∞C.</p><p id="p-50">We incorporate the effect of global warming on the return period by parameterizing Œ∂ as a function of the annual global mean air temperature anomaly<span id="disp-formula-3"><span><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:semantics definitionurl="" encoding=""><mml:mrow><mml:mi mathvariant="normal">Œ∂</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">„Äà</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">„Äâ</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ±</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ±</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">„Äà</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">„Äâ</mml:mo></mml:mrow><mml:annotation encoding=""></mml:annotation></mml:semantics></mml:math></span><span>(3)</span></span>where Œ±<sub>2</sub> and Œ±<sub>3</sub> are the intercept and slope coefficients of a linear regression.</p><p id="p-51">The extent of improvement in this nonstationary model for each grid cell is evaluated using a likelihood ratio test, with test statistic lambda<span id="disp-formula-4"><span><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:semantics definitionurl="" encoding=""><mml:mrow><mml:mi mathvariant="normal">Œõ</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">[</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>‚àí</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:annotation encoding=""></mml:annotation></mml:semantics></mml:math></span><span>(4)</span></span>where <em>L</em> is the log-likelihood of the nonstationary (subscript <em>A</em>) and stationary (subscript 0) models. Under the null hypothesis (that the nonstationary model is not superior), lambda has a chi-squared distribution with one degree of freedom. Of the 119 grid cells fitted with a GEV distribution, for ~83% of them (99 grid cells), parameterizing zeta as a function of „Äà<em>T</em>„Äâ results in a statistically significant improvement at the <em>P</em> = 0.05 level.</p><p id="p-52">We use the nonstationary model to infer the amount of global warming required for annual maximum TW = 35¬∞C to be at most a 1-in-30-year event. This is calculated by substituting <a id="xref-disp-formula-3-1" href="#disp-formula-3">Eq. 3</a> into <a id="xref-disp-formula-2-1" href="#disp-formula-2">Eq. 2</a> and solving for „Äà<em>T</em>„Äâ<span id="disp-formula-5"><span><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block"><mml:semantics definitionurl="" encoding=""><mml:mrow><mml:mo stretchy="false">„Äà</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">„Äâ</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>‚àí</mml:mo><mml:mfrac><mml:mi mathvariant="normal">Œ≤</mml:mi><mml:mi mathvariant="normal">–∫</mml:mi></mml:mfrac><mml:mo stretchy="false">{</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>‚àí</mml:mo><mml:mtext>ln</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mo>‚àí</mml:mo><mml:mi>–∫</mml:mi></mml:mrow></mml:msup><mml:mo>‚àí</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo><mml:mo>+</mml:mo><mml:mn>35</mml:mn><mml:mo>‚àí</mml:mo><mml:msub><mml:mi mathvariant="normal">Œ±</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:msub><mml:mi mathvariant="normal">Œ±</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mfrac></mml:mrow><mml:annotation encoding=""></mml:annotation></mml:semantics></mml:math></span><span>(5)</span></span></p><p id="p-53">Applying <a id="xref-disp-formula-5-1" href="#disp-formula-5">Eq. 5</a> to the 99 grid cells with nonstationary models enables spatially explicit assessments of the amount of global warming required until TW = 35¬∞C should be expected, on average, once per 30-year period at each cell. Here, we have used the HadCRUT4 dataset (version 4.6.0.0) to characterize observed warming (<a id="xref-ref-40-2" href="#ref-40"><em>40</em></a>).</p></div><div id="sec-9"><h3>Temperature of TW = 35¬∞C emergence and its uncertainty estimation</h3><p id="p-54">The spatially resolved estimates of „Äà<em>T</em>„Äâ from <a id="xref-disp-formula-5-2" href="#disp-formula-5">Eq. 5</a> provide the means for identifying the ToE, which we define as the lowest of the 99 values of „Äà<em>T</em>„Äâ returned by <a id="xref-disp-formula-5-3" href="#disp-formula-5">Eq. 5</a> and which we highlight with vertical dotted lines in <a id="xref-fig-4-3" href="#F4">Fig. 4</a>. Uncertainty in the ToE is assessed with a 10,000-member bootstrap simulation. We randomly select with replacement 30 years of TW and SST data from within the period 1979‚Äì2017, fitting parameters (slope, intercept, shape, and scale for <a id="xref-disp-formula-5-4" href="#disp-formula-5">Eq. 5</a>) for each subset. For each bootstrap iteration, we repeat the calculation of the ToE. These 10,000 estimates are then sorted to identify the 5th, 50th, and 95th percentiles; the most likely estimate; and the 90% confidence intervals.</p></div></div><p id="p-1">This is an open-access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by-nc/4.0/" rel="license">Creative Commons Attribution-NonCommercial license</a>, which permits use, distribution, and reproduction in any medium, so long as the resultant use is <strong>not</strong> for commercial advantage and provided the original work is properly cited.</p><div id="ref-list-1"><h2>REFERENCES AND NOTES</h2><ol><li><a href="#xref-ref-1-1" title="View reference 1 in text" id="ref-1">‚Üµ</a></li><li><a href="#xref-ref-2-1" title="View reference 2 in text" id="ref-2">‚Üµ</a></li><li><a href="#xref-ref-3-1" title="View reference 3 in text" id="ref-3">‚Üµ</a></li><li><a href="#xref-ref-4-1" title="View reference 4 in text" id="ref-4">‚Üµ</a></li><li><a href="#xref-ref-5-1" title="View reference 5 in text" id="ref-5">‚Üµ</a></li><li><a href="#xref-ref-6-1" title="View reference 6 in text" id="ref-6">‚Üµ</a></li><li><a href="#xref-ref-7-1" title="View reference 7 in text" id="ref-7">‚Üµ</a></li><li><a href="#xref-ref-8-1" title="View reference 8 in text" id="ref-8">‚Üµ</a><div id="cit-6.19.eaaw1838.8"><p>M. N. Sawka, C. B. Wenger, S. J. Montain, M. A. Kolka, B. Bettencourt, S. Flinn, J. Gardner, W. T. Matthew, M. Lovell, C. Scott, <em>Heat Stress Control and Heat Casualty Management</em> (US Army Research Institute of Environmental Medicine Technical Bulletin 507, 2003).</p></div></li><li><a href="#xref-ref-9-1" title="View reference 9 in text" id="ref-9">‚Üµ</a></li><li><a href="#xref-ref-10-1" title="View reference 10 in text" id="ref-10">‚Üµ</a></li><li><a href="#xref-ref-11-1" title="View reference 11 in text" id="ref-11">‚Üµ</a></li><li><a href="#xref-ref-12-1" title="View reference 12 in text" id="ref-12">‚Üµ</a></li><li><a href="#xref-ref-13-1" title="View reference 13 in text" id="ref-13">‚Üµ</a></li><li><a href="#xref-ref-14-1" title="View reference 14 in text" id="ref-14">‚Üµ</a></li><li><a href="#xref-ref-15-1" title="View reference 15 in text" id="ref-15">‚Üµ</a></li><li><a href="#xref-ref-16-1" title="View reference 16 in text" id="ref-16">‚Üµ</a></li><li><a href="#xref-ref-17-1" title="View reference 17 in text" id="ref-17">‚Üµ</a></li><li><a href="#xref-ref-18-1" title="View reference 18 in text" id="ref-18">‚Üµ</a></li><li><a href="#xref-ref-19-1" title="View reference 19 in text" id="ref-19">‚Üµ</a></li><li><a href="#xref-ref-20-1" title="View reference 20 in text" id="ref-20">‚Üµ</a></li><li><a href="#xref-ref-21-1" title="View reference 21 in text" id="ref-21">‚Üµ</a></li><li><a href="#xref-ref-22-1" title="View reference 22 in text" id="ref-22">‚Üµ</a><div id="cit-6.19.eaaw1838.22"><p>I. Durre, Y. Xungang, R. S. Vose, S. Applequist, J. Arnfield, <em>Integrated Global Radiosonde Archive (IGRA) Version 2</em>. (NOAA National Centers for Environmental Information, 2016).</p></div></li><li><a href="#xref-ref-23-1" title="View reference 23 in text" id="ref-23">‚Üµ</a></li><li><a href="#xref-ref-24-1" title="View reference 24 in text" id="ref-24">‚Üµ</a></li><li><a href="#xref-ref-25-1" title="View reference 25 in text" id="ref-25">‚Üµ</a></li><li><a href="#xref-ref-26-1" title="View reference 26 in text" id="ref-26">‚Üµ</a></li><li><a href="#xref-ref-27-1" title="View reference 27 in text" id="ref-27">‚Üµ</a></li><li><a href="#xref-ref-28-1" title="View reference 28 in text" id="ref-28">‚Üµ</a></li><li><a href="#xref-ref-29-1" title="View reference 29 in text" id="ref-29">‚Üµ</a></li><li><a href="#xref-ref-30-1" title="View reference 30 in text" id="ref-30">‚Üµ</a></li><li><a href="#xref-ref-31-1" title="View reference 31 in text" id="ref-31">‚Üµ</a></li><li><a href="#xref-ref-32-1" title="View reference 32 in text" id="ref-32">‚Üµ</a></li><li><a href="#xref-ref-33-1" title="View reference 33 in text" id="ref-33">‚Üµ</a></li><li><a href="#xref-ref-34-1" title="View reference 34 in text" id="ref-34">‚Üµ</a></li><li><a href="#xref-ref-35-1" title="View reference 35 in text" id="ref-35">‚Üµ</a><div id="cit-6.19.eaaw1838.35"><p>G. J. Van Oldenborgh, M. Collins, J. Arblaster, J. H. Christensen, J. Marotzke, S. B. Power, M. Rummukainen, T. Zhou, Annex I: Atlas of global and regional climate projections. in <em>Climate Change 2013: The Physical Science Basis. Contribution of Working Group I to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change</em>, T. F. Stocker, D. Qin, G.-k. Plattner, M. Tignor, S. K. Allen, Eds. (Cambridge Univ. Press, Cambridge, U.K, 2013).</p></div></li><li><a href="#xref-ref-36-1" title="View reference 36 in text" id="ref-36">‚Üµ</a></li><li><a href="#xref-ref-37-1" title="View reference 37 in text" id="ref-37">‚Üµ</a></li><li><a href="#xref-ref-38-1" title="View reference 38 in text" id="ref-38">‚Üµ</a></li><li><a href="#xref-ref-39-1" title="View reference 39 in text" id="ref-39">‚Üµ</a></li><li><a href="#xref-ref-40-1" title="View reference 40 in text" id="ref-40">‚Üµ</a></li><li><div id="cit-6.19.eaaw1838.41"><p>Copernicus Climate Change Service (C3S) (2017): ERA5: Fifth generation of ECMWF atmospheric reanalyses of the global climate. Copernicus Climate Change Service Climate Data Store (CDS), <a href="https://cds.climate.copernicus.eu/cdsapp#!/home">https://cds.climate.copernicus.eu/cdsapp#!/home</a> [accessed 10 November 2019].</p></div></li><li></li><li></li><li></li></ol></div><p><strong>Acknowledgments: </strong>Code for computing TW using the Davies-Jones formulae was provided by R. Kopp at Rutgers University. Part of this work was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration. <strong>Funding:</strong> Funding for R.M.H. and C.R. was provided by the National Oceanic and Atmospheric Administration‚Äôs Regional Integrated Sciences and Assessments program, grant NA15OAR4310147. <strong>Author contributions:</strong> C.R. and T.M. produced the datasets and conducted the analyses. C.R., T.M., and R.M.H. collectively developed ideas and wrote the manuscript. <strong>Competing interests:</strong> The authors declare that they have no competing interests. <strong>Data and materials availability:</strong> Datasets are described in the Supplementary Materials. Data and code used in the analysis are publicly available in a Github repository at <a href="https://github.com/cr2630git/humidheat">https://github.com/cr2630git/humidheat</a>. All data needed to evaluate the conclusions in the paper are present in the paper and/or the Supplementary Materials. Additional data related to this paper may be requested from the authors.</p><ul><li id="copyright-statement-1">Copyright ¬© 2020 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).</li></ul></div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 01:17:10 +0000</pubDate>
      <source>https://advances.sciencemag.org/content/6/19/eaaw1838</source>
    </item>
    <item>
      <title>Embrace ephemerality with default disappearing messages</title>
      <link>https://signal.org/blog/disappearing-by-default/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___signal_org_blog_disappearing-by-default_/image.jpg" /> 
<div id="readability-page-1" class="page"><div><div><p></p><p>As the norms for how people connect have changed, much of the communication that once took place through the medium of coffee shops, bars, and parks now takes place through the medium of digital devices. One side effect of this shift from <em>analog</em> to <em>digital</em> is the conjoined shift from the <em>ephemeral</em> to the <em>eternal:</em> words once transiently spoken are now ‚Äì more often than not ‚Äì data stored forever.</p><p>We‚Äôve designed Signal so that your data always stays in your hands. We think there‚Äôs something special about sharing a private fleeting moment between friends, so Signal also supports disappearing messages. Now, we‚Äôve added the ability to preconfigure all conversations you initiate with a default disappearing messages timer.</p><h2 id="a-primer-on-the-timer">A primer on the timer</h2><p><a href="https://signal.org/blog/disappearing-messages/">Disappearing messages</a> provide a way to keep your message history tidy. When enabled for a conversation, messages will be deleted for the sender and recipients after the specified time. This is not for situations where your contact is your adversary ‚Äî after all, if someone who receives a disappearing message really wants a record of it, they can always use another camera to take a photo of the screen before the message disappears. However, this is a nice way to automatically save storage space on your devices and limit the amount of conversation history that remains on your device if you should find yourself physically separated from it.</p><p>You can even enable disappearing message for <em>Note To Self</em> to create an ephemeral cross-device personal clipboard of sorts.</p><h2 id="disappearing-by-default-and-customized-timers">Disappearing by default and customized timers</h2><p>Until now, disappearing messages had to be enabled on a per-conversation basis, but for those who want to take ephemerality to the fullest, Signal now supports the ability to preconfigure all conversations you initiate with a default timer.</p><p>We‚Äôve also added the ability to set custom timer durations on your conversations, so that some content can be <em>gone in 60 seconds</em> and others can exist for 18 minutes or 4 weeks. <a href="https://signal.org/install/">Install Signal</a>, and give it a shot today!</p><p></p></div></div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 05:00:28 +0000</pubDate>
      <source>https://signal.org/blog/disappearing-by-default/</source>
    </item>
    <item>
      <title>Scrimba (YC S20) is hiring a full-stack dev to make CS education more accessible</title>
      <link>https://jobs.scrimba.com/</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___jobs_scrimba_com_/image.jpg" /> 
<div id="readability-page-1" class="page"><div>
    
      <div>
        <div>
<p><strong>Once upon a time</strong>¬†there lived a programmer called Sindre in a fjord in Norway üá≥üá¥</p>
<p>Sindre was not like most programmers, because he only wrote code in his own homemade programming language, called <a href="https://imba.io/"></a><a href="https://imba.io/" target="_blank">Imba.</a><strong></strong></p>
<p>Sindre loved Imba as if it was his own child. However, it was lonely to code in Imba, as he was the only developer in the world who knew the language. And he desperately wanted a few colleagues¬†üò¢</p>
<p><strong>So one day, Sindre decided to teach people about Imba.¬†</strong>He bought a microphone, downloaded Final Cut Pro, and started recording video tutorials¬†üé¨</p>
<p>But he quickly realised how difficult it was to create good educational videos. A five minute video would take him an hour to produce, because of all the post-production that he needed to do (editing, exporting, uploading). So Sindre grew increasingly frustrated¬†üòñ</p>
<p>He also feared that other programmers wouldn&#39;t learn Imba properly by watching his videos, as the only way to learn Imba was to write a lot of Imba code. But regular videos wouldn&#39;t permit students to interact with the code.</p>
<p>So Sindre gave eventually up. He didn&#39;t publish any video tutorials about Imba. These were sad and lonesome times, as he feared that he would never ever get a colleague üò≠</p>
<p><strong>But then Sindre had an idea! üí°</strong></p>
<p><em>&#34;Perhaps video in itself is the wrong format? What if I invent a new video format that makes it easier for me to record tutorials, and that also enables students to interact with the code inside the tutorials?&#34;</em></p>
<p><strong>For seven days and seven nights</strong>, he worked tirelessly at his home office. And when he finally came out of the office, he had invented an¬†<em>interactive video format </em>for creating coding screencasts.</p>
<p>He called the technology <strong>Scrimba</strong>, as he would use it to create¬†<strong>S</strong><strong>cr</strong>eencasts for¬†<strong>Imba.</strong></p>
<p><strong>The morning after Sindre had invented Scrimba,</strong> his friend Per came to visit him. Per was also a programmer, but didn&#39;t know Imba. Sindre showed Per the Scrimba invention and told him happily:</p>
<p><em>&#34;Now I can teach people about Imba. Perhaps I willI finally get an Imba colleague to work with, so that I don&#39;t have to be lonely anymore.&#34;</em>¬†ü•≥<em></em></p>
<p>But Per looked at the Scrimba technology and said:</p>
<p><em>&#34;Why use it to just teach Imba? This brilliant invention should be used to teach HTML, CSS, JavaScript, and React! There&#39;s a much bigger need for that in the world!&#34;</em></p>
<p><strong>And so it was that Sindre did not publish any Imba tutorials. </strong>Instead, he and Per formed a company around Scrimba. They turned it into an online learning platform that grew to half a million users over the next few years¬†üöÄ</p>
<p>And today, five years later, Sindre still has not recorded a single Imba tutorial, as he spends all his time working on the underlying Scrimba technology.</p>
<p><strong>But now that Scrimba has become a cash flow-positive business</strong>, they can afford to hire a new Imba developer, and pay him to learn the Imba language. So Sindre can finally get an Imba colleague¬†üéâ¬†üéâ üéâ</p>
<p>And that colleague might just be you?</p>
</div>
      </div>
    
  </div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 07:00:30 +0000</pubDate>
      <source>https://jobs.scrimba.com/</source>
    </item>
    <item>
      <title>The Ancient Persian way to keep cool</title>
      <link>https://www.bbc.com/future/article/20210810-the-ancient-persian-way-to-keep-cool</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___www_bbc_com_future_article_20210810-the-ancient-persian-way-to-keep-cool/image.jpg" /> 
<div id="readability-page-1" class="page"><div><div><section id="futurearticle20210810-the-ancient-persian-way-to-keep-cool"><div id="headline-futurearticle20210810-the-ancient-persian-way-to-keep-cool"><div><p>The Ancient Persian way to keep cool</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rtttz.webp" type="image/webp"/><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rtttz.jpg" type="image/jpeg"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rtttz.webp" type="image/webp"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rtttz.jpg" type="image/jpeg"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rtttz.webp" type="image/webp"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rtttz.jpg" type="image/jpeg"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rtttz.webp" type="image/webp"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rtttz.jpg" type="image/jpeg"/></picture></div></div><div><div><div><article><div><p>From Ancient Egypt to the Persian Empire, an ingenious method of catching the breeze kept people cool for millennia. In the search for emissions-free cooling, the &#34;wind catcher&#34; could once again come to our aid.</p><div><div><p>T</p><div><div><p>The city of Yazd in the desert of central Iran has long been a focal point for creative ingenuity. Yazd is home to a system of ancient engineering marvels that include an underground refrigeration structure called <em><a href="https://theculturetrip.com/middle-east/articles/this-ancient-technique-to-make-ice-in-the-desert-is-mind-boggling/">y</a><a href="https://theculturetrip.com/middle-east/articles/this-ancient-technique-to-make-ice-in-the-desert-is-mind-boggling/">akhchƒÅl</a></em>, an underground irrigation system called <em><a href="https://www.bbc.com/travel/article/20180619-irans-ancient-engineering-marvel">qanats</a></em>, and even a network of couriers called <em><a href="https://www.bbc.com/travel/article/20200624-iran-the-surprising-origins-of-the-postal-service">pirradazi≈°</a></em> that predate postal services in the US by more than 2,000 years.</p>
<p>Among Yazd&#39;s ancient technologies is the wind catcher, or <em>b√¢dgir</em> in Persian. These remarkable structures are a common sight soaring above the rooftops of Yazd. They are often rectangular towers, but they also appear in circular, square, octagonal and other ornate shapes.</p>
<p>Yazd is said to have the most wind catchers in the world, though <a href="https://www.bbc.com/travel/article/20180926-an-ancient-engineering-feat-that-harnessed-the-wind">they may have originated in Ancient Egypt</a>. In Yazd, the wind catcher soon proved indispensable, making this part of the hot and arid Iranian Plateau livable.</p>
<p>Though many of the city&#39;s wind catchers have fallen out of use, the structures are now drawing academics, architects and engineers back to the desert city to see what role they could play in keeping us cool in a <a href="https://www.bbc.co.uk/news/science-environment-57751918">rapidly heating world</a>.</p></div></div></div></div><div><div id="future/article/20210810-the-ancient-persian-way-to-keep-cool-p09rttxb"><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rttxb.webp" type="image/webp"/><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rttxb.jpg" type="image/jpeg"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rttxb.webp" type="image/webp"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rttxb.jpg" type="image/jpeg"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rttxb.webp" type="image/webp"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rttxb.jpg" type="image/jpeg"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rttxb.webp" type="image/webp"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rttxb.jpg" type="image/jpeg"/></picture><div><p>The openings of the towers face the prevailing wind, catching it and funneling it down to the interior below (Credit: Alamy)</p></div></div></div></div><div><div><div><div><p>As a wind catcher requires no electricity to power it, it is both a cost-efficient and green form of cooling. With conventional mechanical air conditioning already <a href="https://www.iea.org/reports/the-future-of-cooling">accounting for a fifth of total electricity consumption globally</a>, ancient alternatives like the wind catcher are becoming an <a href="https://www.bbc.com/future/article/20190822-are-there-alternatives-to-air-conditioning">increasingly appealing option</a>.</p>
<p>There are two main forces that drive the air through and down into the structures: the incoming wind and the change in buoyancy of air depending on temperature ‚Äì with warmer air tending to rise above cooler, denser air. First, as air is caught by the opening of a wind catcher, it is funneled down to the dwelling below, depositing any sand or debris at the foot of the tower. Then the air flows throughout the interior of the building, <a href="https://www.sciencedirect.com/science/article/pii/S1364032114008351">sometimes over subterranean pools of water for further cooling</a>. Eventually, warmed air will rise and leave the building through another tower or opening, aided by the pressure within the building.</p>
<p>The shape of the tower, alongside factors like the layout of the house, the direction the tower is facing, how many openings it has, its configuration of fixed internal blades, canals and height are all finely tuned to improve the tower&#39;s ability to draw wind down into the dwellings below.</p></div></div></div></div><div><div><div><div><p>Using the wind to cool buildings has a history stretching back almost as long as people have lived in hot desert environments. Some of the <a href="https://ascelibrary.org/doi/10.1061/9780784413517.161">earliest wind-catching technology comes from Egypt 3,300 years ago</a>, according to researchers Chris Soelberg and Julie Rich of Weber State University in Utah. Here, buildings had thick walls, few windows facing the Sun, openings to take in air on the side of prevailing winds and an exit vent on the other side ‚Äì known in Arabic as <em><a href="https://orbi.uliege.be/bitstream/2268/167581/1/Attia_Designing%20the%20Malqaf%20for%20summer%20cooling%20in%20low-rise%20housing,%20an%20experimental%20study.pdf">malq</a><a href="https://orbi.uliege.be/bitstream/2268/167581/1/Attia_Designing%20the%20Malqaf%20for%20summer%20cooling%20in%20low-rise%20housing,%20an%20experimental%20study.pdf">af architecture</a></em>. Though some argue that <a href="https://www.bbc.com/travel/article/20180926-an-ancient-engineering-feat-that-harnessed-the-wind">the birthplace of the wind catcher was Iran itself</a>.</p>
<p>Wherever it was first invented, wind catchers have since become widespread across the Middle East and North Africa. Variations of Iran&#39;s wind catchers can be found in the <em>barjeels</em> of Qatar and Bahrain, the <em>malqaf</em> of Egypt, the <em>mungh</em> of Pakistan, and <a href="https://eprints.whiterose.ac.uk/112557/3/A%252520review%252520on%252520windcatcher%252520for%252520passive%252520cooling%252520and%252520natural%252520ventilation%252520in%252520buildings%20%281%29.pdf">many other</a><a href="https://eprints.whiterose.ac.uk/112557/3/A%252520review%252520on%252520windcatcher%252520for%252520passive%252520cooling%252520and%252520natural%252520ventilation%252520in%252520buildings%20%281%29.pdf"> places</a><a href="https://eprints.whiterose.ac.uk/112557/3/A%252520review%252520on%252520windcatcher%252520for%252520passive%252520cooling%252520and%252520natural%252520ventilation%252520in%252520buildings%20%281%29.pdf">, notes </a><a href="https://eprints.whiterose.ac.uk/112557/3/A%252520review%252520on%252520windcatcher%252520for%252520passive%252520cooling%252520and%252520natural%252520ventilation%252520in%252520buildings%20%281%29.pdf">Fatemeh Jomehzadeh of the University of Technology Malaysia and colleagues</a>.</p></div></div></div></div><div><div id="future/article/20210810-the-ancient-persian-way-to-keep-cool-p09rtv6p"><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rtv6p.webp" type="image/webp"/><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rtv6p.jpg" type="image/jpeg"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rtv6p.webp" type="image/webp"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rtv6p.jpg" type="image/jpeg"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rtv6p.webp" type="image/webp"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rtv6p.jpg" type="image/jpeg"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rtv6p.webp" type="image/webp"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rtv6p.jpg" type="image/jpeg"/></picture><div><p>Due to long disuse, many of Iran&#39;s windcatchers are not in a good state of repair. But some researchers would like to see them restored to working order (Credit: Alamy)</p></div></div></div></div><div><div><div><div><p>The Persian civilisation is widely considered to have added structural variations to allow for better cooling ‚Äì such as combining it with its existing irrigation system to help to cool the air down before releasing it throughout the home. In Yazd&#39;s hot, dry climate, these structures proved remarkably popular, until the city became a hotspot of soaring ornate towers seeking the desert wind. The historical city of Yazd was recognised as a Unesco World Heritage site in <a href="https://whc.unesco.org/en/list/1544/">2017</a>, in part for its proliferation of wind catchers.</p>
<p>As well as performing the functional purpose of cooling homes, the towers also had a strong cultural significance. In Yazd, the wind catchers are as much a part of the skyline as the Zoroastrian Fire Temple and Tower of Silence. Among them is the wind catcher at the Dowlatabad Abad Gardens, said to be the <a href="https://www.researchgate.net/figure/The-eight-sided-wind-catcher-of-Dowlat-Abad-Gardens-edifice-in-Yazd-is-the-tallest-in_fig2_308532117">tallest in the world at 33m</a> (108ft) and one of the few wind catchers still in operation. Housed in an octagonal building, it overlooks a fountain stretching past rows of pine trees.</p></div></div></div></div><div><div><div><div><p>The emissions-free cooling efficacy of such wind catchers make some researchers argue that they are due a revival.</p>
<p>Parham Kheirkhah Sangdeh has extensively studied the scientific application and surrounding culture of wind catchers in contemporary architecture at Ilam University in Tehran, Iran. He says inconveniences like pests entering the chutes and the gathering of dust and desert debris have meant many have turned away from traditional wind catchers. In their place are mechanical cooling systems, such as conventional air-conditioning units. Often, those options are powered by fossil fuels and use <a href="https://www.bbc.com/future/article/20201204-climate-change-how-chemicals-in-your-fridge-warm-the-planet">refrigerants that act as powerful greenhouse gases if released into the atmosphere</a>.</p></div></div></div></div><div><div id="future/article/20210810-the-ancient-persian-way-to-keep-cool-p09rtvlr"><div><picture><source media="(min-width:624px)" srcset="https://ychef.files.bbci.co.uk/1024x1280/p09rtvlr.webp" type="image/webp"/><source media="(min-width:624px)" srcset="https://ychef.files.bbci.co.uk/1024x1280/p09rtvlr.jpg" type="image/jpeg"/><source media="(min-width:485px)" srcset="https://ychef.files.bbci.co.uk/885x1280/p09rtvlr.webp" type="image/webp"/><source media="(min-width:485px)" srcset="https://ychef.files.bbci.co.uk/885x1280/p09rtvlr.jpg" type="image/jpeg"/><source media="(min-width:320px)" srcset="https://ychef.files.bbci.co.uk/720x900/p09rtvlr.webp" type="image/webp"/><source media="(min-width:320px)" srcset="https://ychef.files.bbci.co.uk/720x900/p09rtvlr.jpg" type="image/jpeg"/></picture><div><p>The wind catchers of Iran have inspired modern designs in Europe, the US and elsewhere, as architects turn towards passive forms of cooling (Credit: Alamy)</p></div></div></div></div><div><div><div><div><p>The advent of modern cooling technologies has long been blamed for the deterioration of traditional methods in Iran, <a href="https://doi.org/10.2307/4300566">the historian of Iranian architecture Elizabeth Beazley wrote in 1977</a>. Without constant maintenance, the harsh climate of the Iranian Plateau has worn away many structures from wind catchers to ice houses. Kheirkhah Sangdeh also sees the shift away from wind catchers as in part down to a tendency among the public to engage with technologies from the West.</p>
<p>&#34;There needs to be some changes in cultural perspectives to use these technologies. People need to keep an eye on the past and understand why energy conservation is important,&#34; Kheirkhah Sangdeh says. &#34;It starts with recognising cultural history and the importance of energy conservation.&#34;</p>
<p>Kheirkhah Sangdeh hopes to see Iran&#39;s wind catchers updated to add energy-efficient cooling to existing buildings. But he has met many barriers to his work in the form of ongoing international tensions, the coronavirus pandemic and ongoing<a href="https://www.bbc.com/news/av/world-middle-east-57948717"> water shortage</a>. &#34;Things are so bad in Iran that [people] take it day by day,&#34; says Kheirkhah Sangdeh.</p></div></div></div></div><div><div id="future/article/20210810-the-ancient-persian-way-to-keep-cool-p09rtttz"><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rtttz.webp" type="image/webp"/><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p09rtttz.jpg" type="image/jpeg"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rtttz.webp" type="image/webp"/><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p09rtttz.jpg" type="image/jpeg"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rtttz.webp" type="image/webp"/><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p09rtttz.jpg" type="image/jpeg"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rtttz.webp" type="image/webp"/><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p09rtttz.jpg" type="image/jpeg"/></picture><div><p>Yazd is said to have the most wind catchers of any city in the world (Credit: Alamy)</p></div></div></div></div><div><div><div><div><p>Fossil-fuel-free methods of cooling like the wind catcher might well be due a revival, but to a surprising extent they are already present ‚Äì albeit in a less magnificent form than those in Iran ‚Äì in many Western countries.</p>
<p>In the UK, <a href="https://www.semanticscholar.org/paper/Evaluation-of-pressure-coefficients-and-estimation-Karakatsanis-Bahadori/6cfc2eb6ccf3b79c2197db02df62c31ee14e0b99">some 7,000 variations of wind catchers were installed in public buildings between 1979 and 1994</a>. They can be seen from buildings such as <a href="https://www.monodraught.com/projects/royal-chelsea-hospital">the Royal Chelsea Hospital in London</a>, to <a href="https://www.sciencedirect.com/science/article/abs/pii/S1364032116310358?via%3Dihub">supermarkets in Manchester</a>.</p>
<p>These modernised wind catchers bear little resemblance to Iran&#39;s towering structures. On one three-storey building on a busy road in north London, small hot pink ventilation towers allow passive ventilation. Atop a shopping centre in Dartford, <a href="https://www.visionventilation.co.uk/architectural-inspired-designs/">conical ventilation towers rotate to catch the breeze with the help of a rear wing that keeps the tower facing the prevailing wind</a>.</p>
<p>The US too has adopted wind-catcher-inspired designs with enthusiasm. One such example is the visitor center at <a href="http://sipb.sggw.pl/CRC2014/data/papers/9780784413517.161.pdf">Zion National Park</a> in southern Utah. The park sits in a high desert plateau, comparable to Yazd in climate and topography, and the use of passive cooling technologies including the wind catcher nearly eliminated the need for mechanical air-conditioning. Scientists have recorded a temperature difference of 16C (29F) between the outside and inside of the visitor centre, despite the many bodies regularly passing through.</p>
<p>There is further scope for the spread of the wind catcher, as <a href="https://www.theccc.org.uk/2017/08/08/hidden-problem-overheating/">the search for sustainable solutions to overheating continues</a>. In Palermo, Sicily, researchers have found that <a href="https://www.tandfonline.com/doi/abs/10.1080/14733315.2016.1214397">the climate and prevailing wind conditions make it a ripe location for a version of the Iranian wind catcher</a>. This October, meanwhile, the wind catcher is set to have a high-profile position at <a href="https://www.bbc.co.uk/news/business-56682427">the World Expo</a> fair in Dubai, as part of <a href="https://www.querkraft.at/en/projects/expo-pavilion">a network of conical buildings in the Austrian pavilion</a>, where the Austrian architecture firm Querkraft has taken inspiration from the Arabic <em>barjeel</em> version of the wind tower.</p>
<p>While researchers such as Kheirkhah Sangdeh argue that the wind catcher has much more to give in cooling homes without fossil fuels, this ingenious technology has already migrated further around the world than you might think. Next time you see a tall vented tower on top of a supermarket, high-rise or <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjH7rK7kKTyAhWiwOYKHStlCpgQFnoECA4QAw&amp;url=https%3A%2F%2Fs3-eu-west-1.amazonaws.com%2Fmonodraught%2Fdownloads%2Fprojects%2Faddey-and-stanhope-shool-windcatcher-case-study.pdf%3Fv%3D2&amp;usg=AOvVaw2b0GfphSTbK_2wygJxCHG9">school</a>, look carefully ‚Äì you might just be looking at the legacy of the magnificent wind catchers of Iran.</p>
<p>--</p>
<p><em>The emissions from travel it took to report this story were 0kg CO2. The digital emissions from this story are an estimated 1.2g to 3.6g CO2 per page view. </em><a href="https://www.bbc.com/future/article/20200131-why-and-how-does-future-planet-count-carbon"><em>Find out more about how we calculated this figure here</em></a><em>.</em></p>
<p>--</p>
<p><em>Join one million Future fans by liking us on¬†</em><a href="https://www.facebook.com/BBCFuture/"><strong><em>Facebook</em></strong></a><em>, or follow us on¬†</em><a href="https://twitter.com/BBC_Future"><strong><em>Twitter</em></strong></a><em>¬†or<strong>¬†</strong></em><a href="https://www.instagram.com/bbcfuture_official/"><strong><em>Instagram</em></strong></a><em>.</em></p>
<p><em>If you liked this story,¬†</em><a href="http://pages.emails.bbc.com/subscribe/?ocid=fut.bbc.email.we.email-signup"><strong><em>sign up for the weekly bbc.com features newsletter</em></strong></a><em>, called &#34;The Essential List&#34;. A handpicked selection of stories from BBC Future, Culture, Worklife, and Travel, delivered to your inbox every Friday.</em></p></div></div></div></div></div></article></div></div></div></section></div></div></div>]]></content:encoded>
      <pubDate>Wed, 11 Aug 2021 06:46:09 +0000</pubDate>
      <source>https://www.bbc.com/future/article/20210810-the-ancient-persian-way-to-keep-cool</source>
    </item>
    <item>
      <title>Giuseppe &#39;Bepi&#39; Colombo: Grandfather of the orbital fly-by</title>
      <link>https://www.esa.int/About_Us/ESA_history/Giuseppe_Bepi_Colombo_Grandfather_of_the_fly-by</link>
      <description></description>
      <content:encoded><![CDATA[<img src="https://rss.markdessain.com/feeds/hackernews/https___www_esa_int_About_Us_ESA_history_Giuseppe_Bepi_Colombo_Grandfather_of_the_fly-by/image.jpg" /> 
<div id="readability-page-1" class="page"><div>
	
	
		




	
	
	


	


 
		


							
														
																	

	  

								
				
								
						
								
				<section>
	<a href="https://www.esa.int/ESA_Multimedia/Images/2002/01/Giuseppe_Bepi_Colombo_1920-1984">
		
	</a>
	</section>
	

<article>

<header>
	<span>Agency</span>
	
	<p><span><span id="viewcount">9813</span><small> views</small></span>
										<span><span id="ezsr_total_6821226">48</span><small> likes</small></span>
				
	</p>
</header>



<p>Professor Giuseppe ‚ÄòBepi‚Äô Colombo was a mathematician and engineer of astonishing imagination. His bald head and grey moustache of later years were a familiar sight in the corridors of both ESA and NASA.</p>

<div>
				
		<p>Giuseppe Colombo was born in 1920 in Padua, Italy, where he attended primary and secondary schools. After graduating from the University of Pisa in Mathematics in 1944, he returned to Padua where he worked as Assistant, and then Associate Professor, of Theoretical Mechanics at the University.</p><p>In 1955, he became Full Professor of Applied Mechanics at the Faculty of Engineering and in 1970 he was invited to NASA‚Äôs Jet Propulsion Laboratory (JPL) to participate in a conference on NASA&#39;s Mariner 10 Venus/Mercury mission. Earlier in that year he had noted that the period of the spacecraft&#39;s orbit, after it flew past Mercury, would be very close to twice the rotational period of the planet itself. He suggested that a second encounter with Mercury could be achieved.</p>
	</div>
			
    
							
														
																	



								
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2003/04/Planet_Mercury">
				
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2003/04/Planet_Mercury">Planet Mercury</a>
								</figcaption>
	</figure>	
		<p>An analytical study conducted by JPL confirmed Colombo&#39;s suggestion. The study showed that by careful choice of the Mercury fly-by point, the planet‚Äôs gravity could help the spacecraft return to Mercury six months later. Almost everything known until now about the planet Mercury comes from Mariner 10‚Äôs orbits during 1974-75, which were inspired by Colombo&#39;s calculations.</p><p>In the same year as those Mercury flybys, Colombo invented the concept of using of a long tether to support a spacecraft from an orbiting platform. Together with a colleague, Mario Grossi, he approached NASA and the Italian Space Agency with the idea, which developed into the Tethered Satellite System (TSS). The TSS was launched in 1992 aboard Space Shuttle mission STS-46, and again in 1996 on STS-75.</p>	</div>	
    
							
														
																	



							
				
								
						
								
												<div>
				<figure>
					<a href="https://www.esa.int/ESA_Multimedia/Images/2003/05/Giotto_approaching_the_nucleus_of_Halley_s_Comet">
				
			</a>
				<figcaption>
							<a href="https://www.esa.int/ESA_Multimedia/Images/2003/05/Giotto_approaching_the_nucleus_of_Halley_s_Comet">Giotto approaching the nucleus of Halley&#39;s Comet</a>
								</figcaption>
	</figure>	
		<p>As one of the initiators of ESA&#39;s mission to Comet Halley, he suggested the name Giotto, but died in 1984 before that project was accomplished. At the University of Padua, his work continues in the Centro Interdipartimentale Studi ed Attivit√† Spaziali ‚ÄòG. Colombo‚Äô (CISAS).</p><p>To commemorate this great scientist, ESA has named its Mercury mission BepiColombo. It also awards a &#39;Colombo fellowship&#39; each year to a European scientist working in the field of astronautics. In addition, asteroid number 10387 was named in his honour.</p>	</div>	
    
						
    
						
    
						
    
						
    
						
    
						
    
						
    
					



</article>



	<section>
		<h2>Related Links</h2>
	
</section> 

	
	
 
	
	</div></div>]]></content:encoded>
      <pubDate>Tue, 10 Aug 2021 21:10:10 +0000</pubDate>
      <source>https://www.esa.int/About_Us/ESA_history/Giuseppe_Bepi_Colombo_Grandfather_of_the_fly-by</source>
    </item>
  </channel>
</rss>